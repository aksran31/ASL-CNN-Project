{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our stated objective is:\n",
    "> This study will employ a structured procedure including data preprocessing, designing a custom CNN architecture, model \n",
    "training, and model evaluation. \n",
    "To enhance gesture accuracy and model performance, images will be filtered through \n",
    "different preprocessing steps such as normalising by scaling pixels between 0 and 1. The \n",
    "carefully planned architecture starts with a multi-layer convolutional block, where each block \n",
    "contains convolutional layers (with 3x3 or 5x5 filter sizes) for spatial feature extraction, along \n",
    "with a non-linear activation function like ReLU (Rectified Linear Unit) and pooling layers for \n",
    "spatial dimensionality reduction. The feature maps will be flattened and passed on to \n",
    "fully-connected (dense) layers, which will have dropout layers to take care of overfitting. Finally, \n",
    "the classification will be carried out using the softmax layer, providing 29 classes of \n",
    "probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deep Learning**\n",
    "\n",
    "    - Deep Learning is about finding patterns in data using a ***neural network***, a model inspired by the human brain, and making predictions based on these patterns.\n",
    "\n",
    "    - A ***layer*** is a group of interconnected **neurons** that can learn from data and make decisions. A neural network is made up of multiple layers stacked one upon the other (hence the word \"deep\"). The output of one layer becomes the input for the layer right below it.\n",
    "\n",
    "    - Each following layer helps the model learn more complex patterns.  The first layer starts by learning simple features (like identifying words from sentences). The later layers learn more complex features (like understanding what each word implies. e.g., love -> positive, hate -> negative).\n",
    "\n",
    "    - Generally,\n",
    "\n",
    "        - **Input layer:** Takes in the data.\n",
    "\n",
    "        - **Hidden layers:** Processes and learns patterns from the data. They are called \"hidden\" because no one can really see or understand what happens inside them, just like how the human brain is not fully understood. Two general types:\n",
    "\n",
    "            - **Fully connected layers (dense layers):** \n",
    "\n",
    "                - Every neuron is connected to every neuron in the previous layer. The fully connected layer takes the information from all the neurons in the previous layer and mixes it together to make a decision.\n",
    "\n",
    "                - In an image recognition task, if the previous layer has learned features like edges or textures, the fully connected layer combines those features to identify objects like \"cat\" or \"dog.\"\n",
    "\n",
    "            - **Activation layers:** \n",
    "\n",
    "                - The activation layer takes the weighted sum of features from a neuron, and decides whether this neuron should \"fire\" (pass information to the next layer) that sum should influence the next step in the network.\n",
    "\n",
    "                - It uses an **activation function** to check if this neuron should \"fire\" (pass the information to next layer) or not. For example, in the ReLU function, if the sum is negative, it will block the information (turning it to zero).\n",
    "\n",
    "                    - **Example**: Say we are predicting if a fruit is an apple or orange based on two features:\n",
    "\n",
    "                        - Color: Red (0) or Orange (1), Shape: Round (1) or Elliptical (0)\n",
    "\n",
    "                    - Let the random weights for each feature be:\n",
    "\n",
    "                        - Color: 0.5, Shape: 1.5\n",
    "\n",
    "                    - Now, for an image of an Apple where the Color = Red and Shape = Round:\n",
    "\n",
    "                        - The network multiplies the input by the weights:\n",
    "\n",
    "                        - Color: Red = 0, so weighted sum for color = 0 * 0.5 = 0. Shape: Round = 1, so weighted sum for shape = 1 * 1.5 = 1.5. The total weighted sum = 0 + 1.5 = 1.5.\n",
    "\n",
    "                    - This sum is then passed through an activation function (let’s say ReLU):\n",
    "\n",
    "                        - ReLU turns any negative value to 0. Since the weighted sum is positive, ReLU allows the value to pass through as 1.5.\n",
    "\n",
    "                    - But for an image of a Carrot where the Color = Red and Shape = Eliptical,\n",
    "\n",
    "                        - Color: Orange = 1, so weighted sum for color = 1 * 0.5 = 0.5. Shape: Elliptical = -1, so weighted sum for shape= -1 * 1.5 = -1.5 (elliptical shape gives a negative contribution). Total weighted sum = 0.5 - 1.5 = -1.\n",
    "\n",
    "                    - Since the weighted sum is negative (-1.5), ReLU will turn it to 0, as ReLU only passes positive values.\n",
    "                    - This helps the network focus on the most important features and ignore less important ones that don't contribute to the final prediction (a Carrot in a model predicting Apple or Orange), passing only relevant information to the next layer.\n",
    "\n",
    "                - Cutting off the negative values adds non-linearity, letting the network learn complex patterns instead of just simple straight-line relationships.\n",
    "\n",
    "        - **Output Layer:** Final result (e.g., classification label or predicted value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convolutional Neural Network (CNN)**\n",
    "\n",
    "    - CNN is a type of deep learning model for images. \n",
    "\n",
    "    - First, it learns simple patterns in an image, such as edges, lines, and colours.\n",
    "\n",
    "    - As it moves through more layers, it combines these simple patterns to recognise more complex shapes and structures.\n",
    "\n",
    "    - Throughout this process, it also keeps track of where each pattern appears in the image.\n",
    "    By building up understanding in this way — from small details to full objects (***spatial hierarchies of features***) — the model starts to identify what the image shows. On Python this is automatic.\n",
    "\n",
    "- A CNN is organised into a series of layers. Each layer has a specific role to gradually transform the raw image into a set of class predictions. The standard architecture usually follows this pattern:\n",
    "\n",
    "    - Input Layer\n",
    "Receives the raw pixel values of the image, often normalised (e.g., values between 0 and 1).\n",
    "\n",
    "    - Convolutional Layers\n",
    "Apply multiple filters to the input image to detect low-level features like edges, corners, and textures. Deeper layers detect more complex patterns like shapes or objects.\n",
    "\n",
    "    - Activation Layers (usually ReLU)\n",
    "Applied immediately after convolution to introduce non-linearity, allowing the network to learn complex relationships.\n",
    "\n",
    "    - Pooling Layers (typically Max Pooling)\n",
    "Reduce the spatial dimensions of the feature maps, keeping the most important information while decreasing the computational load.\n",
    "\n",
    "    - (Optional) Additional Convolutional and Pooling Blocks\n",
    "Several convolution-pooling pairs are often stacked to allow the network to learn increasingly abstract and complex features at different levels.\n",
    "\n",
    "    - Flatten Layer\n",
    "Flattens the output of the final pooling layer into a 1D vector to prepare it for the fully-connected layers.\n",
    "\n",
    "    - Fully-Connected (Dense) Layers\n",
    "Combine the features learned by the convolutional layers to make predictions. These layers behave like traditional neural networks.\n",
    "\n",
    "    - Dropout Layer (often added before or between dense layers)\n",
    "Randomly drops some neurons during training to prevent overfitting and improve generalisation.\n",
    "\n",
    "    - Output Layer (typically Softmax for classification tasks)\n",
    "Produces the final prediction by outputting a probability distribution over all target classes.\n",
    "\n",
    "\n",
    "\n",
    "- Convolutional Layer\n",
    "Applies a set of filters (small matrices like 3×3 or 5×5) over the input image to detect low-level features such as edges, textures, and patterns.\n",
    "\n",
    "- Activation Function (ReLU)\n",
    "Introduces non-linearity into the model by replacing negative values with zero, allowing the network to model complex patterns.\n",
    "\n",
    "- Pooling Layer\n",
    "Reduces the spatial dimensions (width and height) of feature maps, keeping the most important information while making the model faster and more robust.\n",
    "\n",
    "- Flattening\n",
    "Converts the 2D feature maps output by convolutional and pooling layers into a 1D vector to be used by fully-connected layers.\n",
    "\n",
    "- Fully-Connected (Dense) Layer\n",
    "A traditional neural network layer where each neuron connects to every neuron in the next layer, used for combining extracted features and making final predictions.\n",
    "\n",
    "- Dropout Layer\n",
    "A regularisation technique that randomly disables a fraction of neurons during training to prevent the model from overfitting the training data.\n",
    "\n",
    "- Softmax Layer\n",
    "The final output layer for multi-class classification that converts raw model outputs into probabilities across all classes, ensuring they sum to 1.\n",
    "\n",
    "- Data Preprocessing\n",
    "Preparing raw input data before feeding it into the model, such as scaling pixel values between 0 and 1 to improve training stability and performance.\n",
    "\n",
    "- Model Training\n",
    "The phase where the CNN learns from data by adjusting its internal parameters using optimisation algorithms and loss functions.\n",
    "\n",
    "- Model Evaluation\n",
    "Assessing the trained model’s performance on new, unseen data to measure how accurately it generalises, using metrics like accuracy or confusion matrices.\n",
    "\n",
    "### Convolutional Block\n",
    "A convolutional block is a repeated structure inside a CNN that groups several key operations together. Instead of treating each layer separately, CNNs often bundle them into blocks to form a more organised and powerful model.\n",
    "\n",
    "A typical convolutional block includes:\n",
    "\n",
    "One or more Convolutional Layers\n",
    "Apply filters to detect patterns from the input or from previous layers.\n",
    "\n",
    "Activation Function (usually ReLU)\n",
    "Introduces non-linearity immediately after each convolution, enabling the network to learn complex features.\n",
    "\n",
    "Pooling Layer (usually Max Pooling)\n",
    "Reduces the spatial size after convolution and activation, keeping only the most important information.\n",
    "\n",
    "(Optional) Batch Normalisation\n",
    "Sometimes added between convolution and activation to stabilise and speed up training by normalising outputs.\n",
    "\n",
    "- **Epoch**\n",
    "    - An epoch is one complete pass of the entire training dataset through the model. During each epoch, the model looks at all the layers in the neural network and processes the data step by step.\n",
    "\n",
    "    - The model uses its layers to make predictions, then compares them to the actual answers. Based on the differences (errors), it adjusts the settings (weights) inside the layers.\n",
    "\n",
    "    - With each epoch, the model learns more about the patterns in the data and gets better at making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69600 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Paths\n",
    "data_dir = '../dataset/asl_alphabet_train'\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,  # 20% for validation\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Training generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67712</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">17,334,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,453</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67712\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m17,334,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │         \u001b[38;5;34m7,453\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,436,765</span> (66.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,436,765\u001b[0m (66.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,436,765</span> (66.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,436,765\u001b[0m (66.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential([\n",
    "    # Block 1\n",
    "    Input(shape=(200, 200, 3)),  # Explicit Input layer\n",
    "    Conv2D(32, (5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    # Block 2\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    # Block 3\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    # Flatten and Dense layers\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Output layer\n",
    "    Dense(29, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Early Stopping Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    patience=3,              # Stop after 3 epochs without improvement\n",
    "    restore_best_weights=True  # Keep the best model weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.2288 - loss: 2.6480"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19101s\u001b[0m 9s/step - accuracy: 0.2289 - loss: 2.6477 - val_accuracy: 0.5495 - val_loss: 1.3226\n",
      "Epoch 2/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 350ms/step - accuracy: 0.6369 - loss: 1.0819 - val_accuracy: 0.6314 - val_loss: 1.0694\n",
      "Epoch 3/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 350ms/step - accuracy: 0.7580 - loss: 0.7090 - val_accuracy: 0.7266 - val_loss: 0.8369\n",
      "Epoch 4/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1251s\u001b[0m 575ms/step - accuracy: 0.8114 - loss: 0.5464 - val_accuracy: 0.7637 - val_loss: 0.7704\n",
      "Epoch 5/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3264s\u001b[0m 2s/step - accuracy: 0.8499 - loss: 0.4441 - val_accuracy: 0.7723 - val_loss: 0.7978\n",
      "Epoch 6/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3729s\u001b[0m 2s/step - accuracy: 0.8664 - loss: 0.3907 - val_accuracy: 0.7832 - val_loss: 0.7248\n",
      "Epoch 7/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3675s\u001b[0m 2s/step - accuracy: 0.8866 - loss: 0.3384 - val_accuracy: 0.7861 - val_loss: 0.7548\n",
      "Epoch 8/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3681s\u001b[0m 2s/step - accuracy: 0.8972 - loss: 0.3077 - val_accuracy: 0.8039 - val_loss: 0.6125\n",
      "Epoch 9/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3684s\u001b[0m 2s/step - accuracy: 0.9079 - loss: 0.2812 - val_accuracy: 0.8150 - val_loss: 0.6305\n",
      "Epoch 10/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2625s\u001b[0m 1s/step - accuracy: 0.9133 - loss: 0.2588 - val_accuracy: 0.7972 - val_loss: 0.7931\n",
      "Epoch 11/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 380ms/step - accuracy: 0.9183 - loss: 0.2426 - val_accuracy: 0.8105 - val_loss: 0.7537\n",
      "Epoch 12/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m768s\u001b[0m 353ms/step - accuracy: 0.9259 - loss: 0.2260 - val_accuracy: 0.8439 - val_loss: 0.5940\n",
      "Epoch 13/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 343ms/step - accuracy: 0.9270 - loss: 0.2210 - val_accuracy: 0.7921 - val_loss: 0.7395\n",
      "Epoch 14/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 365ms/step - accuracy: 0.9307 - loss: 0.2129 - val_accuracy: 0.8220 - val_loss: 0.7267\n",
      "Epoch 15/30\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 354ms/step - accuracy: 0.9295 - loss: 0.2142 - val_accuracy: 0.8333 - val_loss: 0.6481\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data with validation and early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added BatchNormalization after each convolutional and dense layer to stabilize learning and improve validation accuracy.\n",
    "\n",
    "Added L2 Regularization (0.001) to prevent overfitting by penalizing large weights.\n",
    "\n",
    "Replaced Flatten with GlobalAveragePooling2D to drastically reduce parameters (will drop from 17M to under 500K).\n",
    "\n",
    "Enhanced data augmentation with wider rotation range and brightness variations to improve generalization.\n",
    "\n",
    "Added learning rate scheduler (ReduceLROnPlateau) to automatically reduce learning rate when validation loss plateaus.\n",
    "\n",
    "Slightly reduced dropout from 0.5 to 0.4 as we're now using multiple regularization techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Input layer\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "\n",
    "# Block 1\n",
    "x = Conv2D(32, (5, 5), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
    "\n",
    "# Global Average Pooling instead of Flatten\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Dense layer with regularization\n",
    "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)  # Slightly reduced dropout\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,453</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m2,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │         \u001b[38;5;34m7,453\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">137,181</span> (535.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m137,181\u001b[0m (535.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,221</span> (532.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m136,221\u001b[0m (532.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enhanced data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,       # Increased rotation range\n",
    "    width_shift_range=0.2,   # Increased shift range\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,          # Increased zoom range\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2]  # Add brightness variation\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3273 - loss: 2.6823"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8726s\u001b[0m 4s/step - accuracy: 0.3274 - loss: 2.6819 - val_accuracy: 0.4804 - val_loss: 2.0926 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2700s\u001b[0m 1s/step - accuracy: 0.8114 - loss: 0.8406 - val_accuracy: 0.5552 - val_loss: 2.1284 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2429s\u001b[0m 1s/step - accuracy: 0.8923 - loss: 0.5699 - val_accuracy: 0.5525 - val_loss: 2.1868 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1441s\u001b[0m 662ms/step - accuracy: 0.9605 - loss: 0.3628 - val_accuracy: 0.8349 - val_loss: 0.8209 - learning_rate: 2.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2707s\u001b[0m 1s/step - accuracy: 0.9744 - loss: 0.2758 - val_accuracy: 0.8337 - val_loss: 0.8827 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1538s\u001b[0m 707ms/step - accuracy: 0.9781 - loss: 0.2327 - val_accuracy: 0.8630 - val_loss: 0.6409 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1986s\u001b[0m 892ms/step - accuracy: 0.9790 - loss: 0.2099 - val_accuracy: 0.8185 - val_loss: 0.9283 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1733s\u001b[0m 797ms/step - accuracy: 0.9815 - loss: 0.1871 - val_accuracy: 0.8721 - val_loss: 0.6304 - learning_rate: 2.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2811s\u001b[0m 1s/step - accuracy: 0.9829 - loss: 0.1719 - val_accuracy: 0.8326 - val_loss: 0.9486 - learning_rate: 2.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2152s\u001b[0m 990ms/step - accuracy: 0.9823 - loss: 0.1644 - val_accuracy: 0.8201 - val_loss: 0.9389 - learning_rate: 2.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2295s\u001b[0m 1s/step - accuracy: 0.9899 - loss: 0.1373 - val_accuracy: 0.8750 - val_loss: 0.7106 - learning_rate: 4.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2669s\u001b[0m 1s/step - accuracy: 0.9939 - loss: 0.1223 - val_accuracy: 0.8830 - val_loss: 0.6633 - learning_rate: 4.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2459s\u001b[0m 1s/step - accuracy: 0.9946 - loss: 0.1162 - val_accuracy: 0.8843 - val_loss: 0.6723 - learning_rate: 1.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1495s\u001b[0m 688ms/step - accuracy: 0.9958 - loss: 0.1122 - val_accuracy: 0.8864 - val_loss: 0.6427 - learning_rate: 1.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1855s\u001b[0m 853ms/step - accuracy: 0.9946 - loss: 0.1142 - val_accuracy: 0.8868 - val_loss: 0.6730 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2121s\u001b[0m 975ms/step - accuracy: 0.9953 - loss: 0.1109 - val_accuracy: 0.8845 - val_loss: 0.6758 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1319s\u001b[0m 606ms/step - accuracy: 0.9951 - loss: 0.1092 - val_accuracy: 0.8824 - val_loss: 0.6900 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2795s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.1082 - val_accuracy: 0.8874 - val_loss: 0.6366 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3347s\u001b[0m 2s/step - accuracy: 0.9964 - loss: 0.1046 - val_accuracy: 0.8833 - val_loss: 0.6905 - learning_rate: 1.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3323s\u001b[0m 2s/step - accuracy: 0.9960 - loss: 0.1041 - val_accuracy: 0.8870 - val_loss: 0.6818 - learning_rate: 1.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3338s\u001b[0m 2s/step - accuracy: 0.9949 - loss: 0.1044 - val_accuracy: 0.8883 - val_loss: 0.6614 - learning_rate: 1.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3356s\u001b[0m 2s/step - accuracy: 0.9960 - loss: 0.1012 - val_accuracy: 0.8867 - val_loss: 0.6567 - learning_rate: 1.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2081s\u001b[0m 951ms/step - accuracy: 0.9960 - loss: 0.1004 - val_accuracy: 0.8849 - val_loss: 0.6684 - learning_rate: 1.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3291s\u001b[0m 1s/step - accuracy: 0.9962 - loss: 0.0992 - val_accuracy: 0.8884 - val_loss: 0.6475 - learning_rate: 1.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3139s\u001b[0m 1s/step - accuracy: 0.9964 - loss: 0.0979 - val_accuracy: 0.8860 - val_loss: 0.6472 - learning_rate: 1.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2225s\u001b[0m 1s/step - accuracy: 0.9966 - loss: 0.0963 - val_accuracy: 0.8873 - val_loss: 0.6420 - learning_rate: 1.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m965s\u001b[0m 444ms/step - accuracy: 0.9962 - loss: 0.0966 - val_accuracy: 0.8921 - val_loss: 0.6653 - learning_rate: 1.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m961s\u001b[0m 442ms/step - accuracy: 0.9962 - loss: 0.0949 - val_accuracy: 0.8902 - val_loss: 0.6897 - learning_rate: 1.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m980s\u001b[0m 450ms/step - accuracy: 0.9962 - loss: 0.0938 - val_accuracy: 0.8897 - val_loss: 0.6797 - learning_rate: 1.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1814s\u001b[0m 834ms/step - accuracy: 0.9967 - loss: 0.0923 - val_accuracy: 0.8878 - val_loss: 0.7016 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Compile with the same optimizer but add metrics\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train with both callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,  # Increased epochs since we have early stopping\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        reduce_lr\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three convolutional blocks with increasing filter complexity (32→64→128)\n",
    "\n",
    "Spatial dropout (dropping entire feature maps) after each conv block to reduce overfitting\n",
    "\n",
    "L2 regularization (0.002) on all convolutional and dense layers\n",
    "\n",
    "BatchNormalization after each convolution for faster, more stable training\n",
    "\n",
    "GlobalAveragePooling2D instead of Flatten to drastically reduce parameters\n",
    "\n",
    "Enhanced training process with learning rate scheduling and strong data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69600 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │         \u001b[38;5;34m3,741\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,909</span> (448.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,909\u001b[0m (448.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,205</span> (446.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,205\u001b[0m (446.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Enhanced data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,       # Increased rotation range\n",
    "    width_shift_range=0.2,   # Increased shift range\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,          # Increased zoom range\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],  # Brightness variation\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Define paths and image dimensions\n",
    "data_dir = '../dataset/asl_alphabet_train'  # Adjust if needed\n",
    "img_height, img_width = 200, 200\n",
    "batch_size = 32\n",
    "num_classes = 29  # A-Z plus SPACE, DELETE, NOTHING\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Build the improved model with Functional API\n",
    "inputs = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "# Block 1\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.002))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.002))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.002))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Global Average Pooling instead of Flatten (drastically reduces parameters)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Dense layers with regularization\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.002))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,  # Slightly increased patience\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "epochs = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 179ms/step - accuracy: 0.1088 - loss: 3.8525 - val_accuracy: 0.1821 - val_loss: 3.1428 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 157ms/step - accuracy: 0.3759 - loss: 2.2342 - val_accuracy: 0.5389 - val_loss: 1.6321 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 174ms/step - accuracy: 0.5659 - loss: 1.6142 - val_accuracy: 0.6530 - val_loss: 1.2374 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 160ms/step - accuracy: 0.6586 - loss: 1.3460 - val_accuracy: 0.7352 - val_loss: 1.0995 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 152ms/step - accuracy: 0.7015 - loss: 1.2375 - val_accuracy: 0.6926 - val_loss: 1.2445 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 154ms/step - accuracy: 0.7311 - loss: 1.1533 - val_accuracy: 0.7479 - val_loss: 1.0229 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 151ms/step - accuracy: 0.7493 - loss: 1.1034 - val_accuracy: 0.7164 - val_loss: 1.1756 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 150ms/step - accuracy: 0.7623 - loss: 1.0606 - val_accuracy: 0.6666 - val_loss: 1.3904 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 152ms/step - accuracy: 0.7727 - loss: 1.0361 - val_accuracy: 0.7939 - val_loss: 1.0142 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 153ms/step - accuracy: 0.7752 - loss: 1.0215 - val_accuracy: 0.7903 - val_loss: 0.9398 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 153ms/step - accuracy: 0.7855 - loss: 0.9954 - val_accuracy: 0.8278 - val_loss: 0.8406 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 155ms/step - accuracy: 0.7916 - loss: 0.9740 - val_accuracy: 0.8197 - val_loss: 0.8864 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 150ms/step - accuracy: 0.7956 - loss: 0.9709 - val_accuracy: 0.7615 - val_loss: 1.0717 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 145ms/step - accuracy: 0.8034 - loss: 0.9474 - val_accuracy: 0.8156 - val_loss: 0.9525 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 210ms/step - accuracy: 0.8538 - loss: 0.7768 - val_accuracy: 0.8708 - val_loss: 0.6971 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 177ms/step - accuracy: 0.8762 - loss: 0.6540 - val_accuracy: 0.8873 - val_loss: 0.6184 - learning_rate: 2.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 175ms/step - accuracy: 0.8823 - loss: 0.6061 - val_accuracy: 0.8966 - val_loss: 0.5316 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 176ms/step - accuracy: 0.8878 - loss: 0.5672 - val_accuracy: 0.8936 - val_loss: 0.5541 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 176ms/step - accuracy: 0.8939 - loss: 0.5370 - val_accuracy: 0.8947 - val_loss: 0.5178 - learning_rate: 2.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 176ms/step - accuracy: 0.8932 - loss: 0.5253 - val_accuracy: 0.8707 - val_loss: 0.5922 - learning_rate: 2.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 176ms/step - accuracy: 0.8950 - loss: 0.5113 - val_accuracy: 0.8756 - val_loss: 0.5934 - learning_rate: 2.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 178ms/step - accuracy: 0.8960 - loss: 0.5048 - val_accuracy: 0.8775 - val_loss: 0.5495 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# To train the model, run:\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double Convolution in Each Block:\n",
    "\n",
    "Added two consecutive 3×3 convolutions in each block instead of a single layer\n",
    "\n",
    "This creates a deeper feature hierarchy while keeping the parameter count low\n",
    "\n",
    "Residual Connection in Block 3:\n",
    "\n",
    "Added a skip connection that helps with gradient flow during backpropagation\n",
    "\n",
    "Improves learning of complex features without increasing depth excessively\n",
    "\n",
    "Increased Regularization:\n",
    "\n",
    "L2 regularization increased to 0.0015 from 0.001\n",
    "\n",
    "Progressive SpatialDropout2D (0.1→0.15→0.2) to increasingly regularize deeper features\n",
    "\n",
    "BatchNormalization After Every Conv Layer:\n",
    "\n",
    "Stabilizes training and accelerates convergence\n",
    "\n",
    "Reduces internal covariate shift between layers\n",
    "\n",
    "Smaller Initial Filter Size:\n",
    "\n",
    "Using 3×3 filters throughout (instead of 5×5) reduces parameters while maintaining receptive field through stacking\n",
    "\n",
    "GlobalAveragePooling2D:\n",
    "\n",
    "Retained from your current model to drastically reduce parameters compared to Flatten\n",
    "\n",
    "Provides some built-in regularization by averaging features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Input layer\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "\n",
    "# Block 1 - Initial Feature Extraction\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0015))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0015))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Block 2 - Intermediate Features\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0015))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0015))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = SpatialDropout2D(0.15)(x)\n",
    "\n",
    "# Block 3 - Advanced Features with Residual Connection\n",
    "x_shortcut = Conv2D(128, (1, 1), padding='same')(x)  # Shortcut connection\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0015))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.0015))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Add()([x, x_shortcut])  # Add residual connection\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = SpatialDropout2D(0.2)(x)\n",
    "\n",
    "# Global Average Pooling instead of Flatten\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Dense layers with regularization\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.002))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_9 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_10… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_11… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_9 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_9[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_10… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_11… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m3,741\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">317,885</span> (1.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m317,885\u001b[0m (1.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">316,733</span> (1.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m316,733\u001b[0m (1.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enhanced data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=6,  # Slightly increased patience\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Compile with Adam optimizer\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 187ms/step - accuracy: 0.1309 - loss: 3.9067 - val_accuracy: 0.3075 - val_loss: 2.4240 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 176ms/step - accuracy: 0.5154 - loss: 1.8418 - val_accuracy: 0.6754 - val_loss: 1.5014 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 177ms/step - accuracy: 0.7417 - loss: 1.1988 - val_accuracy: 0.8504 - val_loss: 0.8814 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 176ms/step - accuracy: 0.8054 - loss: 1.0085 - val_accuracy: 0.8254 - val_loss: 0.9695 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 176ms/step - accuracy: 0.8255 - loss: 0.9417 - val_accuracy: 0.6887 - val_loss: 1.4186 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 174ms/step - accuracy: 0.8410 - loss: 0.8896 - val_accuracy: 0.8230 - val_loss: 0.9528 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 170ms/step - accuracy: 0.9014 - loss: 0.6703 - val_accuracy: 0.9193 - val_loss: 0.5169 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 171ms/step - accuracy: 0.9257 - loss: 0.5035 - val_accuracy: 0.9436 - val_loss: 0.3988 - learning_rate: 2.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 176ms/step - accuracy: 0.9337 - loss: 0.4383 - val_accuracy: 0.9213 - val_loss: 0.4466 - learning_rate: 2.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 176ms/step - accuracy: 0.9350 - loss: 0.4102 - val_accuracy: 0.9295 - val_loss: 0.3886 - learning_rate: 2.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 178ms/step - accuracy: 0.9389 - loss: 0.3778 - val_accuracy: 0.9167 - val_loss: 0.4902 - learning_rate: 2.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 175ms/step - accuracy: 0.9404 - loss: 0.3633 - val_accuracy: 0.9328 - val_loss: 0.3828 - learning_rate: 2.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 175ms/step - accuracy: 0.9457 - loss: 0.3381 - val_accuracy: 0.9330 - val_loss: 0.4009 - learning_rate: 2.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 174ms/step - accuracy: 0.9448 - loss: 0.3364 - val_accuracy: 0.9280 - val_loss: 0.3898 - learning_rate: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-Attention Mechanism: Added lightweight spatial attention to focus on the most informative regions of hand gestures.\n",
    "\n",
    "Residual Blocks Throughout: Now using residual connections in all blocks to improve gradient flow, enabling deeper feature learning without vanishing gradients.\n",
    "\n",
    "Enhanced Data Augmentation: Added shear transforms and channel shifts to make the model more robust to variations in lighting and hand positioning.\n",
    "\n",
    "Layer Normalization: Added after global pooling to stabilize feature distributions before classification.\n",
    "\n",
    "Cyclic Learning Rate Option: Alternative learning rate scheduler that can help escape local minima.\n",
    "\n",
    "Stronger Regularization: Slightly increased L2 regularization (0.0018 vs 0.0015) to further prevent overfitting.\n",
    "\n",
    "Increased Training Duration: More epochs (75) with longer early stopping patience (8) gives the model time to find more optimal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m132\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │         \u001b[38;5;34m16\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m5\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m1,056\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m2,112\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m) │        \u001b[38;5;34m520\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m) │         \u001b[38;5;34m32\u001b[0m │ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m9\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m4,160\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m64\u001b[0m)               │            │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m2,064\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │         \u001b[38;5;34m64\u001b[0m │ conv2d_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │         \u001b[38;5;34m17\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ activation_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │      \u001b[38;5;34m2,064\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │         \u001b[38;5;34m64\u001b[0m │ conv2d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m1\u001b[0m) │         \u001b[38;5;34m17\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │     \u001b[38;5;34m16,512\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m256\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m3,741\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">747,337</span> (2.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m747,337\u001b[0m (2.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">744,305</span> (2.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m744,305\u001b[0m (2.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,032</span> (11.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,032\u001b[0m (11.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Reshape, Permute\n",
    "from tensorflow.keras.layers import LayerNormalization, Activation\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Enhanced data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.1,\n",
    "    channel_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Define a simple self-attention module\n",
    "def self_attention_block(inputs, filters):\n",
    "    # Spatial attention\n",
    "    x = Conv2D(filters//8, kernel_size=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Generate attention map\n",
    "    attention = Conv2D(1, kernel_size=1)(x)\n",
    "    attention = Activation('sigmoid')(attention)\n",
    "    \n",
    "    # Apply attention\n",
    "    return Multiply()([inputs, attention])\n",
    "\n",
    "# Residual block with attention\n",
    "def residual_block(inputs, filters, kernel_size=3, strides=1, attention=True):\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same', \n",
    "               kernel_regularizer=l2(0.0018))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same',\n",
    "               kernel_regularizer=l2(0.0018))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Add attention if requested\n",
    "    if attention:\n",
    "        x = self_attention_block(x, filters)\n",
    "    \n",
    "    # Handle input shape mismatch for the residual connection\n",
    "    if strides > 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Cyclic learning rate scheduler\n",
    "def cyclic_lr(epoch):\n",
    "    initial_lr = 0.001\n",
    "    max_lr = 0.01\n",
    "    step_size = 10.0\n",
    "    \n",
    "    cycle = math.floor(1 + epoch / (2 * step_size))\n",
    "    x = abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = initial_lr + (max_lr - initial_lr) * max(0, (1 - x))\n",
    "    return lr\n",
    "\n",
    "# Build enhanced model\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "\n",
    "# Initial convolution\n",
    "x = Conv2D(32, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(0.0018))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Block 1 with residual connections\n",
    "x = residual_block(x, 32, strides=1, attention=False)\n",
    "x = residual_block(x, 32, strides=2, attention=True)  # Downsample\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Block 2 with residual connections\n",
    "x = residual_block(x, 64, strides=1, attention=False)\n",
    "x = residual_block(x, 64, strides=2, attention=True)  # Downsample\n",
    "x = SpatialDropout2D(0.15)(x)\n",
    "\n",
    "# Block 3 with residual connections and attention\n",
    "x = residual_block(x, 128, strides=1, attention=True)\n",
    "x = residual_block(x, 128, strides=2, attention=True)  # Downsample\n",
    "x = SpatialDropout2D(0.2)(x)\n",
    "\n",
    "# Global pooling and feature normalization\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "# Classification head\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.0025))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile with a slightly lower initial learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 204ms/step - accuracy: 0.0708 - loss: 5.1761 - val_accuracy: 0.2021 - val_loss: 3.1875 - learning_rate: 5.0000e-04\n",
      "Epoch 2/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 209ms/step - accuracy: 0.2788 - loss: 2.8158 - val_accuracy: 0.1707 - val_loss: 4.6165 - learning_rate: 5.0000e-04\n",
      "Epoch 3/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 212ms/step - accuracy: 0.6042 - loss: 1.5760 - val_accuracy: 0.7372 - val_loss: 1.2008 - learning_rate: 5.0000e-04\n",
      "Epoch 4/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 210ms/step - accuracy: 0.7650 - loss: 1.0814 - val_accuracy: 0.8210 - val_loss: 0.9039 - learning_rate: 5.0000e-04\n",
      "Epoch 5/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 208ms/step - accuracy: 0.8287 - loss: 0.8740 - val_accuracy: 0.7673 - val_loss: 1.1226 - learning_rate: 5.0000e-04\n",
      "Epoch 6/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 208ms/step - accuracy: 0.8656 - loss: 0.7537 - val_accuracy: 0.8266 - val_loss: 0.7976 - learning_rate: 5.0000e-04\n",
      "Epoch 7/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 208ms/step - accuracy: 0.8816 - loss: 0.6854 - val_accuracy: 0.8979 - val_loss: 0.6561 - learning_rate: 5.0000e-04\n",
      "Epoch 8/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 208ms/step - accuracy: 0.8910 - loss: 0.6487 - val_accuracy: 0.9333 - val_loss: 0.4820 - learning_rate: 5.0000e-04\n",
      "Epoch 9/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 208ms/step - accuracy: 0.8990 - loss: 0.6142 - val_accuracy: 0.9423 - val_loss: 0.4561 - learning_rate: 5.0000e-04\n",
      "Epoch 10/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 208ms/step - accuracy: 0.9075 - loss: 0.5773 - val_accuracy: 0.8760 - val_loss: 0.6713 - learning_rate: 5.0000e-04\n",
      "Epoch 11/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 208ms/step - accuracy: 0.9115 - loss: 0.5568 - val_accuracy: 0.9389 - val_loss: 0.4838 - learning_rate: 5.0000e-04\n",
      "Epoch 12/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 209ms/step - accuracy: 0.9146 - loss: 0.5413 - val_accuracy: 0.9524 - val_loss: 0.4146 - learning_rate: 5.0000e-04\n",
      "Epoch 13/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 204ms/step - accuracy: 0.9201 - loss: 0.5190 - val_accuracy: 0.9571 - val_loss: 0.3934 - learning_rate: 5.0000e-04\n",
      "Epoch 14/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 204ms/step - accuracy: 0.9235 - loss: 0.5037 - val_accuracy: 0.8661 - val_loss: 0.7883 - learning_rate: 5.0000e-04\n",
      "Epoch 15/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 204ms/step - accuracy: 0.9223 - loss: 0.5064 - val_accuracy: 0.9626 - val_loss: 0.3738 - learning_rate: 5.0000e-04\n",
      "Epoch 16/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 205ms/step - accuracy: 0.9253 - loss: 0.4881 - val_accuracy: 0.9417 - val_loss: 0.4221 - learning_rate: 5.0000e-04\n",
      "Epoch 17/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 211ms/step - accuracy: 0.9281 - loss: 0.4756 - val_accuracy: 0.9471 - val_loss: 0.4018 - learning_rate: 5.0000e-04\n",
      "Epoch 18/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 206ms/step - accuracy: 0.9332 - loss: 0.4595 - val_accuracy: 0.9291 - val_loss: 0.4507 - learning_rate: 5.0000e-04\n",
      "Epoch 19/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 206ms/step - accuracy: 0.9578 - loss: 0.3670 - val_accuracy: 0.9745 - val_loss: 0.2738 - learning_rate: 1.0000e-04\n",
      "Epoch 20/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 207ms/step - accuracy: 0.9690 - loss: 0.3015 - val_accuracy: 0.9741 - val_loss: 0.2492 - learning_rate: 1.0000e-04\n",
      "Epoch 21/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 206ms/step - accuracy: 0.9707 - loss: 0.2674 - val_accuracy: 0.9834 - val_loss: 0.2097 - learning_rate: 1.0000e-04\n",
      "Epoch 22/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 206ms/step - accuracy: 0.9719 - loss: 0.2477 - val_accuracy: 0.9696 - val_loss: 0.2432 - learning_rate: 1.0000e-04\n",
      "Epoch 23/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 206ms/step - accuracy: 0.9732 - loss: 0.2270 - val_accuracy: 0.9822 - val_loss: 0.1855 - learning_rate: 1.0000e-04\n",
      "Epoch 24/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 206ms/step - accuracy: 0.9744 - loss: 0.2142 - val_accuracy: 0.9833 - val_loss: 0.1730 - learning_rate: 1.0000e-04\n",
      "Epoch 25/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 206ms/step - accuracy: 0.9742 - loss: 0.2072 - val_accuracy: 0.9717 - val_loss: 0.1933 - learning_rate: 1.0000e-04\n",
      "Epoch 26/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 206ms/step - accuracy: 0.9752 - loss: 0.1946 - val_accuracy: 0.9829 - val_loss: 0.1616 - learning_rate: 1.0000e-04\n",
      "Epoch 27/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 206ms/step - accuracy: 0.9760 - loss: 0.1863 - val_accuracy: 0.9805 - val_loss: 0.1662 - learning_rate: 1.0000e-04\n",
      "Epoch 28/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 206ms/step - accuracy: 0.9746 - loss: 0.1883 - val_accuracy: 0.9674 - val_loss: 0.2287 - learning_rate: 1.0000e-04\n",
      "Epoch 29/75\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 207ms/step - accuracy: 0.9770 - loss: 0.1757 - val_accuracy: 0.9808 - val_loss: 0.1552 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks with both cyclic LR and reduce on plateau for flexibility\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=8,  # Increased patience to allow learning more complex patterns\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Option 1: Use cyclic learning rate\n",
    "lr_scheduler = LearningRateScheduler(cyclic_lr)\n",
    "\n",
    "# Choose which LR strategy to use:\n",
    "# callbacks = [early_stopping, lr_scheduler]  # Cyclic LR\n",
    "callbacks = [early_stopping, reduce_lr]     # Reduce on plateau\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=75,  # Increased epochs with reliable early stopping\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class A: 1800 training, 600 validation, 600 test images\n",
      "Class K: 1800 training, 600 validation, 600 test images\n",
      "Class C: 1800 training, 600 validation, 600 test images\n",
      "Class W: 1800 training, 600 validation, 600 test images\n",
      "Class del: 1800 training, 600 validation, 600 test images\n",
      "Class I: 1800 training, 600 validation, 600 test images\n",
      "Class X: 1800 training, 600 validation, 600 test images\n",
      "Class G: 1800 training, 600 validation, 600 test images\n",
      "Class U: 1800 training, 600 validation, 600 test images\n",
      "Class S: 1800 training, 600 validation, 600 test images\n",
      "Class Y: 1800 training, 600 validation, 600 test images\n",
      "Class nothing: 1800 training, 600 validation, 600 test images\n",
      "Class R: 1800 training, 600 validation, 600 test images\n",
      "Class B: 1800 training, 600 validation, 600 test images\n",
      "Class P: 1800 training, 600 validation, 600 test images\n",
      "Class Q: 1800 training, 600 validation, 600 test images\n",
      "Class space: 1800 training, 600 validation, 600 test images\n",
      "Class T: 1800 training, 600 validation, 600 test images\n",
      "Class H: 1800 training, 600 validation, 600 test images\n",
      "Class D: 1800 training, 600 validation, 600 test images\n",
      "Class V: 1800 training, 600 validation, 600 test images\n",
      "Class N: 1800 training, 600 validation, 600 test images\n",
      "Class O: 1800 training, 600 validation, 600 test images\n",
      "Class F: 1800 training, 600 validation, 600 test images\n",
      "Class M: 1800 training, 600 validation, 600 test images\n",
      "Class L: 1800 training, 600 validation, 600 test images\n",
      "Class Z: 1800 training, 600 validation, 600 test images\n",
      "Class J: 1800 training, 600 validation, 600 test images\n",
      "Class E: 1800 training, 600 validation, 600 test images\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define dataset paths\n",
    "original_dataset_dir = '../dataset/asl_alphabet_train'  # Path to your original dataset\n",
    "base_dir = '../dataset/asl_split'  # Directory to store the split datasets\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Create train, validation, and test directories\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Get all class folders\n",
    "classes = os.listdir(original_dataset_dir)\n",
    "\n",
    "# Create class directories and split data\n",
    "for cls in classes:\n",
    "    # Create class directories\n",
    "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
    "    \n",
    "    # Get all images in the class\n",
    "    class_path = os.path.join(original_dataset_dir, cls)\n",
    "    images = [img for img in os.listdir(class_path) if img.endswith(('.jpg'))]\n",
    "    \n",
    "    # First split: separate train+val from test (80/20)\n",
    "    train_val_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Second split: separate train from validation (75/25 of the 80% train+val)\n",
    "    # This gives approx. 60% train, 20% validation, 20% test overall\n",
    "    train_images, val_images = train_test_split(train_val_images, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Copy images to respective directories\n",
    "    for img in train_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(train_dir, cls, img)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    for img in val_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(val_dir, cls, img)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    for img in test_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(test_dir, cls, img)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    print(f\"Class {cls}: {len(train_images)} training, {len(val_images)} validation, {len(test_images)} test images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52200 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m132\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │         \u001b[38;5;34m16\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m5\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m1,056\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m2,112\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m) │        \u001b[38;5;34m520\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m) │         \u001b[38;5;34m32\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m9\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m4,160\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m64\u001b[0m)               │            │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m2,064\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │         \u001b[38;5;34m64\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │         \u001b[38;5;34m17\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ activation_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │      \u001b[38;5;34m2,064\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │         \u001b[38;5;34m64\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m1\u001b[0m) │         \u001b[38;5;34m17\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │     \u001b[38;5;34m16,512\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout2… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m256\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m3,741\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">747,337</span> (2.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m747,337\u001b[0m (2.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">744,305</span> (2.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m744,305\u001b[0m (2.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,032</span> (11.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,032\u001b[0m (11.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Reshape, Permute\n",
    "from tensorflow.keras.layers import LayerNormalization, Activation\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Enhanced data augmentation\n",
    "# Create separate generators for training, validation, and testing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest',\n",
    "    shear_range=0.1,\n",
    "    channel_shift_range=0.1\n",
    ")\n",
    "\n",
    "# Validation and test data should only be rescaled, not augmented\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Define a simple self-attention module\n",
    "def self_attention_block(inputs, filters):\n",
    "    # Spatial attention\n",
    "    x = Conv2D(filters//8, kernel_size=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Generate attention map\n",
    "    attention = Conv2D(1, kernel_size=1)(x)\n",
    "    attention = Activation('sigmoid')(attention)\n",
    "    \n",
    "    # Apply attention\n",
    "    return Multiply()([inputs, attention])\n",
    "\n",
    "# Residual block with attention\n",
    "def residual_block(inputs, filters, kernel_size=3, strides=1, attention=True):\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same', \n",
    "               kernel_regularizer=l2(0.0018))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same',\n",
    "               kernel_regularizer=l2(0.0018))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Add attention if requested\n",
    "    if attention:\n",
    "        x = self_attention_block(x, filters)\n",
    "    \n",
    "    # Handle input shape mismatch for the residual connection\n",
    "    if strides > 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Cyclic learning rate scheduler\n",
    "def cyclic_lr(epoch):\n",
    "    initial_lr = 0.001\n",
    "    max_lr = 0.01\n",
    "    step_size = 10.0\n",
    "    \n",
    "    cycle = math.floor(1 + epoch / (2 * step_size))\n",
    "    x = abs(epoch / step_size - 2 * cycle + 1)\n",
    "    lr = initial_lr + (max_lr - initial_lr) * max(0, (1 - x))\n",
    "    return lr\n",
    "\n",
    "# Build enhanced model\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "\n",
    "# Initial convolution\n",
    "x = Conv2D(32, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(0.0018))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Block 1 with residual connections\n",
    "x = residual_block(x, 32, strides=1, attention=False)\n",
    "x = residual_block(x, 32, strides=2, attention=True)  # Downsample\n",
    "x = SpatialDropout2D(0.1)(x)\n",
    "\n",
    "# Block 2 with residual connections\n",
    "x = residual_block(x, 64, strides=1, attention=False)\n",
    "x = residual_block(x, 64, strides=2, attention=True)  # Downsample\n",
    "x = SpatialDropout2D(0.15)(x)\n",
    "\n",
    "# Block 3 with residual connections and attention\n",
    "x = residual_block(x, 128, strides=1, attention=True)\n",
    "x = residual_block(x, 128, strides=2, attention=True)  # Downsample\n",
    "x = SpatialDropout2D(0.2)(x)\n",
    "\n",
    "# Global pooling and feature normalization\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "# Classification head\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.0025))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile with a slightly lower initial learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "\u001b[1m 694/1632\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 188ms/step - accuracy: 0.0441 - loss: 5.8735"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 220ms/step - accuracy: 0.0612 - loss: 5.4056 - val_accuracy: 0.2126 - val_loss: 3.2948 - learning_rate: 5.0000e-04\n",
      "Epoch 2/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 205ms/step - accuracy: 0.2534 - loss: 3.0839 - val_accuracy: 0.6294 - val_loss: 1.5605 - learning_rate: 5.0000e-04\n",
      "Epoch 3/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 213ms/step - accuracy: 0.5438 - loss: 1.8313 - val_accuracy: 0.6420 - val_loss: 1.4908 - learning_rate: 5.0000e-04\n",
      "Epoch 4/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 215ms/step - accuracy: 0.7124 - loss: 1.2717 - val_accuracy: 0.8737 - val_loss: 0.7743 - learning_rate: 5.0000e-04\n",
      "Epoch 5/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 212ms/step - accuracy: 0.7972 - loss: 1.0040 - val_accuracy: 0.8989 - val_loss: 0.6645 - learning_rate: 5.0000e-04\n",
      "Epoch 6/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 210ms/step - accuracy: 0.8378 - loss: 0.8603 - val_accuracy: 0.9642 - val_loss: 0.4765 - learning_rate: 5.0000e-04\n",
      "Epoch 7/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 211ms/step - accuracy: 0.8646 - loss: 0.7680 - val_accuracy: 0.9573 - val_loss: 0.4737 - learning_rate: 5.0000e-04\n",
      "Epoch 8/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 210ms/step - accuracy: 0.8780 - loss: 0.7135 - val_accuracy: 0.9475 - val_loss: 0.4877 - learning_rate: 5.0000e-04\n",
      "Epoch 9/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 210ms/step - accuracy: 0.8866 - loss: 0.6740 - val_accuracy: 0.9239 - val_loss: 0.5310 - learning_rate: 5.0000e-04\n",
      "Epoch 10/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 210ms/step - accuracy: 0.8970 - loss: 0.6365 - val_accuracy: 0.9795 - val_loss: 0.3628 - learning_rate: 5.0000e-04\n",
      "Epoch 11/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 210ms/step - accuracy: 0.9019 - loss: 0.6015 - val_accuracy: 0.9815 - val_loss: 0.3379 - learning_rate: 5.0000e-04\n",
      "Epoch 12/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 210ms/step - accuracy: 0.9050 - loss: 0.5915 - val_accuracy: 0.9803 - val_loss: 0.3527 - learning_rate: 5.0000e-04\n",
      "Epoch 13/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 210ms/step - accuracy: 0.9103 - loss: 0.5611 - val_accuracy: 0.9695 - val_loss: 0.3556 - learning_rate: 5.0000e-04\n",
      "Epoch 14/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9120 - loss: 0.5528 - val_accuracy: 0.9793 - val_loss: 0.3444 - learning_rate: 5.0000e-04\n",
      "Epoch 15/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 210ms/step - accuracy: 0.9464 - loss: 0.4390 - val_accuracy: 0.9988 - val_loss: 0.2431 - learning_rate: 1.0000e-04\n",
      "Epoch 16/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 210ms/step - accuracy: 0.9597 - loss: 0.3579 - val_accuracy: 0.9982 - val_loss: 0.2145 - learning_rate: 1.0000e-04\n",
      "Epoch 17/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 210ms/step - accuracy: 0.9637 - loss: 0.3247 - val_accuracy: 0.9987 - val_loss: 0.1906 - learning_rate: 1.0000e-04\n",
      "Epoch 18/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 209ms/step - accuracy: 0.9638 - loss: 0.2999 - val_accuracy: 0.9986 - val_loss: 0.1766 - learning_rate: 1.0000e-04\n",
      "Epoch 19/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 211ms/step - accuracy: 0.9654 - loss: 0.2806 - val_accuracy: 0.9979 - val_loss: 0.1668 - learning_rate: 1.0000e-04\n",
      "Epoch 20/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 209ms/step - accuracy: 0.9663 - loss: 0.2669 - val_accuracy: 0.9991 - val_loss: 0.1523 - learning_rate: 1.0000e-04\n",
      "Epoch 21/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9668 - loss: 0.2564 - val_accuracy: 0.9991 - val_loss: 0.1448 - learning_rate: 1.0000e-04\n",
      "Epoch 22/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 211ms/step - accuracy: 0.9657 - loss: 0.2504 - val_accuracy: 0.9991 - val_loss: 0.1378 - learning_rate: 1.0000e-04\n",
      "Epoch 23/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9698 - loss: 0.2294 - val_accuracy: 0.9989 - val_loss: 0.1323 - learning_rate: 1.0000e-04\n",
      "Epoch 24/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 211ms/step - accuracy: 0.9685 - loss: 0.2289 - val_accuracy: 0.9991 - val_loss: 0.1276 - learning_rate: 1.0000e-04\n",
      "Epoch 25/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 210ms/step - accuracy: 0.9704 - loss: 0.2212 - val_accuracy: 0.9995 - val_loss: 0.1217 - learning_rate: 1.0000e-04\n",
      "Epoch 26/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 209ms/step - accuracy: 0.9701 - loss: 0.2182 - val_accuracy: 0.9997 - val_loss: 0.1183 - learning_rate: 1.0000e-04\n",
      "Epoch 27/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9703 - loss: 0.2107 - val_accuracy: 0.9978 - val_loss: 0.1200 - learning_rate: 1.0000e-04\n",
      "Epoch 28/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 210ms/step - accuracy: 0.9704 - loss: 0.2085 - val_accuracy: 0.9994 - val_loss: 0.1121 - learning_rate: 1.0000e-04\n",
      "Epoch 29/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 209ms/step - accuracy: 0.9712 - loss: 0.2027 - val_accuracy: 0.9991 - val_loss: 0.1113 - learning_rate: 1.0000e-04\n",
      "Epoch 30/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9694 - loss: 0.2055 - val_accuracy: 0.9996 - val_loss: 0.1078 - learning_rate: 1.0000e-04\n",
      "Epoch 31/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9693 - loss: 0.2021 - val_accuracy: 0.9980 - val_loss: 0.1113 - learning_rate: 1.0000e-04\n",
      "Epoch 32/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 208ms/step - accuracy: 0.9722 - loss: 0.1951 - val_accuracy: 0.9997 - val_loss: 0.1046 - learning_rate: 1.0000e-04\n",
      "Epoch 33/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 208ms/step - accuracy: 0.9712 - loss: 0.1957 - val_accuracy: 0.9997 - val_loss: 0.1031 - learning_rate: 1.0000e-04\n",
      "Epoch 34/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9740 - loss: 0.1882 - val_accuracy: 0.9995 - val_loss: 0.1022 - learning_rate: 1.0000e-04\n",
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 52ms/step - accuracy: 0.9996 - loss: 0.1184\n",
      "Test accuracy: 0.9994\n",
      "Test loss: 0.1194\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks with both cyclic LR and reduce on plateau for flexibility\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=8,  # Increased patience to allow learning more complex patterns\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Option 1: Use cyclic learning rate\n",
    "lr_scheduler = LearningRateScheduler(cyclic_lr)\n",
    "\n",
    "# Choose which LR strategy to use:\n",
    "# callbacks = [early_stopping, lr_scheduler]  # Cyclic LR\n",
    "callbacks = [early_stopping, reduce_lr]     # Reduce on plateau\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=75,  # Increased epochs with reliable early stopping\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model.save('/home/adithya/projects/ASL-CNN-Project/models/asl_custom_cnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training for fold 1/5\n",
      "==================================================\n",
      "Creating symlinks for fold data...\n",
      "Found 41760 images belonging to 29 classes.\n",
      "Found 10440 images belonging to 29 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 202ms/step - accuracy: 0.0560 - loss: 5.5187 - val_accuracy: 0.1512 - val_loss: 3.7766 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 201ms/step - accuracy: 0.1952 - loss: 3.4853 - val_accuracy: 0.4835 - val_loss: 2.0740 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 205ms/step - accuracy: 0.4511 - loss: 2.1768 - val_accuracy: 0.6092 - val_loss: 1.5742 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 206ms/step - accuracy: 0.6543 - loss: 1.4825 - val_accuracy: 0.8489 - val_loss: 0.8771 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 208ms/step - accuracy: 0.7447 - loss: 1.1701 - val_accuracy: 0.9285 - val_loss: 0.6198 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 211ms/step - accuracy: 0.8029 - loss: 0.9781 - val_accuracy: 0.9305 - val_loss: 0.5881 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.8255 - loss: 0.9092 - val_accuracy: 0.9399 - val_loss: 0.5382 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 214ms/step - accuracy: 0.8531 - loss: 0.8247 - val_accuracy: 0.8190 - val_loss: 0.8675 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.8711 - loss: 0.7482 - val_accuracy: 0.8932 - val_loss: 0.6742 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 208ms/step - accuracy: 0.8799 - loss: 0.7208 - val_accuracy: 0.9744 - val_loss: 0.4131 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 208ms/step - accuracy: 0.8885 - loss: 0.6787 - val_accuracy: 0.9052 - val_loss: 0.5672 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.8955 - loss: 0.6530 - val_accuracy: 0.9496 - val_loss: 0.4485 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 209ms/step - accuracy: 0.9013 - loss: 0.6259 - val_accuracy: 0.9882 - val_loss: 0.3472 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 208ms/step - accuracy: 0.8995 - loss: 0.6265 - val_accuracy: 0.9684 - val_loss: 0.4019 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 211ms/step - accuracy: 0.9101 - loss: 0.5880 - val_accuracy: 0.9879 - val_loss: 0.3336 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.9103 - loss: 0.5754 - val_accuracy: 0.9531 - val_loss: 0.4216 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.9198 - loss: 0.5479 - val_accuracy: 0.9592 - val_loss: 0.4220 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.9192 - loss: 0.5456 - val_accuracy: 0.9696 - val_loss: 0.3708 - learning_rate: 5.0000e-04\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - accuracy: 0.9886 - loss: 0.3479\n",
      "Score for fold 1: Loss = 0.3472, Accuracy = 98.82%\n",
      "\n",
      "==================================================\n",
      "Training for fold 2/5\n",
      "==================================================\n",
      "Creating symlinks for fold data...\n",
      "Found 41760 images belonging to 29 classes.\n",
      "Found 10440 images belonging to 29 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 213ms/step - accuracy: 0.0686 - loss: 5.4809 - val_accuracy: 0.1265 - val_loss: 3.9082 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.2463 - loss: 3.2754 - val_accuracy: 0.6076 - val_loss: 1.7137 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.5260 - loss: 1.9892 - val_accuracy: 0.8607 - val_loss: 0.9268 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 211ms/step - accuracy: 0.6874 - loss: 1.4157 - val_accuracy: 0.8823 - val_loss: 0.7840 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 217ms/step - accuracy: 0.7695 - loss: 1.1305 - val_accuracy: 0.9420 - val_loss: 0.6082 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 215ms/step - accuracy: 0.8145 - loss: 0.9688 - val_accuracy: 0.9180 - val_loss: 0.6429 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 218ms/step - accuracy: 0.8477 - loss: 0.8488 - val_accuracy: 0.9592 - val_loss: 0.4697 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 215ms/step - accuracy: 0.8575 - loss: 0.7976 - val_accuracy: 0.8627 - val_loss: 0.7719 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 214ms/step - accuracy: 0.8706 - loss: 0.7536 - val_accuracy: 0.9505 - val_loss: 0.5015 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 215ms/step - accuracy: 0.8870 - loss: 0.6967 - val_accuracy: 0.9266 - val_loss: 0.5533 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 212ms/step - accuracy: 0.9288 - loss: 0.5465 - val_accuracy: 0.9961 - val_loss: 0.3013 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 210ms/step - accuracy: 0.9466 - loss: 0.4498 - val_accuracy: 0.9963 - val_loss: 0.2651 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.9515 - loss: 0.4004 - val_accuracy: 0.9954 - val_loss: 0.2407 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.9512 - loss: 0.3777 - val_accuracy: 0.9968 - val_loss: 0.2227 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 212ms/step - accuracy: 0.9567 - loss: 0.3452 - val_accuracy: 0.9959 - val_loss: 0.2070 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.9552 - loss: 0.3367 - val_accuracy: 0.9978 - val_loss: 0.1898 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.9594 - loss: 0.3108 - val_accuracy: 0.9959 - val_loss: 0.1859 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.9588 - loss: 0.3051 - val_accuracy: 0.9966 - val_loss: 0.1756 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.9605 - loss: 0.2958 - val_accuracy: 0.9971 - val_loss: 0.1681 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.9632 - loss: 0.2768 - val_accuracy: 0.9969 - val_loss: 0.1631 - learning_rate: 1.0000e-04\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - accuracy: 0.9983 - loss: 0.1882\n",
      "Score for fold 2: Loss = 0.1898, Accuracy = 99.78%\n",
      "\n",
      "==================================================\n",
      "Training for fold 3/5\n",
      "==================================================\n",
      "Creating symlinks for fold data...\n",
      "Found 41760 images belonging to 29 classes.\n",
      "Found 10440 images belonging to 29 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 211ms/step - accuracy: 0.0513 - loss: 5.5361 - val_accuracy: 0.1867 - val_loss: 3.5262 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.1710 - loss: 3.5184 - val_accuracy: 0.4065 - val_loss: 2.4073 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 209ms/step - accuracy: 0.3970 - loss: 2.3352 - val_accuracy: 0.6561 - val_loss: 1.4800 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 210ms/step - accuracy: 0.6183 - loss: 1.5740 - val_accuracy: 0.6827 - val_loss: 1.4808 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 208ms/step - accuracy: 0.7308 - loss: 1.2053 - val_accuracy: 0.8665 - val_loss: 0.8028 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.7908 - loss: 1.0175 - val_accuracy: 0.9179 - val_loss: 0.5817 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 212ms/step - accuracy: 0.8274 - loss: 0.8923 - val_accuracy: 0.9053 - val_loss: 0.6171 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 212ms/step - accuracy: 0.8460 - loss: 0.8300 - val_accuracy: 0.9298 - val_loss: 0.5471 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 212ms/step - accuracy: 0.8669 - loss: 0.7519 - val_accuracy: 0.9377 - val_loss: 0.5385 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 211ms/step - accuracy: 0.8780 - loss: 0.7106 - val_accuracy: 0.9635 - val_loss: 0.4188 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.8916 - loss: 0.6624 - val_accuracy: 0.9518 - val_loss: 0.4492 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.8946 - loss: 0.6420 - val_accuracy: 0.9798 - val_loss: 0.3656 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.8940 - loss: 0.6330 - val_accuracy: 0.9855 - val_loss: 0.3550 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 209ms/step - accuracy: 0.9071 - loss: 0.5951 - val_accuracy: 0.9887 - val_loss: 0.3287 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 210ms/step - accuracy: 0.9054 - loss: 0.6015 - val_accuracy: 0.9933 - val_loss: 0.3184 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 209ms/step - accuracy: 0.9093 - loss: 0.5753 - val_accuracy: 0.7954 - val_loss: 1.0549 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.9088 - loss: 0.5702 - val_accuracy: 0.9888 - val_loss: 0.3230 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.9167 - loss: 0.5412 - val_accuracy: 0.9822 - val_loss: 0.3413 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.9522 - loss: 0.4309 - val_accuracy: 0.9980 - val_loss: 0.2562 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 209ms/step - accuracy: 0.9617 - loss: 0.3670 - val_accuracy: 0.9989 - val_loss: 0.2293 - learning_rate: 1.0000e-04\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - accuracy: 0.9991 - loss: 0.2277\n",
      "Score for fold 3: Loss = 0.2293, Accuracy = 99.89%\n",
      "\n",
      "==================================================\n",
      "Training for fold 4/5\n",
      "==================================================\n",
      "Creating symlinks for fold data...\n",
      "Found 41760 images belonging to 29 classes.\n",
      "Found 10440 images belonging to 29 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 209ms/step - accuracy: 0.0639 - loss: 5.3782 - val_accuracy: 0.0898 - val_loss: 4.1408 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 209ms/step - accuracy: 0.1708 - loss: 3.5400 - val_accuracy: 0.3291 - val_loss: 2.4972 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.3732 - loss: 2.4162 - val_accuracy: 0.2960 - val_loss: 2.8601 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.5949 - loss: 1.6511 - val_accuracy: 0.7870 - val_loss: 0.9949 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 205ms/step - accuracy: 0.7173 - loss: 1.2528 - val_accuracy: 0.8728 - val_loss: 0.7328 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 207ms/step - accuracy: 0.7820 - loss: 1.0510 - val_accuracy: 0.8483 - val_loss: 0.7913 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.8164 - loss: 0.9296 - val_accuracy: 0.7651 - val_loss: 1.0075 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 208ms/step - accuracy: 0.8428 - loss: 0.8364 - val_accuracy: 0.8826 - val_loss: 0.6973 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 208ms/step - accuracy: 0.8565 - loss: 0.7772 - val_accuracy: 0.8935 - val_loss: 0.6088 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.8707 - loss: 0.7339 - val_accuracy: 0.9781 - val_loss: 0.4043 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.8766 - loss: 0.7044 - val_accuracy: 0.9855 - val_loss: 0.3704 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.8906 - loss: 0.6578 - val_accuracy: 0.9438 - val_loss: 0.4840 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 210ms/step - accuracy: 0.8973 - loss: 0.6318 - val_accuracy: 0.9489 - val_loss: 0.4552 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 209ms/step - accuracy: 0.9021 - loss: 0.6142 - val_accuracy: 0.9782 - val_loss: 0.3701 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.9113 - loss: 0.5791 - val_accuracy: 0.9789 - val_loss: 0.3609 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.9066 - loss: 0.5892 - val_accuracy: 0.9539 - val_loss: 0.4230 - learning_rate: 5.0000e-04\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 56ms/step - accuracy: 0.9848 - loss: 0.3727\n",
      "Score for fold 4: Loss = 0.3704, Accuracy = 98.55%\n",
      "\n",
      "==================================================\n",
      "Training for fold 5/5\n",
      "==================================================\n",
      "Creating symlinks for fold data...\n",
      "Found 41760 images belonging to 29 classes.\n",
      "Found 10440 images belonging to 29 classes.\n",
      "Epoch 1/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 211ms/step - accuracy: 0.0520 - loss: 5.5567 - val_accuracy: 0.1689 - val_loss: 3.7524 - learning_rate: 5.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.1489 - loss: 3.6828 - val_accuracy: 0.2127 - val_loss: 3.1159 - learning_rate: 5.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.3475 - loss: 2.4937 - val_accuracy: 0.5169 - val_loss: 1.8211 - learning_rate: 5.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.5440 - loss: 1.7903 - val_accuracy: 0.6968 - val_loss: 1.2765 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 209ms/step - accuracy: 0.6882 - loss: 1.3323 - val_accuracy: 0.8547 - val_loss: 0.7576 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.7621 - loss: 1.0986 - val_accuracy: 0.9267 - val_loss: 0.5903 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 211ms/step - accuracy: 0.8153 - loss: 0.9239 - val_accuracy: 0.7506 - val_loss: 1.2079 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 211ms/step - accuracy: 0.8330 - loss: 0.8497 - val_accuracy: 0.8928 - val_loss: 0.6757 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.8533 - loss: 0.7957 - val_accuracy: 0.9716 - val_loss: 0.4330 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 212ms/step - accuracy: 0.8715 - loss: 0.7223 - val_accuracy: 0.9571 - val_loss: 0.4527 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.8743 - loss: 0.7009 - val_accuracy: 0.9619 - val_loss: 0.4333 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 210ms/step - accuracy: 0.8829 - loss: 0.6775 - val_accuracy: 0.9480 - val_loss: 0.4529 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 212ms/step - accuracy: 0.9280 - loss: 0.5283 - val_accuracy: 0.9939 - val_loss: 0.2932 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 211ms/step - accuracy: 0.9420 - loss: 0.4457 - val_accuracy: 0.9954 - val_loss: 0.2569 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 209ms/step - accuracy: 0.9481 - loss: 0.3977 - val_accuracy: 0.9971 - val_loss: 0.2296 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 210ms/step - accuracy: 0.9493 - loss: 0.3748 - val_accuracy: 0.9974 - val_loss: 0.2113 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.9510 - loss: 0.3585 - val_accuracy: 0.9969 - val_loss: 0.2011 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 216ms/step - accuracy: 0.9537 - loss: 0.3378 - val_accuracy: 0.9972 - val_loss: 0.1909 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 212ms/step - accuracy: 0.9539 - loss: 0.3217 - val_accuracy: 0.9979 - val_loss: 0.1789 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m1305/1305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 213ms/step - accuracy: 0.9562 - loss: 0.3069 - val_accuracy: 0.9979 - val_loss: 0.1719 - learning_rate: 1.0000e-04\n",
      "\u001b[1m327/327\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 57ms/step - accuracy: 0.9984 - loss: 0.1770\n",
      "Score for fold 5: Loss = 0.1789, Accuracy = 99.79%\n",
      "\n",
      "==================================================\n",
      "K-FOLD CROSS-VALIDATION RESULTS FOR 5 FOLDS\n",
      "==================================================\n",
      "Average Loss: 0.2631 (±0.0803)\n",
      "Average Accuracy: 99.37% (±0.56%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Ensure TensorFlow doesn't allocate all GPU memory at once\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Parameters\n",
    "k_folds = 5\n",
    "img_size = (200, 200)\n",
    "batch_size = 32\n",
    "base_dir = '../dataset/asl_split'  # The directory containing train, validation, test folders\n",
    "num_classes = 29\n",
    "epochs = 20  # Reduced for k-fold evaluation\n",
    "\n",
    "# Create function to build model (same as your existing model)\n",
    "def create_model():\n",
    "    # Import the necessary model building code\n",
    "    from tensorflow.keras import Input, Model\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "    from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Activation\n",
    "    from tensorflow.keras.layers import LayerNormalization\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    \n",
    "    # Define helper functions for model architecture\n",
    "    def self_attention_block(inputs, filters):\n",
    "        x = Conv2D(filters//8, kernel_size=1)(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        attention = Conv2D(1, kernel_size=1)(x)\n",
    "        attention = Activation('sigmoid')(attention)\n",
    "        return Multiply()([inputs, attention])\n",
    "    \n",
    "    def residual_block(inputs, filters, kernel_size=3, strides=1, attention=True):\n",
    "        x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same', \n",
    "               kernel_regularizer=l2(0.0018))(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        x = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same',\n",
    "               kernel_regularizer=l2(0.0018))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        if attention:\n",
    "            x = self_attention_block(x, filters)\n",
    "        \n",
    "        if strides > 1 or inputs.shape[-1] != filters:\n",
    "            shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(inputs)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "        else:\n",
    "            shortcut = inputs\n",
    "        \n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "    \n",
    "    # Build the model\n",
    "    inputs = Input(shape=(200, 200, 3))\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', kernel_regularizer=l2(0.0018))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Block 1 with residual connections\n",
    "    x = residual_block(x, 32, strides=1, attention=False)\n",
    "    x = residual_block(x, 32, strides=2, attention=True)  # Downsample\n",
    "    x = SpatialDropout2D(0.1)(x)\n",
    "    \n",
    "    # Block 2 with residual connections\n",
    "    x = residual_block(x, 64, strides=1, attention=False)\n",
    "    x = residual_block(x, 64, strides=2, attention=True)  # Downsample\n",
    "    x = SpatialDropout2D(0.15)(x)\n",
    "    \n",
    "    # Block 3 with residual connections and attention\n",
    "    x = residual_block(x, 128, strides=1, attention=True)\n",
    "    x = residual_block(x, 128, strides=2, attention=True)  # Downsample\n",
    "    x = SpatialDropout2D(0.2)(x)\n",
    "    \n",
    "    # Global pooling and feature normalization\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # Classification head\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.0025))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 1. Create a dataframe of all training images and their labels\n",
    "def create_image_dataframe(train_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_indices = {}\n",
    "    \n",
    "    # Get class indices\n",
    "    for i, class_name in enumerate(sorted(os.listdir(train_dir))):\n",
    "        class_indices[class_name] = i\n",
    "    \n",
    "    # Collect image paths and labels\n",
    "    for class_name in sorted(os.listdir(train_dir)):\n",
    "        class_path = os.path.join(train_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_paths.append(os.path.join(class_path, img_name))\n",
    "                    labels.append(class_indices[class_name])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'image_path': image_paths,\n",
    "        'label': labels,\n",
    "        'class_name': [os.path.basename(os.path.dirname(p)) for p in image_paths]\n",
    "    })\n",
    "    \n",
    "    return df, class_indices\n",
    "\n",
    "# 2. Set up directory structure for k-fold\n",
    "def setup_kfold_dirs(fold_idx, class_indices):\n",
    "    # Create temporary directories for this fold\n",
    "    fold_dir = f'../dataset/fold_{fold_idx}'\n",
    "    fold_train_dir = os.path.join(fold_dir, 'train')\n",
    "    fold_val_dir = os.path.join(fold_dir, 'validation')\n",
    "    \n",
    "    # Clean any existing directories\n",
    "    if os.path.exists(fold_dir):\n",
    "        shutil.rmtree(fold_dir)\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(fold_dir)\n",
    "    os.makedirs(fold_train_dir)\n",
    "    os.makedirs(fold_val_dir)\n",
    "    \n",
    "    # Create class subdirectories\n",
    "    for class_name in class_indices.keys():\n",
    "        os.makedirs(os.path.join(fold_train_dir, class_name))\n",
    "        os.makedirs(os.path.join(fold_val_dir, class_name))\n",
    "    \n",
    "    return fold_dir, fold_train_dir, fold_val_dir\n",
    "\n",
    "# 3. Create symbolic links for the fold's data\n",
    "def create_fold_symlinks(df, train_idx, val_idx, fold_train_dir, fold_val_dir):\n",
    "    # Create symbolic links for training data\n",
    "    for idx in train_idx:\n",
    "        src_path = os.path.abspath(df.iloc[idx]['image_path'])\n",
    "        class_name = df.iloc[idx]['class_name']\n",
    "        dst_dir = os.path.join(fold_train_dir, class_name)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(dst_dir, os.path.basename(src_path))\n",
    "        if os.path.exists(src_path):\n",
    "            os.symlink(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"Warning: Source file not found: {src_path}\")\n",
    "    \n",
    "    # Create symbolic links for validation data\n",
    "    for idx in val_idx:\n",
    "        src_path = os.path.abspath(df.iloc[idx]['image_path'])\n",
    "        class_name = df.iloc[idx]['class_name']\n",
    "        dst_dir = os.path.join(fold_val_dir, class_name)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(dst_dir, os.path.basename(src_path))\n",
    "        if os.path.exists(src_path):\n",
    "            os.symlink(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"Warning: Source file not found: {src_path}\")\n",
    "\n",
    "# Main k-fold cross-validation\n",
    "def run_kfold_cv():\n",
    "    # Get the combined training and validation data\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    df, class_indices = create_image_dataframe(train_dir)\n",
    "    \n",
    "    # Initialize metrics storage\n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    \n",
    "    # Set up stratified k-fold\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=0.00001\n",
    "    )\n",
    "    \n",
    "    # Loop through each fold\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(df['image_path'], df['label'])):\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'Training for fold {fold_idx+1}/{k_folds}')\n",
    "        print(f'{\"=\"*50}')\n",
    "        \n",
    "        # Setup directories for this fold\n",
    "        fold_dir, fold_train_dir, fold_val_dir = setup_kfold_dirs(fold_idx, class_indices)\n",
    "        \n",
    "        try:\n",
    "            # Create symlinks for this fold's data\n",
    "            print(\"Creating symlinks for fold data...\")\n",
    "            create_fold_symlinks(df, train_idx, val_idx, fold_train_dir, fold_val_dir)\n",
    "            \n",
    "            # Data generators for this fold\n",
    "            train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                brightness_range=[0.7, 1.3],\n",
    "                fill_mode='nearest',\n",
    "                shear_range=0.1,\n",
    "                channel_shift_range=0.1\n",
    "            )\n",
    "            \n",
    "            val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "            \n",
    "            # Create generators that load images on-demand, not all at once\n",
    "            train_generator = train_datagen.flow_from_directory(\n",
    "                fold_train_dir,\n",
    "                target_size=img_size,\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True\n",
    "            )\n",
    "            \n",
    "            val_generator = val_datagen.flow_from_directory(\n",
    "                fold_val_dir,\n",
    "                target_size=img_size,\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical',\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "            # Create a fresh model for each fold\n",
    "            model = create_model()\n",
    "            \n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                validation_data=val_generator,\n",
    "                epochs=epochs,\n",
    "                callbacks=[early_stopping, reduce_lr],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Evaluate on validation data\n",
    "            scores = model.evaluate(val_generator, verbose=1)\n",
    "            \n",
    "            # Store metrics\n",
    "            fold_accuracies.append(scores[1])\n",
    "            fold_losses.append(scores[0])\n",
    "            \n",
    "            print(f'Score for fold {fold_idx+1}: Loss = {scores[0]:.4f}, Accuracy = {scores[1]*100:.2f}%')\n",
    "            \n",
    "            # Clear session to prevent memory leaks\n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "            \n",
    "        finally:\n",
    "            # Clean up fold directory\n",
    "            if os.path.exists(fold_dir):\n",
    "                shutil.rmtree(fold_dir)\n",
    "    \n",
    "    # Print final k-fold results\n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print(f'K-FOLD CROSS-VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "    print(f'{\"=\"*50}')\n",
    "    print(f'Average Loss: {np.mean(fold_losses):.4f} (±{np.std(fold_losses):.4f})')\n",
    "    print(f'Average Accuracy: {np.mean(fold_accuracies)*100:.2f}% (±{np.std(fold_accuracies)*100:.2f}%)')\n",
    "    \n",
    "    return fold_accuracies, fold_losses\n",
    "\n",
    "# Run k-fold cross-validation\n",
    "fold_accuracies, fold_losses = run_kfold_cv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('../models/asl_custom_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17400 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '../dataset/asl_split/test',   # or your actual test directory\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 57ms/step - accuracy: 0.9996 - loss: 0.1184\n",
      "Test accuracy: 0.9994\n",
      "Test loss: 0.1194\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00       600\n",
      "           B       1.00      1.00      1.00       600\n",
      "           C       1.00      1.00      1.00       600\n",
      "           D       1.00      1.00      1.00       600\n",
      "           E       1.00      1.00      1.00       600\n",
      "           F       1.00      1.00      1.00       600\n",
      "           G       1.00      1.00      1.00       600\n",
      "           H       1.00      1.00      1.00       600\n",
      "           I       1.00      1.00      1.00       600\n",
      "           J       1.00      1.00      1.00       600\n",
      "           K       1.00      1.00      1.00       600\n",
      "           L       1.00      1.00      1.00       600\n",
      "           M       1.00      1.00      1.00       600\n",
      "           N       1.00      1.00      1.00       600\n",
      "           O       1.00      1.00      1.00       600\n",
      "           P       1.00      1.00      1.00       600\n",
      "           Q       1.00      1.00      1.00       600\n",
      "           R       1.00      1.00      1.00       600\n",
      "           S       1.00      1.00      1.00       600\n",
      "           T       1.00      1.00      1.00       600\n",
      "           U       1.00      0.99      1.00       600\n",
      "           V       1.00      1.00      1.00       600\n",
      "           W       1.00      1.00      1.00       600\n",
      "           X       1.00      1.00      1.00       600\n",
      "           Y       1.00      1.00      1.00       600\n",
      "           Z       1.00      1.00      1.00       600\n",
      "         del       1.00      1.00      1.00       600\n",
      "     nothing       1.00      1.00      1.00       600\n",
      "       space       1.00      1.00      1.00       600\n",
      "\n",
      "    accuracy                           1.00     17400\n",
      "   macro avg       1.00      1.00      1.00     17400\n",
      "weighted avg       1.00      1.00      1.00     17400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get true and predicted labels\n",
    "test_generator.reset()\n",
    "y_true = test_generator.classes\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=test_generator.class_indices.keys(),\n",
    "            yticklabels=test_generator.class_indices.keys())\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=list(test_generator.class_indices.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step\n",
      "Accuracy: 0.9994\n",
      "Macro Precision: 0.9994\n",
      "Macro Recall: 0.9994\n",
      "Macro F1: 0.9994\n",
      "Weighted Precision: 0.9994\n",
      "Weighted Recall: 0.9994\n",
      "Weighted F1: 0.9994\n",
      "Cohen's Kappa: 0.9994\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00       600\n",
      "           B       1.00      1.00      1.00       600\n",
      "           C       1.00      1.00      1.00       600\n",
      "           D       1.00      1.00      1.00       600\n",
      "           E       1.00      1.00      1.00       600\n",
      "           F       1.00      1.00      1.00       600\n",
      "           G       1.00      1.00      1.00       600\n",
      "           H       1.00      1.00      1.00       600\n",
      "           I       1.00      1.00      1.00       600\n",
      "           J       1.00      1.00      1.00       600\n",
      "           K       1.00      1.00      1.00       600\n",
      "           L       1.00      1.00      1.00       600\n",
      "           M       1.00      1.00      1.00       600\n",
      "           N       1.00      1.00      1.00       600\n",
      "           O       1.00      1.00      1.00       600\n",
      "           P       1.00      1.00      1.00       600\n",
      "           Q       1.00      1.00      1.00       600\n",
      "           R       1.00      1.00      1.00       600\n",
      "           S       1.00      1.00      1.00       600\n",
      "           T       1.00      1.00      1.00       600\n",
      "           U       1.00      0.99      1.00       600\n",
      "           V       1.00      1.00      1.00       600\n",
      "           W       1.00      1.00      1.00       600\n",
      "           X       1.00      1.00      1.00       600\n",
      "           Y       1.00      1.00      1.00       600\n",
      "           Z       1.00      1.00      1.00       600\n",
      "         del       1.00      1.00      1.00       600\n",
      "     nothing       1.00      1.00      1.00       600\n",
      "       space       1.00      1.00      1.00       600\n",
      "\n",
      "    accuracy                           1.00     17400\n",
      "   macro avg       1.00      1.00      1.00     17400\n",
      "weighted avg       1.00      1.00      1.00     17400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_true contains true labels and y_pred contains predicted labels\n",
    "# If you need to get these from your test generator and model:\n",
    "y_true = test_generator.classes\n",
    "y_pred = np.argmax(model.predict(test_generator), axis=1)\n",
    "\n",
    "# 1. Overall metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "# 2. Cohen's Kappa (measures agreement beyond chance)\n",
    "kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "# 3. Print all metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro Precision: {precision_macro:.4f}\")\n",
    "print(f\"Macro Recall: {recall_macro:.4f}\")\n",
    "print(f\"Macro F1: {f1_macro:.4f}\")\n",
    "print(f\"Weighted Precision: {precision_weighted:.4f}\")\n",
    "print(f\"Weighted Recall: {recall_weighted:.4f}\")\n",
    "print(f\"Weighted F1: {f1_weighted:.4f}\")\n",
    "print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "\n",
    "# 4. Full classification report (includes per-class and average metrics)\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, \n",
    "                           target_names=list(test_generator.class_indices.keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sed model overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52200 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_6 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ conv2d_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_7 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ conv2d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_7          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_6 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_42 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_43 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_44 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m520\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m9\u001b[0m │ conv2d_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m2,112\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_7 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_7[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m2,064\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │         \u001b[38;5;34m17\u001b[0m │ conv2d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_51 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_7          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m256\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m3,741\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">323,375</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m323,375\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,031</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m322,031\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> (5.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,344\u001b[0m (5.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Activation\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ========================\n",
    "# Dataset Configuration\n",
    "# ========================\n",
    "# Get absolute path to dataset (notebook is in notebooks/ directory)\n",
    "base_dir = os.path.abspath(os.path.join(os.pardir, 'dataset', 'asl_split'))\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# ========================\n",
    "# Enhanced Preprocessing\n",
    "# ========================\n",
    "def preprocess_image(img):\n",
    "    \"\"\"Convert to edges with proper type handling\"\"\"\n",
    "    # Convert float32 [0,1] to uint8 [0,255]\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Convert back to float32 [0,1] and 3 channels\n",
    "    return np.stack([edges, edges, edges], axis=-1).astype(np.float32) / 255.0\n",
    "\n",
    "# ========================\n",
    "# Data Generators\n",
    "# ========================\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    fill_mode='constant',\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=False\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# Model Architecture\n",
    "# ========================\n",
    "def self_attention_block(inputs, filters):\n",
    "    x = Conv2D(filters//8, (1,1), activation='relu')(inputs)\n",
    "    attention = Conv2D(1, (1,1), activation='sigmoid')(x)\n",
    "    return Multiply()([inputs, attention])\n",
    "\n",
    "def residual_block(inputs, filters, strides=1, attention=True):\n",
    "    # Main path\n",
    "    x = Conv2D(filters, (3,3), strides=strides, padding='same', \n",
    "               kernel_regularizer=l2(0.0018))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (3,3), padding='same', kernel_regularizer=l2(0.0018))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Attention\n",
    "    if attention:\n",
    "        x = self_attention_block(x, filters)\n",
    "    \n",
    "    # Shortcut path\n",
    "    shortcut = inputs\n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1,1), strides=strides)(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    return Add()([x, shortcut])\n",
    "\n",
    "# Build model\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "x = residual_block(inputs, 32, attention=False)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.2)(x)\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.3)(x)\n",
    "\n",
    "x = residual_block(x, 128)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.002))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# ========================\n",
    "# Training Configuration\n",
    "# ========================\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']    \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746109400.410218    1503 service.cc:152] XLA service 0x7f890c002a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746109400.410246    1503 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-05-01 18:23:20.538127: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746109401.161251    1503 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1746109417.647437    1503 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.0574 - loss: 4.0771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 18:27:53.527430: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_466', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 170ms/step - accuracy: 0.0574 - loss: 4.0770 - val_accuracy: 0.0753 - val_loss: 3.4405 - learning_rate: 5.0000e-04\n",
      "Epoch 2/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.1067 - loss: 3.2828 - val_accuracy: 0.1718 - val_loss: 2.8875 - learning_rate: 5.0000e-04\n",
      "Epoch 3/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 171ms/step - accuracy: 0.1730 - loss: 2.9462 - val_accuracy: 0.1519 - val_loss: 3.0146 - learning_rate: 5.0000e-04\n",
      "Epoch 4/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 170ms/step - accuracy: 0.2385 - loss: 2.6987 - val_accuracy: 0.3569 - val_loss: 2.2424 - learning_rate: 5.0000e-04\n",
      "Epoch 5/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 173ms/step - accuracy: 0.3124 - loss: 2.4602 - val_accuracy: 0.3923 - val_loss: 2.1938 - learning_rate: 5.0000e-04\n",
      "Epoch 6/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 409ms/step - accuracy: 0.3692 - loss: 2.2843 - val_accuracy: 0.3943 - val_loss: 2.1307 - learning_rate: 5.0000e-04\n",
      "Epoch 7/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 163ms/step - accuracy: 0.4155 - loss: 2.1591 - val_accuracy: 0.3938 - val_loss: 2.1391 - learning_rate: 5.0000e-04\n",
      "Epoch 8/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 164ms/step - accuracy: 0.4456 - loss: 2.0649 - val_accuracy: 0.3407 - val_loss: 2.2899 - learning_rate: 5.0000e-04\n",
      "Epoch 9/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 169ms/step - accuracy: 0.4789 - loss: 1.9803 - val_accuracy: 0.5961 - val_loss: 1.5354 - learning_rate: 5.0000e-04\n",
      "Epoch 10/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.4952 - loss: 1.9190 - val_accuracy: 0.5942 - val_loss: 1.5138 - learning_rate: 5.0000e-04\n",
      "Epoch 11/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 164ms/step - accuracy: 0.5262 - loss: 1.8556 - val_accuracy: 0.6198 - val_loss: 1.4401 - learning_rate: 5.0000e-04\n",
      "Epoch 12/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 164ms/step - accuracy: 0.5399 - loss: 1.8090 - val_accuracy: 0.7349 - val_loss: 1.2814 - learning_rate: 5.0000e-04\n",
      "Epoch 13/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.5564 - loss: 1.7554 - val_accuracy: 0.6800 - val_loss: 1.2924 - learning_rate: 5.0000e-04\n",
      "Epoch 14/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 164ms/step - accuracy: 0.5685 - loss: 1.7201 - val_accuracy: 0.7816 - val_loss: 1.0188 - learning_rate: 5.0000e-04\n",
      "Epoch 15/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 165ms/step - accuracy: 0.5806 - loss: 1.6957 - val_accuracy: 0.7448 - val_loss: 1.1607 - learning_rate: 5.0000e-04\n",
      "Epoch 16/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 163ms/step - accuracy: 0.5849 - loss: 1.6834 - val_accuracy: 0.8059 - val_loss: 0.9613 - learning_rate: 5.0000e-04\n",
      "Epoch 17/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 164ms/step - accuracy: 0.5999 - loss: 1.6331 - val_accuracy: 0.7503 - val_loss: 1.1346 - learning_rate: 5.0000e-04\n",
      "Epoch 18/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.6019 - loss: 1.6269 - val_accuracy: 0.8298 - val_loss: 0.8365 - learning_rate: 5.0000e-04\n",
      "Epoch 19/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 165ms/step - accuracy: 0.6089 - loss: 1.6195 - val_accuracy: 0.8037 - val_loss: 0.9565 - learning_rate: 5.0000e-04\n",
      "Epoch 20/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 163ms/step - accuracy: 0.6210 - loss: 1.5831 - val_accuracy: 0.7994 - val_loss: 0.9859 - learning_rate: 5.0000e-04\n",
      "Epoch 21/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.6254 - loss: 1.5575 - val_accuracy: 0.8451 - val_loss: 0.8305 - learning_rate: 5.0000e-04\n",
      "Epoch 22/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 163ms/step - accuracy: 0.6319 - loss: 1.5498 - val_accuracy: 0.7952 - val_loss: 0.9301 - learning_rate: 5.0000e-04\n",
      "Epoch 23/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 167ms/step - accuracy: 0.6372 - loss: 1.5276 - val_accuracy: 0.7716 - val_loss: 1.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 24/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 164ms/step - accuracy: 0.6390 - loss: 1.5169 - val_accuracy: 0.8439 - val_loss: 0.8512 - learning_rate: 5.0000e-04\n",
      "Epoch 25/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.6468 - loss: 1.4934 - val_accuracy: 0.8784 - val_loss: 0.7464 - learning_rate: 5.0000e-04\n",
      "Epoch 26/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.6477 - loss: 1.4977 - val_accuracy: 0.8496 - val_loss: 0.8212 - learning_rate: 5.0000e-04\n",
      "Epoch 27/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.6531 - loss: 1.4821 - val_accuracy: 0.8401 - val_loss: 0.8104 - learning_rate: 5.0000e-04\n",
      "Epoch 28/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 167ms/step - accuracy: 0.6590 - loss: 1.4626 - val_accuracy: 0.8561 - val_loss: 0.7824 - learning_rate: 5.0000e-04\n",
      "Epoch 29/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 168ms/step - accuracy: 0.6622 - loss: 1.4406 - val_accuracy: 0.8398 - val_loss: 0.8465 - learning_rate: 5.0000e-04\n",
      "Epoch 30/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 168ms/step - accuracy: 0.6652 - loss: 1.4379 - val_accuracy: 0.8774 - val_loss: 0.7746 - learning_rate: 5.0000e-04\n",
      "Epoch 31/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 165ms/step - accuracy: 0.7114 - loss: 1.2860 - val_accuracy: 0.9211 - val_loss: 0.5803 - learning_rate: 1.0000e-04\n",
      "Epoch 32/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.7280 - loss: 1.2088 - val_accuracy: 0.9253 - val_loss: 0.5508 - learning_rate: 1.0000e-04\n",
      "Epoch 33/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.7320 - loss: 1.1711 - val_accuracy: 0.9264 - val_loss: 0.5397 - learning_rate: 1.0000e-04\n",
      "Epoch 34/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 163ms/step - accuracy: 0.7383 - loss: 1.1343 - val_accuracy: 0.9225 - val_loss: 0.5285 - learning_rate: 1.0000e-04\n",
      "Epoch 35/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 164ms/step - accuracy: 0.7442 - loss: 1.1090 - val_accuracy: 0.9288 - val_loss: 0.5087 - learning_rate: 1.0000e-04\n",
      "Epoch 36/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 160ms/step - accuracy: 0.7455 - loss: 1.0996 - val_accuracy: 0.9340 - val_loss: 0.4862 - learning_rate: 1.0000e-04\n",
      "Epoch 37/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 161ms/step - accuracy: 0.7500 - loss: 1.0792 - val_accuracy: 0.9318 - val_loss: 0.4809 - learning_rate: 1.0000e-04\n",
      "Epoch 38/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 161ms/step - accuracy: 0.7480 - loss: 1.0740 - val_accuracy: 0.9271 - val_loss: 0.4844 - learning_rate: 1.0000e-04\n",
      "Epoch 39/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 161ms/step - accuracy: 0.7556 - loss: 1.0433 - val_accuracy: 0.9334 - val_loss: 0.4661 - learning_rate: 1.0000e-04\n",
      "Epoch 40/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 163ms/step - accuracy: 0.7564 - loss: 1.0466 - val_accuracy: 0.9355 - val_loss: 0.4565 - learning_rate: 1.0000e-04\n",
      "Epoch 41/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.7561 - loss: 1.0457 - val_accuracy: 0.9300 - val_loss: 0.4626 - learning_rate: 1.0000e-04\n",
      "Epoch 42/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.7560 - loss: 1.0331 - val_accuracy: 0.9401 - val_loss: 0.4400 - learning_rate: 1.0000e-04\n",
      "Epoch 43/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.7557 - loss: 1.0232 - val_accuracy: 0.9315 - val_loss: 0.4477 - learning_rate: 1.0000e-04\n",
      "Epoch 44/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 167ms/step - accuracy: 0.7588 - loss: 1.0126 - val_accuracy: 0.9220 - val_loss: 0.4564 - learning_rate: 1.0000e-04\n",
      "Epoch 45/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.7587 - loss: 1.0123 - val_accuracy: 0.9432 - val_loss: 0.4095 - learning_rate: 1.0000e-04\n",
      "Epoch 46/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.7644 - loss: 0.9961 - val_accuracy: 0.9409 - val_loss: 0.4158 - learning_rate: 1.0000e-04\n",
      "Epoch 47/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 167ms/step - accuracy: 0.7645 - loss: 0.9914 - val_accuracy: 0.9418 - val_loss: 0.4012 - learning_rate: 1.0000e-04\n",
      "Epoch 48/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 170ms/step - accuracy: 0.7634 - loss: 0.9967 - val_accuracy: 0.9391 - val_loss: 0.4185 - learning_rate: 1.0000e-04\n",
      "Epoch 49/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 164ms/step - accuracy: 0.7643 - loss: 0.9791 - val_accuracy: 0.9368 - val_loss: 0.4120 - learning_rate: 1.0000e-04\n",
      "Epoch 50/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.7663 - loss: 0.9674 - val_accuracy: 0.9452 - val_loss: 0.3889 - learning_rate: 1.0000e-04\n",
      "Epoch 51/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.7660 - loss: 0.9729 - val_accuracy: 0.9403 - val_loss: 0.3968 - learning_rate: 1.0000e-04\n",
      "Epoch 52/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 163ms/step - accuracy: 0.7653 - loss: 0.9733 - val_accuracy: 0.9460 - val_loss: 0.3856 - learning_rate: 1.0000e-04\n",
      "Epoch 53/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 164ms/step - accuracy: 0.7661 - loss: 0.9723 - val_accuracy: 0.9380 - val_loss: 0.3907 - learning_rate: 1.0000e-04\n",
      "Epoch 54/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.7675 - loss: 0.9629 - val_accuracy: 0.9484 - val_loss: 0.3744 - learning_rate: 1.0000e-04\n",
      "Epoch 55/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 164ms/step - accuracy: 0.7677 - loss: 0.9564 - val_accuracy: 0.9399 - val_loss: 0.4048 - learning_rate: 1.0000e-04\n",
      "Epoch 56/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 164ms/step - accuracy: 0.7678 - loss: 0.9536 - val_accuracy: 0.9497 - val_loss: 0.3756 - learning_rate: 1.0000e-04\n",
      "Epoch 57/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 163ms/step - accuracy: 0.7684 - loss: 0.9447 - val_accuracy: 0.9494 - val_loss: 0.3598 - learning_rate: 1.0000e-04\n",
      "Epoch 58/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 161ms/step - accuracy: 0.7712 - loss: 0.9456 - val_accuracy: 0.9478 - val_loss: 0.3745 - learning_rate: 1.0000e-04\n",
      "Epoch 59/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 161ms/step - accuracy: 0.7714 - loss: 0.9384 - val_accuracy: 0.9421 - val_loss: 0.3784 - learning_rate: 1.0000e-04\n",
      "Epoch 60/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.7760 - loss: 0.9246 - val_accuracy: 0.9396 - val_loss: 0.3813 - learning_rate: 1.0000e-04\n",
      "Epoch 61/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 161ms/step - accuracy: 0.7718 - loss: 0.9270 - val_accuracy: 0.9483 - val_loss: 0.3529 - learning_rate: 1.0000e-04\n",
      "Epoch 62/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 163ms/step - accuracy: 0.7774 - loss: 0.9136 - val_accuracy: 0.9467 - val_loss: 0.3684 - learning_rate: 1.0000e-04\n",
      "Epoch 63/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 164ms/step - accuracy: 0.7720 - loss: 0.9305 - val_accuracy: 0.9407 - val_loss: 0.3898 - learning_rate: 1.0000e-04\n",
      "Epoch 64/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.7760 - loss: 0.9272 - val_accuracy: 0.9464 - val_loss: 0.3544 - learning_rate: 1.0000e-04\n",
      "Epoch 65/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 165ms/step - accuracy: 0.7815 - loss: 0.9046 - val_accuracy: 0.9461 - val_loss: 0.3608 - learning_rate: 1.0000e-04\n",
      "Epoch 66/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 163ms/step - accuracy: 0.7713 - loss: 0.9241 - val_accuracy: 0.9438 - val_loss: 0.3580 - learning_rate: 1.0000e-04\n",
      "Epoch 67/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 161ms/step - accuracy: 0.7851 - loss: 0.8835 - val_accuracy: 0.9555 - val_loss: 0.3281 - learning_rate: 2.0000e-05\n",
      "Epoch 68/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.7933 - loss: 0.8535 - val_accuracy: 0.9551 - val_loss: 0.3251 - learning_rate: 2.0000e-05\n",
      "Epoch 69/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 163ms/step - accuracy: 0.7982 - loss: 0.8389 - val_accuracy: 0.9583 - val_loss: 0.3172 - learning_rate: 2.0000e-05\n",
      "Epoch 70/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 166ms/step - accuracy: 0.7960 - loss: 0.8502 - val_accuracy: 0.9573 - val_loss: 0.3157 - learning_rate: 2.0000e-05\n",
      "Epoch 71/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 163ms/step - accuracy: 0.7970 - loss: 0.8406 - val_accuracy: 0.9567 - val_loss: 0.3154 - learning_rate: 2.0000e-05\n",
      "Epoch 72/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 162ms/step - accuracy: 0.7987 - loss: 0.8321 - val_accuracy: 0.9593 - val_loss: 0.3104 - learning_rate: 2.0000e-05\n",
      "Epoch 73/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 163ms/step - accuracy: 0.8002 - loss: 0.8299 - val_accuracy: 0.9590 - val_loss: 0.3107 - learning_rate: 2.0000e-05\n",
      "Epoch 74/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 161ms/step - accuracy: 0.7997 - loss: 0.8329 - val_accuracy: 0.9594 - val_loss: 0.3051 - learning_rate: 2.0000e-05\n",
      "Epoch 75/75\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.8015 - loss: 0.8252 - val_accuracy: 0.9575 - val_loss: 0.3094 - learning_rate: 2.0000e-05\n",
      "\u001b[1m544/544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.9644 - loss: 0.2881\n",
      "\n",
      "Final Test Accuracy: 0.9574\n",
      "Final Test Loss: 0.3096\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.2, patience=5)\n",
    "]\n",
    "\n",
    "# ========================\n",
    "# Training & Evaluation\n",
    "# ========================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=75,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Final evaluation\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('/home/adithya/projects/ASL-CNN-Project/models/testy.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anotha model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_90[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_32       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_37         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ conv2d_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_12… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_33       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_38         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_13… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_34       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_39         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_100[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_101[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_90 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_90[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_32       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_91 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_32[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_92 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │         \u001b[38;5;34m33\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_93 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_37         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m32\u001b[0m)               │            │ conv2d_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_12… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_94 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_33       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_95 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ activation_33[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_96 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │         \u001b[38;5;34m65\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_97 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m2,112\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_38         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_31 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_13… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_98 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_34       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_99 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_34[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_100 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │        \u001b[38;5;34m129\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_101 (\u001b[38;5;33mConv2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_39         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_100[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_101[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_32 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m3,741\u001b[0m │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,248</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321,248\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">319,648</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m319,648\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> (6.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,600\u001b[0m (6.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ========================\n",
    "# Enhanced Preprocessing\n",
    "# ========================\n",
    "def enhanced_edge_preprocessing(img):\n",
    "    \"\"\"Edge detection with gradient preservation\"\"\"\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Core edge detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Preserve gradients for texture\n",
    "    gradient = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    gradient = cv2.normalize(gradient, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    combined = cv2.addWeighted(edges, 0.8, gradient, 0.2, 0)\n",
    "    return np.stack([combined]*3, axis=-1).astype(np.float32) / 255.0\n",
    "\n",
    "# ========================\n",
    "# Adjusted Data Augmentation\n",
    "# ========================\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=enhanced_edge_preprocessing,\n",
    "    rotation_range=15,  # Reduced from 20\n",
    "    width_shift_range=0.15,  # Reduced from 0.2\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,  # Reduced from 0.2\n",
    "    brightness_range=[0.9, 1.1],  # Narrower range\n",
    "    shear_range=0.1,  # Reduced from 0.2\n",
    "    channel_shift_range=10.0,  # Added mild color variation\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=enhanced_edge_preprocessing\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# Modified Model Architecture\n",
    "# ========================\n",
    "def residual_block(inputs, filters, strides=1):\n",
    "    x = Conv2D(filters, (3,3), strides=strides, padding='same', \n",
    "               kernel_regularizer=l2(0.001))(inputs)  # Reduced from 0.0018\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, (3,3), padding='same', \n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Simplified attention\n",
    "    attention = Conv2D(1, (1,1), activation='sigmoid')(x)\n",
    "    x = Multiply()([x, attention])\n",
    "    \n",
    "    shortcut = inputs\n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1,1), strides=strides)(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    return Add()([x, shortcut])\n",
    "\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "\n",
    "# Feature extraction\n",
    "x = residual_block(inputs, 32)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.3)(x)  # Reduced from 0.4\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.35)(x)  # Adjusted\n",
    "\n",
    "x = residual_block(x, 128)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Classifier with enhanced capacity\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.0005))(x)  # Reduced L2\n",
    "x = BatchNormalization()(x)  # Added BN\n",
    "x = Dropout(0.3)(x)  # Reduced from 0.4\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# ========================\n",
    "# Optimized Training Setup\n",
    "# ========================\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # Increased from 0.0005\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=12, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=3)  # More responsive\n",
    "]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 149ms/step - accuracy: 0.0761 - loss: 3.8446 - val_accuracy: 0.1949 - val_loss: 2.8379 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 141ms/step - accuracy: 0.2051 - loss: 2.8598 - val_accuracy: 0.3376 - val_loss: 2.3915 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 136ms/step - accuracy: 0.3200 - loss: 2.4986 - val_accuracy: 0.4333 - val_loss: 2.1065 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 132ms/step - accuracy: 0.4050 - loss: 2.2556 - val_accuracy: 0.5636 - val_loss: 1.7053 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 132ms/step - accuracy: 0.4788 - loss: 2.0421 - val_accuracy: 0.5294 - val_loss: 1.8168 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 132ms/step - accuracy: 0.5338 - loss: 1.8888 - val_accuracy: 0.6210 - val_loss: 1.5179 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 132ms/step - accuracy: 0.5622 - loss: 1.7955 - val_accuracy: 0.7205 - val_loss: 1.2564 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 132ms/step - accuracy: 0.6000 - loss: 1.6885 - val_accuracy: 0.7829 - val_loss: 1.0639 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 132ms/step - accuracy: 0.6230 - loss: 1.6196 - val_accuracy: 0.7751 - val_loss: 1.0516 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 133ms/step - accuracy: 0.6395 - loss: 1.5672 - val_accuracy: 0.7348 - val_loss: 1.1955 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 140ms/step - accuracy: 0.6590 - loss: 1.5040 - val_accuracy: 0.8008 - val_loss: 0.9940 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 135ms/step - accuracy: 0.6777 - loss: 1.4449 - val_accuracy: 0.8176 - val_loss: 0.9660 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 138ms/step - accuracy: 0.6865 - loss: 1.4195 - val_accuracy: 0.8443 - val_loss: 0.8467 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 136ms/step - accuracy: 0.6876 - loss: 1.4066 - val_accuracy: 0.8524 - val_loss: 0.8387 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 138ms/step - accuracy: 0.7093 - loss: 1.3351 - val_accuracy: 0.8613 - val_loss: 0.8305 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 135ms/step - accuracy: 0.7077 - loss: 1.3374 - val_accuracy: 0.8415 - val_loss: 0.8575 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 136ms/step - accuracy: 0.7167 - loss: 1.3084 - val_accuracy: 0.7768 - val_loss: 1.0303 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 135ms/step - accuracy: 0.7216 - loss: 1.2898 - val_accuracy: 0.8427 - val_loss: 0.8613 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 133ms/step - accuracy: 0.7633 - loss: 1.1244 - val_accuracy: 0.9048 - val_loss: 0.6244 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 135ms/step - accuracy: 0.7738 - loss: 1.0565 - val_accuracy: 0.9027 - val_loss: 0.5929 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 137ms/step - accuracy: 0.7759 - loss: 1.0234 - val_accuracy: 0.9075 - val_loss: 0.5815 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 135ms/step - accuracy: 0.7871 - loss: 0.9916 - val_accuracy: 0.9071 - val_loss: 0.5528 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 134ms/step - accuracy: 0.7832 - loss: 0.9749 - val_accuracy: 0.9187 - val_loss: 0.5241 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 138ms/step - accuracy: 0.7890 - loss: 0.9603 - val_accuracy: 0.9180 - val_loss: 0.5253 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 137ms/step - accuracy: 0.7894 - loss: 0.9587 - val_accuracy: 0.9313 - val_loss: 0.4823 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 141ms/step - accuracy: 0.7885 - loss: 0.9527 - val_accuracy: 0.9184 - val_loss: 0.5071 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 138ms/step - accuracy: 0.7922 - loss: 0.9316 - val_accuracy: 0.9201 - val_loss: 0.4998 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 137ms/step - accuracy: 0.7939 - loss: 0.9273 - val_accuracy: 0.9081 - val_loss: 0.5337 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 134ms/step - accuracy: 0.8156 - loss: 0.8564 - val_accuracy: 0.9461 - val_loss: 0.4104 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 139ms/step - accuracy: 0.8259 - loss: 0.8052 - val_accuracy: 0.9484 - val_loss: 0.3949 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 139ms/step - accuracy: 0.8327 - loss: 0.7774 - val_accuracy: 0.9503 - val_loss: 0.3793 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 142ms/step - accuracy: 0.8314 - loss: 0.7666 - val_accuracy: 0.9374 - val_loss: 0.4095 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 140ms/step - accuracy: 0.8329 - loss: 0.7622 - val_accuracy: 0.9278 - val_loss: 0.4235 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 138ms/step - accuracy: 0.8321 - loss: 0.7578 - val_accuracy: 0.9541 - val_loss: 0.3560 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 140ms/step - accuracy: 0.8340 - loss: 0.7444 - val_accuracy: 0.9505 - val_loss: 0.3618 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 141ms/step - accuracy: 0.8360 - loss: 0.7392 - val_accuracy: 0.9478 - val_loss: 0.3588 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 139ms/step - accuracy: 0.8347 - loss: 0.7432 - val_accuracy: 0.9472 - val_loss: 0.3647 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 136ms/step - accuracy: 0.8532 - loss: 0.6814 - val_accuracy: 0.9618 - val_loss: 0.3156 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 147ms/step - accuracy: 0.8547 - loss: 0.6683 - val_accuracy: 0.9609 - val_loss: 0.3055 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 137ms/step - accuracy: 0.8574 - loss: 0.6564 - val_accuracy: 0.9604 - val_loss: 0.3096 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 140ms/step - accuracy: 0.8560 - loss: 0.6456 - val_accuracy: 0.9599 - val_loss: 0.3036 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 138ms/step - accuracy: 0.8617 - loss: 0.6375 - val_accuracy: 0.9627 - val_loss: 0.2922 - learning_rate: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 133ms/step - accuracy: 0.8584 - loss: 0.6373 - val_accuracy: 0.9619 - val_loss: 0.2969 - learning_rate: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 134ms/step - accuracy: 0.8643 - loss: 0.6250 - val_accuracy: 0.9632 - val_loss: 0.2905 - learning_rate: 1.2500e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 133ms/step - accuracy: 0.8635 - loss: 0.6149 - val_accuracy: 0.9625 - val_loss: 0.2846 - learning_rate: 1.2500e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 134ms/step - accuracy: 0.8580 - loss: 0.6210 - val_accuracy: 0.9637 - val_loss: 0.2772 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 136ms/step - accuracy: 0.8624 - loss: 0.6169 - val_accuracy: 0.9652 - val_loss: 0.2713 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 138ms/step - accuracy: 0.8683 - loss: 0.6008 - val_accuracy: 0.9646 - val_loss: 0.2727 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 139ms/step - accuracy: 0.8644 - loss: 0.6090 - val_accuracy: 0.9659 - val_loss: 0.2703 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 138ms/step - accuracy: 0.8634 - loss: 0.6041 - val_accuracy: 0.9654 - val_loss: 0.2651 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 137ms/step - accuracy: 0.8637 - loss: 0.6030 - val_accuracy: 0.9653 - val_loss: 0.2652 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 139ms/step - accuracy: 0.8640 - loss: 0.6060 - val_accuracy: 0.9598 - val_loss: 0.2762 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 138ms/step - accuracy: 0.8625 - loss: 0.6054 - val_accuracy: 0.9662 - val_loss: 0.2531 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 139ms/step - accuracy: 0.8655 - loss: 0.5941 - val_accuracy: 0.9639 - val_loss: 0.2614 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 140ms/step - accuracy: 0.8656 - loss: 0.5863 - val_accuracy: 0.9676 - val_loss: 0.2539 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 140ms/step - accuracy: 0.8626 - loss: 0.5971 - val_accuracy: 0.9668 - val_loss: 0.2534 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 143ms/step - accuracy: 0.8741 - loss: 0.5583 - val_accuracy: 0.9720 - val_loss: 0.2356 - learning_rate: 6.2500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 140ms/step - accuracy: 0.8772 - loss: 0.5494 - val_accuracy: 0.9698 - val_loss: 0.2393 - learning_rate: 6.2500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 137ms/step - accuracy: 0.8801 - loss: 0.5411 - val_accuracy: 0.9710 - val_loss: 0.2326 - learning_rate: 6.2500e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 140ms/step - accuracy: 0.8773 - loss: 0.5434 - val_accuracy: 0.9717 - val_loss: 0.2332 - learning_rate: 6.2500e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 140ms/step - accuracy: 0.8796 - loss: 0.5392 - val_accuracy: 0.9722 - val_loss: 0.2304 - learning_rate: 6.2500e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 136ms/step - accuracy: 0.8781 - loss: 0.5435 - val_accuracy: 0.9697 - val_loss: 0.2299 - learning_rate: 6.2500e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 138ms/step - accuracy: 0.8768 - loss: 0.5405 - val_accuracy: 0.9722 - val_loss: 0.2272 - learning_rate: 6.2500e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 139ms/step - accuracy: 0.8788 - loss: 0.5337 - val_accuracy: 0.9731 - val_loss: 0.2214 - learning_rate: 6.2500e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 137ms/step - accuracy: 0.8810 - loss: 0.5270 - val_accuracy: 0.9732 - val_loss: 0.2175 - learning_rate: 6.2500e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 145ms/step - accuracy: 0.8822 - loss: 0.5236 - val_accuracy: 0.9718 - val_loss: 0.2238 - learning_rate: 6.2500e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 136ms/step - accuracy: 0.8814 - loss: 0.5223 - val_accuracy: 0.9752 - val_loss: 0.2136 - learning_rate: 6.2500e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 139ms/step - accuracy: 0.8823 - loss: 0.5284 - val_accuracy: 0.9744 - val_loss: 0.2154 - learning_rate: 6.2500e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 152ms/step - accuracy: 0.8810 - loss: 0.5195 - val_accuracy: 0.9741 - val_loss: 0.2155 - learning_rate: 6.2500e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 139ms/step - accuracy: 0.8835 - loss: 0.5120 - val_accuracy: 0.9726 - val_loss: 0.2112 - learning_rate: 6.2500e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 137ms/step - accuracy: 0.8810 - loss: 0.5157 - val_accuracy: 0.9730 - val_loss: 0.2114 - learning_rate: 6.2500e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 137ms/step - accuracy: 0.8788 - loss: 0.5237 - val_accuracy: 0.9752 - val_loss: 0.2107 - learning_rate: 6.2500e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 137ms/step - accuracy: 0.8807 - loss: 0.5212 - val_accuracy: 0.9711 - val_loss: 0.2164 - learning_rate: 6.2500e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 139ms/step - accuracy: 0.8817 - loss: 0.5174 - val_accuracy: 0.9730 - val_loss: 0.2103 - learning_rate: 6.2500e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 138ms/step - accuracy: 0.8868 - loss: 0.5007 - val_accuracy: 0.9748 - val_loss: 0.2073 - learning_rate: 6.2500e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 142ms/step - accuracy: 0.8838 - loss: 0.5079 - val_accuracy: 0.9756 - val_loss: 0.2036 - learning_rate: 6.2500e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 178ms/step - accuracy: 0.8818 - loss: 0.5080 - val_accuracy: 0.9763 - val_loss: 0.2034 - learning_rate: 6.2500e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 136ms/step - accuracy: 0.8806 - loss: 0.5132 - val_accuracy: 0.9757 - val_loss: 0.2023 - learning_rate: 6.2500e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 134ms/step - accuracy: 0.8864 - loss: 0.5065 - val_accuracy: 0.9755 - val_loss: 0.2020 - learning_rate: 6.2500e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 134ms/step - accuracy: 0.8831 - loss: 0.5049 - val_accuracy: 0.9712 - val_loss: 0.2108 - learning_rate: 6.2500e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 141ms/step - accuracy: 0.8845 - loss: 0.4996 - val_accuracy: 0.9751 - val_loss: 0.2027 - learning_rate: 6.2500e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 198ms/step - accuracy: 0.8845 - loss: 0.4985 - val_accuracy: 0.9748 - val_loss: 0.2037 - learning_rate: 6.2500e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 151ms/step - accuracy: 0.8875 - loss: 0.4939 - val_accuracy: 0.9755 - val_loss: 0.1953 - learning_rate: 3.1250e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 153ms/step - accuracy: 0.8932 - loss: 0.4681 - val_accuracy: 0.9780 - val_loss: 0.1897 - learning_rate: 3.1250e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 144ms/step - accuracy: 0.8879 - loss: 0.4818 - val_accuracy: 0.9758 - val_loss: 0.1940 - learning_rate: 3.1250e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 149ms/step - accuracy: 0.8927 - loss: 0.4714 - val_accuracy: 0.9765 - val_loss: 0.1893 - learning_rate: 3.1250e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2175/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 266ms/step - accuracy: 0.8893 - loss: 0.4806 - val_accuracy: 0.9778 - val_loss: 0.1882 - learning_rate: 3.1250e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m1982/2175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2:08\u001b[0m 665ms/step - accuracy: 0.8928 - loss: 0.4758"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Training Execution\n",
    "# ========================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    batch_size=48,  # Increased if memory permits\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issok if it crashed sexy model vibe there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52200 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# ========================\n",
    "# Dataset Configuration\n",
    "# ========================\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../dataset/asl_split\"))\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "# ========================\n",
    "# Proven Preprocessing\n",
    "# ========================\n",
    "def preprocess_image(img):\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    return np.stack([edges]*3, axis=-1).astype(np.float32) / 255.0\n",
    "\n",
    "# ========================\n",
    "# Data Generators (Original Working Version)\n",
    "# ========================\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# Architecture (Proven Working Version)\n",
    "# ========================\n",
    "def self_attention_block(inputs, filters):\n",
    "    x = Conv2D(filters//8, (1,1), activation='relu')(inputs)\n",
    "    attention = Conv2D(1, (1,1), activation='sigmoid')(x)\n",
    "    return Multiply()([inputs, attention])\n",
    "\n",
    "def residual_block(inputs, filters, strides=1):\n",
    "    x = Conv2D(filters, (3,3), strides=strides, padding='same', \n",
    "               kernel_regularizer=l2(0.001))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, (3,3), padding='same', \n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = self_attention_block(x, filters)\n",
    "    \n",
    "    shortcut = inputs\n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1,1), strides=strides)(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    return Add()([x, shortcut])\n",
    "\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "x = residual_block(inputs, 32)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.25)(x)\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.3)(x)\n",
    "\n",
    "x = residual_block(x, 128)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# ========================\n",
    "# Guaranteed Training Setup\n",
    "# ========================\n",
    "checkpoint_path = \"asl_checkpoint.weights.h5\"  # Fixed extension\n",
    "initial_epoch = 0\n",
    "\n",
    "# Resume training if checkpoint exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "    initial_epoch = 22  # Set to your last completed epoch\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00075),  # Optimal from previous success\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=3, verbose=1),\n",
    "    EarlyStopping(patience=10, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ conv2d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ conv2d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_22    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_22… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ conv2d_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_7          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_23    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_23… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ conv2d_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_8          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m132\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m4\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_51 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m5\u001b[0m │ conv2d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_52 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m32\u001b[0m)               │            │ conv2d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_22    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_22… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_53 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_54 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_55 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m520\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m8\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_56 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m9\u001b[0m │ conv2d_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_57 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m2,112\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_7          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_23    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_23… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_58 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_59 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_60 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m2,064\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_61 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │         \u001b[38;5;34m17\u001b[0m │ conv2d_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_62 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_8          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m3,741\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">323,256</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m323,256\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321,912</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321,912\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> (5.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,344\u001b[0m (5.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:30:18.494068: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:382] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1472/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28s\u001b[0m 180ms/step - accuracy: 0.0906 - loss: 3.4988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:34:43.829460: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_4041', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.0948 - loss: 3.4700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:35:24.629999: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_435', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.14741, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 202ms/step - accuracy: 0.0948 - loss: 3.4699 - val_accuracy: 0.1474 - val_loss: 3.2394 - learning_rate: 7.5000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.2152 - loss: 2.7788\n",
      "Epoch 2: val_accuracy improved from 0.14741 to 0.26977, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 190ms/step - accuracy: 0.2152 - loss: 2.7788 - val_accuracy: 0.2698 - val_loss: 2.5768 - learning_rate: 7.5000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.3045 - loss: 2.4873\n",
      "Epoch 3: val_accuracy improved from 0.26977 to 0.45385, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 191ms/step - accuracy: 0.3046 - loss: 2.4873 - val_accuracy: 0.4539 - val_loss: 1.9856 - learning_rate: 7.5000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3974 - loss: 2.1993\n",
      "Epoch 4: val_accuracy improved from 0.45385 to 0.59845, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 194ms/step - accuracy: 0.3974 - loss: 2.1993 - val_accuracy: 0.5984 - val_loss: 1.5517 - learning_rate: 7.5000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.4656 - loss: 2.0114\n",
      "Epoch 5: val_accuracy did not improve from 0.59845\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 198ms/step - accuracy: 0.4656 - loss: 2.0114 - val_accuracy: 0.4894 - val_loss: 1.8534 - learning_rate: 7.5000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.5018 - loss: 1.8886\n",
      "Epoch 6: val_accuracy improved from 0.59845 to 0.60603, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 198ms/step - accuracy: 0.5018 - loss: 1.8886 - val_accuracy: 0.6060 - val_loss: 1.5019 - learning_rate: 7.5000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.5437 - loss: 1.7721\n",
      "Epoch 7: val_accuracy improved from 0.60603 to 0.65218, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 201ms/step - accuracy: 0.5437 - loss: 1.7721 - val_accuracy: 0.6522 - val_loss: 1.3621 - learning_rate: 7.5000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.5662 - loss: 1.7077\n",
      "Epoch 8: val_accuracy did not improve from 0.65218\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.5662 - loss: 1.7077 - val_accuracy: 0.4451 - val_loss: 2.1572 - learning_rate: 7.5000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.5925 - loss: 1.6231\n",
      "Epoch 9: val_accuracy improved from 0.65218 to 0.68787, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.5925 - loss: 1.6230 - val_accuracy: 0.6879 - val_loss: 1.2455 - learning_rate: 7.5000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.6118 - loss: 1.5618\n",
      "Epoch 10: val_accuracy did not improve from 0.68787\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.6118 - loss: 1.5618 - val_accuracy: 0.6353 - val_loss: 1.3722 - learning_rate: 7.5000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6340 - loss: 1.4988\n",
      "Epoch 11: val_accuracy improved from 0.68787 to 0.77851, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.6340 - loss: 1.4988 - val_accuracy: 0.7785 - val_loss: 1.0418 - learning_rate: 7.5000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6560 - loss: 1.4434\n",
      "Epoch 12: val_accuracy did not improve from 0.77851\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 194ms/step - accuracy: 0.6560 - loss: 1.4434 - val_accuracy: 0.7347 - val_loss: 1.1528 - learning_rate: 7.5000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6639 - loss: 1.4187\n",
      "Epoch 13: val_accuracy improved from 0.77851 to 0.82466, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 199ms/step - accuracy: 0.6639 - loss: 1.4187 - val_accuracy: 0.8247 - val_loss: 0.9522 - learning_rate: 7.5000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6735 - loss: 1.4006\n",
      "Epoch 14: val_accuracy improved from 0.82466 to 0.82989, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 190ms/step - accuracy: 0.6735 - loss: 1.4006 - val_accuracy: 0.8299 - val_loss: 0.9023 - learning_rate: 7.5000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6812 - loss: 1.3675\n",
      "Epoch 15: val_accuracy improved from 0.82989 to 0.83701, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 190ms/step - accuracy: 0.6812 - loss: 1.3675 - val_accuracy: 0.8370 - val_loss: 0.8831 - learning_rate: 7.5000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6877 - loss: 1.3491\n",
      "Epoch 16: val_accuracy improved from 0.83701 to 0.84379, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 191ms/step - accuracy: 0.6877 - loss: 1.3491 - val_accuracy: 0.8438 - val_loss: 0.8325 - learning_rate: 7.5000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6904 - loss: 1.3333\n",
      "Epoch 17: val_accuracy improved from 0.84379 to 0.85385, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 189ms/step - accuracy: 0.6904 - loss: 1.3333 - val_accuracy: 0.8539 - val_loss: 0.8323 - learning_rate: 7.5000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7053 - loss: 1.2892\n",
      "Epoch 18: val_accuracy did not improve from 0.85385\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.7053 - loss: 1.2892 - val_accuracy: 0.8301 - val_loss: 0.8752 - learning_rate: 7.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7153 - loss: 1.2740\n",
      "Epoch 19: val_accuracy improved from 0.85385 to 0.86017, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.7153 - loss: 1.2740 - val_accuracy: 0.8602 - val_loss: 0.8463 - learning_rate: 7.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7145 - loss: 1.2637\n",
      "Epoch 20: val_accuracy improved from 0.86017 to 0.86580, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.7145 - loss: 1.2637 - val_accuracy: 0.8658 - val_loss: 0.7823 - learning_rate: 7.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7235 - loss: 1.2487\n",
      "Epoch 21: val_accuracy improved from 0.86580 to 0.88678, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.7235 - loss: 1.2487 - val_accuracy: 0.8868 - val_loss: 0.7569 - learning_rate: 7.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7233 - loss: 1.2503\n",
      "Epoch 22: val_accuracy improved from 0.88678 to 0.89770, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.7233 - loss: 1.2503 - val_accuracy: 0.8977 - val_loss: 0.7007 - learning_rate: 7.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7269 - loss: 1.2291\n",
      "Epoch 23: val_accuracy did not improve from 0.89770\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.7269 - loss: 1.2291 - val_accuracy: 0.8386 - val_loss: 0.8473 - learning_rate: 7.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7359 - loss: 1.2096\n",
      "Epoch 24: val_accuracy did not improve from 0.89770\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.7359 - loss: 1.2096 - val_accuracy: 0.8419 - val_loss: 0.8919 - learning_rate: 7.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.7350 - loss: 1.2196\n",
      "Epoch 25: val_accuracy did not improve from 0.89770\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 194ms/step - accuracy: 0.7350 - loss: 1.2196 - val_accuracy: 0.8894 - val_loss: 0.7097 - learning_rate: 7.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7687 - loss: 1.0981\n",
      "Epoch 26: val_accuracy improved from 0.89770 to 0.91621, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.7687 - loss: 1.0981 - val_accuracy: 0.9162 - val_loss: 0.6148 - learning_rate: 3.7500e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7803 - loss: 1.0321\n",
      "Epoch 27: val_accuracy did not improve from 0.91621\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.7803 - loss: 1.0320 - val_accuracy: 0.9103 - val_loss: 0.6001 - learning_rate: 3.7500e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7799 - loss: 1.0066\n",
      "Epoch 28: val_accuracy improved from 0.91621 to 0.92810, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.7799 - loss: 1.0066 - val_accuracy: 0.9281 - val_loss: 0.5499 - learning_rate: 3.7500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7853 - loss: 0.9879\n",
      "Epoch 29: val_accuracy did not improve from 0.92810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 193ms/step - accuracy: 0.7853 - loss: 0.9879 - val_accuracy: 0.9131 - val_loss: 0.5683 - learning_rate: 3.7500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7847 - loss: 0.9831\n",
      "Epoch 30: val_accuracy did not improve from 0.92810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 190ms/step - accuracy: 0.7847 - loss: 0.9831 - val_accuracy: 0.9143 - val_loss: 0.5543 - learning_rate: 3.7500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.7949 - loss: 0.9499\n",
      "Epoch 31: val_accuracy improved from 0.92810 to 0.93034, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.7949 - loss: 0.9499 - val_accuracy: 0.9303 - val_loss: 0.5187 - learning_rate: 3.7500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7917 - loss: 0.9511\n",
      "Epoch 32: val_accuracy did not improve from 0.93034\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.7917 - loss: 0.9511 - val_accuracy: 0.9100 - val_loss: 0.5677 - learning_rate: 3.7500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7990 - loss: 0.9331\n",
      "Epoch 33: val_accuracy did not improve from 0.93034\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.7990 - loss: 0.9331 - val_accuracy: 0.9263 - val_loss: 0.5254 - learning_rate: 3.7500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7936 - loss: 0.9405\n",
      "Epoch 34: val_accuracy did not improve from 0.93034\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.7936 - loss: 0.9404 - val_accuracy: 0.9138 - val_loss: 0.5605 - learning_rate: 3.7500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8144 - loss: 0.8694\n",
      "Epoch 35: val_accuracy improved from 0.93034 to 0.94529, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.8144 - loss: 0.8694 - val_accuracy: 0.9453 - val_loss: 0.4531 - learning_rate: 1.8750e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8217 - loss: 0.8363\n",
      "Epoch 36: val_accuracy did not improve from 0.94529\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8217 - loss: 0.8363 - val_accuracy: 0.9283 - val_loss: 0.4795 - learning_rate: 1.8750e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8217 - loss: 0.8195\n",
      "Epoch 37: val_accuracy did not improve from 0.94529\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8217 - loss: 0.8195 - val_accuracy: 0.9425 - val_loss: 0.4373 - learning_rate: 1.8750e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8237 - loss: 0.8151\n",
      "Epoch 38: val_accuracy improved from 0.94529 to 0.94862, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8237 - loss: 0.8151 - val_accuracy: 0.9486 - val_loss: 0.4131 - learning_rate: 1.8750e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8272 - loss: 0.7925\n",
      "Epoch 39: val_accuracy did not improve from 0.94862\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8272 - loss: 0.7925 - val_accuracy: 0.9348 - val_loss: 0.4511 - learning_rate: 1.8750e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8331 - loss: 0.7847\n",
      "Epoch 40: val_accuracy did not improve from 0.94862\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.8331 - loss: 0.7847 - val_accuracy: 0.9398 - val_loss: 0.4260 - learning_rate: 1.8750e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8287 - loss: 0.7882\n",
      "Epoch 41: val_accuracy did not improve from 0.94862\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8287 - loss: 0.7882 - val_accuracy: 0.9443 - val_loss: 0.4094 - learning_rate: 1.8750e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8290 - loss: 0.7855\n",
      "Epoch 42: val_accuracy did not improve from 0.94862\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8290 - loss: 0.7855 - val_accuracy: 0.9459 - val_loss: 0.4102 - learning_rate: 1.8750e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8312 - loss: 0.7721\n",
      "Epoch 43: val_accuracy did not improve from 0.94862\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 191ms/step - accuracy: 0.8312 - loss: 0.7721 - val_accuracy: 0.9442 - val_loss: 0.4013 - learning_rate: 1.8750e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8364 - loss: 0.7585\n",
      "Epoch 44: val_accuracy did not improve from 0.94862\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8364 - loss: 0.7585 - val_accuracy: 0.9441 - val_loss: 0.4024 - learning_rate: 1.8750e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8323 - loss: 0.7579\n",
      "Epoch 45: val_accuracy improved from 0.94862 to 0.95029, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8323 - loss: 0.7579 - val_accuracy: 0.9503 - val_loss: 0.3866 - learning_rate: 1.8750e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8363 - loss: 0.7432\n",
      "Epoch 46: val_accuracy did not improve from 0.95029\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8363 - loss: 0.7432 - val_accuracy: 0.9434 - val_loss: 0.4099 - learning_rate: 1.8750e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8342 - loss: 0.7551\n",
      "Epoch 47: val_accuracy did not improve from 0.95029\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8342 - loss: 0.7551 - val_accuracy: 0.9496 - val_loss: 0.3821 - learning_rate: 1.8750e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8382 - loss: 0.7432\n",
      "Epoch 48: val_accuracy improved from 0.95029 to 0.95437, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8382 - loss: 0.7432 - val_accuracy: 0.9544 - val_loss: 0.3662 - learning_rate: 1.8750e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8359 - loss: 0.7495\n",
      "Epoch 49: val_accuracy improved from 0.95437 to 0.95454, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8359 - loss: 0.7495 - val_accuracy: 0.9545 - val_loss: 0.3684 - learning_rate: 1.8750e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8336 - loss: 0.7427\n",
      "Epoch 50: val_accuracy did not improve from 0.95454\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 191ms/step - accuracy: 0.8336 - loss: 0.7427 - val_accuracy: 0.9523 - val_loss: 0.3716 - learning_rate: 1.8750e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8382 - loss: 0.7326\n",
      "Epoch 51: val_accuracy improved from 0.95454 to 0.95856, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 193ms/step - accuracy: 0.8382 - loss: 0.7326 - val_accuracy: 0.9586 - val_loss: 0.3545 - learning_rate: 1.8750e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8436 - loss: 0.7272\n",
      "Epoch 52: val_accuracy did not improve from 0.95856\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 191ms/step - accuracy: 0.8436 - loss: 0.7272 - val_accuracy: 0.9507 - val_loss: 0.3667 - learning_rate: 1.8750e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8351 - loss: 0.7384\n",
      "Epoch 53: val_accuracy did not improve from 0.95856\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.8351 - loss: 0.7384 - val_accuracy: 0.9530 - val_loss: 0.3739 - learning_rate: 1.8750e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8383 - loss: 0.7323\n",
      "Epoch 54: val_accuracy improved from 0.95856 to 0.95868, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8383 - loss: 0.7323 - val_accuracy: 0.9587 - val_loss: 0.3457 - learning_rate: 1.8750e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8393 - loss: 0.7203\n",
      "Epoch 55: val_accuracy did not improve from 0.95868\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 193ms/step - accuracy: 0.8393 - loss: 0.7203 - val_accuracy: 0.9586 - val_loss: 0.3489 - learning_rate: 1.8750e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8417 - loss: 0.7224\n",
      "Epoch 56: val_accuracy did not improve from 0.95868\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8417 - loss: 0.7224 - val_accuracy: 0.9499 - val_loss: 0.3687 - learning_rate: 1.8750e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8425 - loss: 0.7184\n",
      "Epoch 57: val_accuracy did not improve from 0.95868\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8425 - loss: 0.7184 - val_accuracy: 0.9533 - val_loss: 0.3518 - learning_rate: 1.8750e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8536 - loss: 0.6733\n",
      "Epoch 58: val_accuracy improved from 0.95868 to 0.95937, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8536 - loss: 0.6733 - val_accuracy: 0.9594 - val_loss: 0.3315 - learning_rate: 9.3750e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8555 - loss: 0.6610\n",
      "Epoch 59: val_accuracy improved from 0.95937 to 0.96351, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 191ms/step - accuracy: 0.8555 - loss: 0.6610 - val_accuracy: 0.9635 - val_loss: 0.3203 - learning_rate: 9.3750e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8555 - loss: 0.6597\n",
      "Epoch 60: val_accuracy improved from 0.96351 to 0.96374, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.8555 - loss: 0.6597 - val_accuracy: 0.9637 - val_loss: 0.3103 - learning_rate: 9.3750e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8590 - loss: 0.6469\n",
      "Epoch 61: val_accuracy improved from 0.96374 to 0.96575, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8590 - loss: 0.6469 - val_accuracy: 0.9657 - val_loss: 0.3040 - learning_rate: 9.3750e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8608 - loss: 0.6425\n",
      "Epoch 62: val_accuracy did not improve from 0.96575\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8608 - loss: 0.6425 - val_accuracy: 0.9656 - val_loss: 0.3094 - learning_rate: 9.3750e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8603 - loss: 0.6380\n",
      "Epoch 63: val_accuracy did not improve from 0.96575\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8603 - loss: 0.6380 - val_accuracy: 0.9637 - val_loss: 0.3079 - learning_rate: 9.3750e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8649 - loss: 0.6268\n",
      "Epoch 64: val_accuracy did not improve from 0.96575\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8649 - loss: 0.6268 - val_accuracy: 0.9626 - val_loss: 0.3053 - learning_rate: 9.3750e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8672 - loss: 0.6147\n",
      "Epoch 65: val_accuracy improved from 0.96575 to 0.96764, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8672 - loss: 0.6147 - val_accuracy: 0.9676 - val_loss: 0.2912 - learning_rate: 4.6875e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8729 - loss: 0.6010\n",
      "Epoch 66: val_accuracy improved from 0.96764 to 0.96931, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8729 - loss: 0.6010 - val_accuracy: 0.9693 - val_loss: 0.2863 - learning_rate: 4.6875e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8732 - loss: 0.5965\n",
      "Epoch 67: val_accuracy improved from 0.96931 to 0.96989, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 191ms/step - accuracy: 0.8732 - loss: 0.5965 - val_accuracy: 0.9699 - val_loss: 0.2823 - learning_rate: 4.6875e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m1629/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8761 - loss: 0.5895\n",
      "Epoch 68: val_accuracy did not improve from 0.96989\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8761 - loss: 0.5895 - val_accuracy: 0.9699 - val_loss: 0.2799 - learning_rate: 4.6875e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8734 - loss: 0.5937\n",
      "Epoch 69: val_accuracy improved from 0.96989 to 0.97109, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.8734 - loss: 0.5937 - val_accuracy: 0.9711 - val_loss: 0.2809 - learning_rate: 4.6875e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8697 - loss: 0.5937\n",
      "Epoch 70: val_accuracy improved from 0.97109 to 0.97213, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 194ms/step - accuracy: 0.8697 - loss: 0.5937 - val_accuracy: 0.9721 - val_loss: 0.2715 - learning_rate: 4.6875e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8751 - loss: 0.5867\n",
      "Epoch 71: val_accuracy did not improve from 0.97213\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8751 - loss: 0.5867 - val_accuracy: 0.9707 - val_loss: 0.2746 - learning_rate: 4.6875e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8738 - loss: 0.5855\n",
      "Epoch 72: val_accuracy did not improve from 0.97213\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 191ms/step - accuracy: 0.8738 - loss: 0.5855 - val_accuracy: 0.9699 - val_loss: 0.2731 - learning_rate: 4.6875e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m1625/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.8753 - loss: 0.5782\n",
      "Epoch 73: val_accuracy did not improve from 0.97213\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 191ms/step - accuracy: 0.8753 - loss: 0.5782 - val_accuracy: 0.9701 - val_loss: 0.2719 - learning_rate: 4.6875e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8776 - loss: 0.5692\n",
      "Epoch 74: val_accuracy improved from 0.97213 to 0.97339, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8776 - loss: 0.5692 - val_accuracy: 0.9734 - val_loss: 0.2651 - learning_rate: 2.3438e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8804 - loss: 0.5580\n",
      "Epoch 75: val_accuracy did not improve from 0.97339\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8804 - loss: 0.5580 - val_accuracy: 0.9731 - val_loss: 0.2632 - learning_rate: 2.3438e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8835 - loss: 0.5531\n",
      "Epoch 76: val_accuracy did not improve from 0.97339\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8835 - loss: 0.5531 - val_accuracy: 0.9732 - val_loss: 0.2595 - learning_rate: 2.3438e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8806 - loss: 0.5573\n",
      "Epoch 77: val_accuracy did not improve from 0.97339\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8806 - loss: 0.5573 - val_accuracy: 0.9713 - val_loss: 0.2631 - learning_rate: 2.3438e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8808 - loss: 0.5608\n",
      "Epoch 78: val_accuracy improved from 0.97339 to 0.97408, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8808 - loss: 0.5608 - val_accuracy: 0.9741 - val_loss: 0.2586 - learning_rate: 2.3438e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8826 - loss: 0.5552\n",
      "Epoch 79: val_accuracy did not improve from 0.97408\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 191ms/step - accuracy: 0.8826 - loss: 0.5552 - val_accuracy: 0.9732 - val_loss: 0.2601 - learning_rate: 2.3438e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m1624/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.8804 - loss: 0.5578\n",
      "Epoch 80: val_accuracy did not improve from 0.97408\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.8804 - loss: 0.5577 - val_accuracy: 0.9733 - val_loss: 0.2553 - learning_rate: 2.3438e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8827 - loss: 0.5521\n",
      "Epoch 81: val_accuracy did not improve from 0.97408\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 191ms/step - accuracy: 0.8827 - loss: 0.5521 - val_accuracy: 0.9739 - val_loss: 0.2539 - learning_rate: 2.3438e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8837 - loss: 0.5448\n",
      "Epoch 82: val_accuracy improved from 0.97408 to 0.97448, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8837 - loss: 0.5448 - val_accuracy: 0.9745 - val_loss: 0.2536 - learning_rate: 2.3438e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8827 - loss: 0.5475\n",
      "Epoch 83: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 190ms/step - accuracy: 0.8827 - loss: 0.5475 - val_accuracy: 0.9734 - val_loss: 0.2532 - learning_rate: 2.3438e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8834 - loss: 0.5404\n",
      "Epoch 84: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 193ms/step - accuracy: 0.8834 - loss: 0.5404 - val_accuracy: 0.9732 - val_loss: 0.2558 - learning_rate: 2.3438e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8832 - loss: 0.5422\n",
      "Epoch 85: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8832 - loss: 0.5422 - val_accuracy: 0.9742 - val_loss: 0.2512 - learning_rate: 2.3438e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8803 - loss: 0.5522\n",
      "Epoch 86: val_accuracy did not improve from 0.97448\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.8803 - loss: 0.5522 - val_accuracy: 0.9732 - val_loss: 0.2527 - learning_rate: 2.3438e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8855 - loss: 0.5405\n",
      "Epoch 87: val_accuracy improved from 0.97448 to 0.97477, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 193ms/step - accuracy: 0.8855 - loss: 0.5405 - val_accuracy: 0.9748 - val_loss: 0.2483 - learning_rate: 2.3438e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8793 - loss: 0.5499\n",
      "Epoch 88: val_accuracy did not improve from 0.97477\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8793 - loss: 0.5499 - val_accuracy: 0.9730 - val_loss: 0.2502 - learning_rate: 2.3438e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8787 - loss: 0.5506\n",
      "Epoch 89: val_accuracy improved from 0.97477 to 0.97552, saving model to asl_checkpoint.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.8787 - loss: 0.5506 - val_accuracy: 0.9755 - val_loss: 0.2463 - learning_rate: 2.3438e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8857 - loss: 0.5334\n",
      "Epoch 90: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8857 - loss: 0.5334 - val_accuracy: 0.9735 - val_loss: 0.2505 - learning_rate: 2.3438e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8856 - loss: 0.5399\n",
      "Epoch 91: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 194ms/step - accuracy: 0.8856 - loss: 0.5399 - val_accuracy: 0.9715 - val_loss: 0.2527 - learning_rate: 2.3438e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8858 - loss: 0.5285\n",
      "Epoch 92: val_accuracy did not improve from 0.97552\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 195ms/step - accuracy: 0.8858 - loss: 0.5285 - val_accuracy: 0.9721 - val_loss: 0.2485 - learning_rate: 2.3438e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8851 - loss: 0.5375\n",
      "Epoch 93: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8851 - loss: 0.5375 - val_accuracy: 0.9754 - val_loss: 0.2421 - learning_rate: 1.1719e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8891 - loss: 0.5222\n",
      "Epoch 94: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.8891 - loss: 0.5222 - val_accuracy: 0.9753 - val_loss: 0.2412 - learning_rate: 1.1719e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8876 - loss: 0.5275\n",
      "Epoch 95: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8876 - loss: 0.5275 - val_accuracy: 0.9752 - val_loss: 0.2412 - learning_rate: 1.1719e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8880 - loss: 0.5255\n",
      "Epoch 96: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8880 - loss: 0.5255 - val_accuracy: 0.9746 - val_loss: 0.2408 - learning_rate: 1.1719e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8874 - loss: 0.5304\n",
      "Epoch 97: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8874 - loss: 0.5304 - val_accuracy: 0.9751 - val_loss: 0.2409 - learning_rate: 1.1719e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8883 - loss: 0.5226\n",
      "Epoch 98: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.8883 - loss: 0.5226 - val_accuracy: 0.9751 - val_loss: 0.2402 - learning_rate: 1.1719e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8848 - loss: 0.5316\n",
      "Epoch 99: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8848 - loss: 0.5316 - val_accuracy: 0.9753 - val_loss: 0.2397 - learning_rate: 1.1719e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8880 - loss: 0.5270\n",
      "Epoch 100: val_accuracy did not improve from 0.97552\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.8880 - loss: 0.5270 - val_accuracy: 0.9744 - val_loss: 0.2390 - learning_rate: 1.1719e-05\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Training Execution\n",
    "# ========================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    initial_epoch=initial_epoch,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm anotha one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52200 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ cast_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ cast_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ spatial_dropout2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,576</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,205</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_2 (\u001b[38;5;33mCast\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ cast_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ cast_3 (\u001b[38;5;33mCast\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │         \u001b[38;5;34m33\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ cast_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m32\u001b[0m)               │            │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │         \u001b[38;5;34m65\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │      \u001b[38;5;34m2,112\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m64\u001b[0m)               │            │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)  │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1\u001b[0m) │        \u001b[38;5;34m129\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ spatial_dropout2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m128\u001b[0m)              │            │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)       │     \u001b[38;5;34m18,576\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)       │        \u001b[38;5;34m576\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        │      \u001b[38;5;34m4,205\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">323,840</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m323,840\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">322,208</span> (1.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m322,208\u001b[0m (1.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> (6.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,632\u001b[0m (6.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# ========================\n",
    "# Dataset Configuration\n",
    "# ========================\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../dataset/asl_split\"))\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "# ========================\n",
    "# Proven Preprocessing (Unchanged)\n",
    "# ========================\n",
    "def enhanced_edge_preprocessing(img):\n",
    "    \"\"\"Edge detection with gradient preservation\"\"\"\n",
    "    img_uint8 = (img * 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Core edge detection\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    \n",
    "    # Preserve gradients for texture\n",
    "    gradient = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    gradient = cv2.normalize(gradient, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    combined = cv2.addWeighted(edges, 0.8, gradient, 0.2, 0)\n",
    "    return np.stack([combined]*3, axis=-1).astype(np.float32) / 255.0\n",
    "\n",
    "# ========================\n",
    "# Data Generators (Unchanged)\n",
    "# ========================\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=enhanced_edge_preprocessing,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    shear_range=0.1,\n",
    "    channel_shift_range=10.0,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=enhanced_edge_preprocessing\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(200, 200),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ========================\n",
    "# Modified Model Architecture (Key Changes)\n",
    "# ========================\n",
    "def residual_block(inputs, filters, strides=1):\n",
    "    x = Conv2D(filters, (3,3), strides=strides, padding='same', \n",
    "               kernel_regularizer=l2(0.001))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, (3,3), padding='same', \n",
    "               kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Simplified attention\n",
    "    attention = Conv2D(1, (1,1), activation='sigmoid')(x)\n",
    "    x = Multiply()([x, attention])\n",
    "    \n",
    "    shortcut = inputs\n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1,1), strides=strides)(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    return Add()([x, shortcut])\n",
    "\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "\n",
    "# Feature extraction\n",
    "x = residual_block(inputs, 32)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.3)(x)\n",
    "\n",
    "x = residual_block(x, 64)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.35)(x)\n",
    "\n",
    "x = residual_block(x, 128)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# === CRUCIAL MODIFICATION ===\n",
    "x = Dense(144, activation='relu', kernel_regularizer=l2(0.0003))(x)  # Increased capacity\n",
    "# ============================\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# ========================\n",
    "# Optimized Training Setup (Key Changes)\n",
    "# ========================\n",
    "model.compile(\n",
    "    optimizer=Adam(\n",
    "        learning_rate=0.0012,  # Increased from 0.001\n",
    "        clipvalue=0.5          # New: Gradient clipping\n",
    "    ),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=3, verbose=1),\n",
    "    ModelCheckpoint(\n",
    "        \"best_train.weights.h5\",\n",
    "        save_weights_only=True,\n",
    "        monitor='accuracy',  # Tracks training accuracy\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        \"best_val.weights.h5\",\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adithya/projects/ASL-CNN-Project/venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746343768.325120  481692 service.cc:152] XLA service 0x7f7d500145a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746343768.325191  481692 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-05-04 11:29:28.454872: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746343769.586056  481692 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-05-04 11:29:41.054715: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.15 = (f16[32,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,200,200,32]{3,2,1,0} %bitcast.23395, f16[32,200,200,32]{3,2,1,0} %bitcast.23397), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/conv2d_4_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/adithya/projects/ASL-CNN-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-04 11:29:42.852127: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.798101788s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.15 = (f16[32,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,200,200,32]{3,2,1,0} %bitcast.23395, f16[32,200,200,32]{3,2,1,0} %bitcast.23397), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/conv2d_4_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/adithya/projects/ASL-CNN-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-04 11:29:45.616542: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.18 = (f16[64,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,100,100,32]{3,2,1,0} %bitcast.23794, f16[32,100,100,64]{3,2,1,0} %bitcast.23629), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/conv2d_7_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/adithya/projects/ASL-CNN-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-04 11:29:45.874108: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.259084555s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.18 = (f16[64,3,3,32]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,100,100,32]{3,2,1,0} %bitcast.23794, f16[32,100,100,64]{3,2,1,0} %bitcast.23629), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/conv2d_7_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/adithya/projects/ASL-CNN-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-04 11:29:48.669818: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.22 = (f16[128,3,3,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,50,50,64]{3,2,1,0} %bitcast.24028, f16[32,50,50,128]{3,2,1,0} %bitcast.23863), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/conv2d_11_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/adithya/projects/ASL-CNN-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-04 11:29:48.849926: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.180600229s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bw-filter.22 = (f16[128,3,3,64]{3,2,1,0}, u8[0]{0}) custom-call(f16[32,50,50,64]{3,2,1,0} %bitcast.24028, f16[32,50,50,128]{3,2,1,0} %bitcast.23863), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/functional_1/conv2d_11_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/adithya/projects/ASL-CNN-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "I0000 00:00:1746343795.867649  481692 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 197/1632\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:27\u001b[0m 187ms/step - accuracy: 0.0470 - loss: 4.4098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 11:30:47.200616: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'input_convert_multiply_reduce_fusion_1', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.1017 - loss: 3.6574\n",
      "Epoch 1: accuracy improved from -inf to 0.15435, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16655, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 221ms/step - accuracy: 0.1017 - loss: 3.6571 - val_accuracy: 0.1666 - val_loss: 3.0564 - learning_rate: 0.0012\n",
      "Epoch 2/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.2911 - loss: 2.5470\n",
      "Epoch 2: accuracy improved from 0.15435 to 0.33866, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.16655 to 0.36103, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 199ms/step - accuracy: 0.2912 - loss: 2.5469 - val_accuracy: 0.3610 - val_loss: 2.5110 - learning_rate: 0.0012\n",
      "Epoch 3/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.4674 - loss: 2.0296\n",
      "Epoch 3: accuracy improved from 0.33866 to 0.50310, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.36103 to 0.42690, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 195ms/step - accuracy: 0.4674 - loss: 2.0296 - val_accuracy: 0.4269 - val_loss: 2.3252 - learning_rate: 0.0012\n",
      "Epoch 4/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5802 - loss: 1.7065\n",
      "Epoch 4: accuracy improved from 0.50310 to 0.59875, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.42690 to 0.64069, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 189ms/step - accuracy: 0.5802 - loss: 1.7064 - val_accuracy: 0.6407 - val_loss: 1.5291 - learning_rate: 0.0012\n",
      "Epoch 5/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6426 - loss: 1.5201\n",
      "Epoch 5: accuracy improved from 0.59875 to 0.65379, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.64069 to 0.70598, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.6426 - loss: 1.5201 - val_accuracy: 0.7060 - val_loss: 1.2835 - learning_rate: 0.0012\n",
      "Epoch 6/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6834 - loss: 1.4042\n",
      "Epoch 6: accuracy improved from 0.65379 to 0.69220, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.70598 to 0.75431, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 191ms/step - accuracy: 0.6834 - loss: 1.4042 - val_accuracy: 0.7543 - val_loss: 1.1354 - learning_rate: 0.0012\n",
      "Epoch 7/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7066 - loss: 1.3148\n",
      "Epoch 7: accuracy improved from 0.69220 to 0.70912, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.75431 to 0.83172, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.7066 - loss: 1.3148 - val_accuracy: 0.8317 - val_loss: 0.9547 - learning_rate: 0.0012\n",
      "Epoch 8/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.7225 - loss: 1.2680\n",
      "Epoch 8: accuracy improved from 0.70912 to 0.72782, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.83172 to 0.83632, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 197ms/step - accuracy: 0.7225 - loss: 1.2680 - val_accuracy: 0.8363 - val_loss: 0.8952 - learning_rate: 0.0012\n",
      "Epoch 9/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7401 - loss: 1.2347\n",
      "Epoch 9: accuracy improved from 0.72782 to 0.74165, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.83632\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 195ms/step - accuracy: 0.7401 - loss: 1.2347 - val_accuracy: 0.7475 - val_loss: 1.2351 - learning_rate: 0.0012\n",
      "Epoch 10/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7531 - loss: 1.1903\n",
      "Epoch 10: accuracy improved from 0.74165 to 0.75534, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.83632\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 195ms/step - accuracy: 0.7531 - loss: 1.1903 - val_accuracy: 0.8174 - val_loss: 0.9552 - learning_rate: 0.0012\n",
      "Epoch 11/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.7597 - loss: 1.1682\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "\n",
      "Epoch 11: accuracy improved from 0.75534 to 0.76370, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.83632\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 197ms/step - accuracy: 0.7597 - loss: 1.1682 - val_accuracy: 0.8139 - val_loss: 0.9810 - learning_rate: 0.0012\n",
      "Epoch 12/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8094 - loss: 0.9741\n",
      "Epoch 12: accuracy improved from 0.76370 to 0.81625, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.83632 to 0.88977, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 199ms/step - accuracy: 0.8094 - loss: 0.9740 - val_accuracy: 0.8898 - val_loss: 0.6514 - learning_rate: 6.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8191 - loss: 0.9028\n",
      "Epoch 13: accuracy improved from 0.81625 to 0.82149, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 13: val_accuracy improved from 0.88977 to 0.90494, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 196ms/step - accuracy: 0.8191 - loss: 0.9027 - val_accuracy: 0.9049 - val_loss: 0.5822 - learning_rate: 6.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8278 - loss: 0.8501\n",
      "Epoch 14: accuracy improved from 0.82149 to 0.82770, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 14: val_accuracy improved from 0.90494 to 0.90701, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 193ms/step - accuracy: 0.8278 - loss: 0.8501 - val_accuracy: 0.9070 - val_loss: 0.5699 - learning_rate: 6.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8312 - loss: 0.8261\n",
      "Epoch 15: accuracy improved from 0.82770 to 0.83077, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 15: val_accuracy improved from 0.90701 to 0.92649, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 192ms/step - accuracy: 0.8312 - loss: 0.8261 - val_accuracy: 0.9265 - val_loss: 0.5042 - learning_rate: 6.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8326 - loss: 0.8068\n",
      "Epoch 16: accuracy improved from 0.83077 to 0.83418, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 16: val_accuracy improved from 0.92649 to 0.94523, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 196ms/step - accuracy: 0.8326 - loss: 0.8068 - val_accuracy: 0.9452 - val_loss: 0.4376 - learning_rate: 6.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8352 - loss: 0.7884\n",
      "Epoch 17: accuracy improved from 0.83418 to 0.83858, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.94523\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 197ms/step - accuracy: 0.8352 - loss: 0.7884 - val_accuracy: 0.9189 - val_loss: 0.5102 - learning_rate: 6.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8403 - loss: 0.7776\n",
      "Epoch 18: accuracy did not improve from 0.83858\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.94523\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 194ms/step - accuracy: 0.8403 - loss: 0.7776 - val_accuracy: 0.9402 - val_loss: 0.4431 - learning_rate: 6.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8419 - loss: 0.7677\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "\n",
      "Epoch 19: accuracy improved from 0.83858 to 0.84102, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.94523\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 196ms/step - accuracy: 0.8419 - loss: 0.7677 - val_accuracy: 0.9339 - val_loss: 0.4629 - learning_rate: 6.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.8655 - loss: 0.6819\n",
      "Epoch 20: accuracy improved from 0.84102 to 0.86931, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 20: val_accuracy improved from 0.94523 to 0.95575, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 206ms/step - accuracy: 0.8655 - loss: 0.6819 - val_accuracy: 0.9557 - val_loss: 0.3724 - learning_rate: 3.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8784 - loss: 0.6193\n",
      "Epoch 21: accuracy improved from 0.86931 to 0.87563, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.95575\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 198ms/step - accuracy: 0.8784 - loss: 0.6193 - val_accuracy: 0.9508 - val_loss: 0.3674 - learning_rate: 3.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8802 - loss: 0.6061\n",
      "Epoch 22: accuracy improved from 0.87563 to 0.87989, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 22: val_accuracy improved from 0.95575 to 0.95684, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 199ms/step - accuracy: 0.8802 - loss: 0.6061 - val_accuracy: 0.9568 - val_loss: 0.3406 - learning_rate: 3.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8801 - loss: 0.5916\n",
      "Epoch 23: accuracy did not improve from 0.87989\n",
      "\n",
      "Epoch 23: val_accuracy improved from 0.95684 to 0.96201, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 197ms/step - accuracy: 0.8801 - loss: 0.5916 - val_accuracy: 0.9620 - val_loss: 0.3210 - learning_rate: 3.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8788 - loss: 0.5901\n",
      "Epoch 24: accuracy improved from 0.87989 to 0.88061, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.96201\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 202ms/step - accuracy: 0.8788 - loss: 0.5901 - val_accuracy: 0.9391 - val_loss: 0.3783 - learning_rate: 3.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8784 - loss: 0.5852\n",
      "Epoch 25: accuracy improved from 0.88061 to 0.88170, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.96201\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 200ms/step - accuracy: 0.8784 - loss: 0.5852 - val_accuracy: 0.9522 - val_loss: 0.3357 - learning_rate: 3.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8859 - loss: 0.5547\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\n",
      "Epoch 26: accuracy improved from 0.88170 to 0.88349, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.96201\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 200ms/step - accuracy: 0.8859 - loss: 0.5547 - val_accuracy: 0.9524 - val_loss: 0.3359 - learning_rate: 3.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.8979 - loss: 0.5182\n",
      "Epoch 27: accuracy improved from 0.88349 to 0.89937, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 27: val_accuracy improved from 0.96201 to 0.97057, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 204ms/step - accuracy: 0.8979 - loss: 0.5182 - val_accuracy: 0.9706 - val_loss: 0.2725 - learning_rate: 1.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9056 - loss: 0.4843\n",
      "Epoch 28: accuracy improved from 0.89937 to 0.90354, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.97057\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 205ms/step - accuracy: 0.9056 - loss: 0.4843 - val_accuracy: 0.9682 - val_loss: 0.2695 - learning_rate: 1.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9029 - loss: 0.4810\n",
      "Epoch 29: accuracy did not improve from 0.90354\n",
      "\n",
      "Epoch 29: val_accuracy improved from 0.97057 to 0.97207, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 203ms/step - accuracy: 0.9029 - loss: 0.4810 - val_accuracy: 0.9721 - val_loss: 0.2545 - learning_rate: 1.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9008 - loss: 0.4852\n",
      "Epoch 30: accuracy did not improve from 0.90354\n",
      "\n",
      "Epoch 30: val_accuracy improved from 0.97207 to 0.97397, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 204ms/step - accuracy: 0.9008 - loss: 0.4852 - val_accuracy: 0.9740 - val_loss: 0.2451 - learning_rate: 1.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9046 - loss: 0.4627\n",
      "Epoch 31: accuracy improved from 0.90354 to 0.90609, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.97397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 199ms/step - accuracy: 0.9046 - loss: 0.4627 - val_accuracy: 0.9739 - val_loss: 0.2400 - learning_rate: 1.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9021 - loss: 0.4726\n",
      "Epoch 32: accuracy did not improve from 0.90609\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.97397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 199ms/step - accuracy: 0.9021 - loss: 0.4726 - val_accuracy: 0.9703 - val_loss: 0.2453 - learning_rate: 1.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9023 - loss: 0.4669\n",
      "Epoch 33: accuracy did not improve from 0.90609\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.97397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 198ms/step - accuracy: 0.9023 - loss: 0.4669 - val_accuracy: 0.9700 - val_loss: 0.2451 - learning_rate: 1.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9087 - loss: 0.4513\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\n",
      "Epoch 34: accuracy improved from 0.90609 to 0.90923, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.97397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 200ms/step - accuracy: 0.9087 - loss: 0.4513 - val_accuracy: 0.9691 - val_loss: 0.2413 - learning_rate: 1.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9120 - loss: 0.4317\n",
      "Epoch 35: accuracy improved from 0.90923 to 0.91508, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 35: val_accuracy improved from 0.97397 to 0.97557, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 199ms/step - accuracy: 0.9120 - loss: 0.4317 - val_accuracy: 0.9756 - val_loss: 0.2256 - learning_rate: 7.5000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9176 - loss: 0.4121\n",
      "Epoch 36: accuracy improved from 0.91508 to 0.91730, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 36: val_accuracy improved from 0.97557 to 0.97730, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 199ms/step - accuracy: 0.9176 - loss: 0.4121 - val_accuracy: 0.9773 - val_loss: 0.2201 - learning_rate: 7.5000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9197 - loss: 0.4023\n",
      "Epoch 37: accuracy improved from 0.91730 to 0.92025, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.97730\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 209ms/step - accuracy: 0.9197 - loss: 0.4023 - val_accuracy: 0.9763 - val_loss: 0.2162 - learning_rate: 7.5000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9186 - loss: 0.4046\n",
      "Epoch 38: accuracy did not improve from 0.92025\n",
      "\n",
      "Epoch 38: val_accuracy improved from 0.97730 to 0.97776, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 207ms/step - accuracy: 0.9186 - loss: 0.4046 - val_accuracy: 0.9778 - val_loss: 0.2078 - learning_rate: 7.5000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9202 - loss: 0.3981\n",
      "Epoch 39: accuracy did not improve from 0.92025\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.97776\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 209ms/step - accuracy: 0.9202 - loss: 0.3981 - val_accuracy: 0.9778 - val_loss: 0.2049 - learning_rate: 7.5000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9239 - loss: 0.3788\n",
      "Epoch 40: accuracy improved from 0.92025 to 0.92257, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.97776\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 205ms/step - accuracy: 0.9239 - loss: 0.3788 - val_accuracy: 0.9774 - val_loss: 0.2051 - learning_rate: 7.5000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9238 - loss: 0.3838\n",
      "Epoch 41: accuracy did not improve from 0.92257\n",
      "\n",
      "Epoch 41: val_accuracy improved from 0.97776 to 0.98138, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 206ms/step - accuracy: 0.9238 - loss: 0.3838 - val_accuracy: 0.9814 - val_loss: 0.1923 - learning_rate: 7.5000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9212 - loss: 0.3870\n",
      "Epoch 42: accuracy did not improve from 0.92257\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 207ms/step - accuracy: 0.9212 - loss: 0.3870 - val_accuracy: 0.9788 - val_loss: 0.1963 - learning_rate: 7.5000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9189 - loss: 0.3886\n",
      "Epoch 43: accuracy did not improve from 0.92257\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 203ms/step - accuracy: 0.9189 - loss: 0.3886 - val_accuracy: 0.9802 - val_loss: 0.1930 - learning_rate: 7.5000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9240 - loss: 0.3800\n",
      "Epoch 44: accuracy improved from 0.92257 to 0.92337, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 201ms/step - accuracy: 0.9240 - loss: 0.3800 - val_accuracy: 0.9805 - val_loss: 0.1908 - learning_rate: 7.5000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9240 - loss: 0.3730\n",
      "Epoch 45: accuracy did not improve from 0.92337\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 201ms/step - accuracy: 0.9240 - loss: 0.3730 - val_accuracy: 0.9773 - val_loss: 0.1974 - learning_rate: 7.5000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9242 - loss: 0.3722\n",
      "Epoch 46: accuracy did not improve from 0.92337\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 208ms/step - accuracy: 0.9242 - loss: 0.3722 - val_accuracy: 0.9775 - val_loss: 0.1942 - learning_rate: 7.5000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9219 - loss: 0.3741\n",
      "Epoch 47: accuracy did not improve from 0.92337\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 213ms/step - accuracy: 0.9219 - loss: 0.3741 - val_accuracy: 0.9795 - val_loss: 0.1862 - learning_rate: 7.5000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9242 - loss: 0.3671\n",
      "Epoch 48: accuracy improved from 0.92337 to 0.92400, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 208ms/step - accuracy: 0.9242 - loss: 0.3671 - val_accuracy: 0.9803 - val_loss: 0.1853 - learning_rate: 7.5000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9246 - loss: 0.3623\n",
      "Epoch 49: accuracy improved from 0.92400 to 0.92523, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 207ms/step - accuracy: 0.9246 - loss: 0.3623 - val_accuracy: 0.9795 - val_loss: 0.1864 - learning_rate: 7.5000e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9224 - loss: 0.3670\n",
      "Epoch 50: accuracy did not improve from 0.92523\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 200ms/step - accuracy: 0.9224 - loss: 0.3670 - val_accuracy: 0.9802 - val_loss: 0.1812 - learning_rate: 7.5000e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.9239 - loss: 0.3632\n",
      "Epoch 51: accuracy did not improve from 0.92523\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 199ms/step - accuracy: 0.9239 - loss: 0.3632 - val_accuracy: 0.9772 - val_loss: 0.1883 - learning_rate: 7.5000e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m1628/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9238 - loss: 0.3658\n",
      "Epoch 52: accuracy did not improve from 0.92523\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 203ms/step - accuracy: 0.9238 - loss: 0.3658 - val_accuracy: 0.9811 - val_loss: 0.1759 - learning_rate: 7.5000e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9253 - loss: 0.3554\n",
      "Epoch 53: accuracy did not improve from 0.92523\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 346ms/step - accuracy: 0.9253 - loss: 0.3554 - val_accuracy: 0.9810 - val_loss: 0.1766 - learning_rate: 7.5000e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9278 - loss: 0.3471\n",
      "Epoch 54: accuracy improved from 0.92523 to 0.92605, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 54: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 193ms/step - accuracy: 0.9278 - loss: 0.3471 - val_accuracy: 0.9762 - val_loss: 0.1894 - learning_rate: 7.5000e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9263 - loss: 0.3512\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "\n",
      "Epoch 55: accuracy did not improve from 0.92605\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.98138\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.9263 - loss: 0.3512 - val_accuracy: 0.9797 - val_loss: 0.1788 - learning_rate: 7.5000e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9275 - loss: 0.3457\n",
      "Epoch 56: accuracy improved from 0.92605 to 0.92985, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 56: val_accuracy improved from 0.98138 to 0.98172, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.9275 - loss: 0.3457 - val_accuracy: 0.9817 - val_loss: 0.1710 - learning_rate: 3.7500e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9331 - loss: 0.3322\n",
      "Epoch 57: accuracy improved from 0.92985 to 0.93178, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 57: val_accuracy improved from 0.98172 to 0.98397, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 197ms/step - accuracy: 0.9331 - loss: 0.3322 - val_accuracy: 0.9840 - val_loss: 0.1643 - learning_rate: 3.7500e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9317 - loss: 0.3306\n",
      "Epoch 58: accuracy improved from 0.93178 to 0.93226, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.98397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 188ms/step - accuracy: 0.9317 - loss: 0.3306 - val_accuracy: 0.9833 - val_loss: 0.1656 - learning_rate: 3.7500e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9334 - loss: 0.3278\n",
      "Epoch 59: accuracy improved from 0.93226 to 0.93261, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.98397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 188ms/step - accuracy: 0.9334 - loss: 0.3278 - val_accuracy: 0.9833 - val_loss: 0.1634 - learning_rate: 3.7500e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9313 - loss: 0.3357\n",
      "Epoch 60: accuracy did not improve from 0.93261\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.98397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 187ms/step - accuracy: 0.9313 - loss: 0.3357 - val_accuracy: 0.9828 - val_loss: 0.1645 - learning_rate: 3.7500e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9321 - loss: 0.3301\n",
      "Epoch 61: accuracy improved from 0.93261 to 0.93285, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.98397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 196ms/step - accuracy: 0.9321 - loss: 0.3301 - val_accuracy: 0.9826 - val_loss: 0.1629 - learning_rate: 3.7500e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9332 - loss: 0.3244\n",
      "Epoch 62: accuracy improved from 0.93285 to 0.93316, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.98397\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 194ms/step - accuracy: 0.9332 - loss: 0.3244 - val_accuracy: 0.9822 - val_loss: 0.1619 - learning_rate: 3.7500e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9345 - loss: 0.3159\n",
      "Epoch 63: accuracy improved from 0.93316 to 0.93400, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 63: val_accuracy improved from 0.98397 to 0.98511, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.9345 - loss: 0.3159 - val_accuracy: 0.9851 - val_loss: 0.1535 - learning_rate: 3.7500e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9352 - loss: 0.3206\n",
      "Epoch 64: accuracy improved from 0.93400 to 0.93546, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.98511\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 193ms/step - accuracy: 0.9352 - loss: 0.3206 - val_accuracy: 0.9839 - val_loss: 0.1595 - learning_rate: 3.7500e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9316 - loss: 0.3286\n",
      "Epoch 65: accuracy did not improve from 0.93546\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.98511\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 196ms/step - accuracy: 0.9316 - loss: 0.3286 - val_accuracy: 0.9847 - val_loss: 0.1555 - learning_rate: 3.7500e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9365 - loss: 0.3121\n",
      "Epoch 66: accuracy did not improve from 0.93546\n",
      "\n",
      "Epoch 66: val_accuracy improved from 0.98511 to 0.98534, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.9365 - loss: 0.3121 - val_accuracy: 0.9853 - val_loss: 0.1526 - learning_rate: 3.7500e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9345 - loss: 0.3141\n",
      "Epoch 67: accuracy did not improve from 0.93546\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.98534\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 187ms/step - accuracy: 0.9345 - loss: 0.3141 - val_accuracy: 0.9841 - val_loss: 0.1545 - learning_rate: 3.7500e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9354 - loss: 0.3147\n",
      "Epoch 68: accuracy improved from 0.93546 to 0.93567, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.98534\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 188ms/step - accuracy: 0.9354 - loss: 0.3147 - val_accuracy: 0.9836 - val_loss: 0.1528 - learning_rate: 3.7500e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9363 - loss: 0.3149\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
      "\n",
      "Epoch 69: accuracy did not improve from 0.93567\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 0.98534\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 187ms/step - accuracy: 0.9363 - loss: 0.3149 - val_accuracy: 0.9850 - val_loss: 0.1535 - learning_rate: 3.7500e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9367 - loss: 0.3070\n",
      "Epoch 70: accuracy improved from 0.93567 to 0.93814, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 70: val_accuracy improved from 0.98534 to 0.98632, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.9367 - loss: 0.3070 - val_accuracy: 0.9863 - val_loss: 0.1494 - learning_rate: 1.8750e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9394 - loss: 0.3014\n",
      "Epoch 71: accuracy improved from 0.93814 to 0.93916, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 0.98632\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 193ms/step - accuracy: 0.9394 - loss: 0.3014 - val_accuracy: 0.9863 - val_loss: 0.1488 - learning_rate: 1.8750e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9389 - loss: 0.2965\n",
      "Epoch 72: accuracy did not improve from 0.93916\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.98632\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 195ms/step - accuracy: 0.9389 - loss: 0.2965 - val_accuracy: 0.9862 - val_loss: 0.1475 - learning_rate: 1.8750e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9386 - loss: 0.3009\n",
      "Epoch 73: accuracy did not improve from 0.93916\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 0.98632\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 193ms/step - accuracy: 0.9386 - loss: 0.3009 - val_accuracy: 0.9858 - val_loss: 0.1477 - learning_rate: 1.8750e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9395 - loss: 0.2956\n",
      "Epoch 74: accuracy improved from 0.93916 to 0.93933, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 0.98632\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 205ms/step - accuracy: 0.9395 - loss: 0.2956 - val_accuracy: 0.9860 - val_loss: 0.1489 - learning_rate: 1.8750e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9390 - loss: 0.3018\n",
      "Epoch 75: accuracy did not improve from 0.93933\n",
      "\n",
      "Epoch 75: val_accuracy improved from 0.98632 to 0.98684, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 201ms/step - accuracy: 0.9390 - loss: 0.3018 - val_accuracy: 0.9868 - val_loss: 0.1453 - learning_rate: 1.8750e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9394 - loss: 0.3015\n",
      "Epoch 76: accuracy improved from 0.93933 to 0.93971, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 76: val_accuracy improved from 0.98684 to 0.98713, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 202ms/step - accuracy: 0.9394 - loss: 0.3015 - val_accuracy: 0.9871 - val_loss: 0.1440 - learning_rate: 1.8750e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9414 - loss: 0.2916\n",
      "Epoch 77: accuracy did not improve from 0.93971\n",
      "\n",
      "Epoch 77: val_accuracy improved from 0.98713 to 0.98736, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 192ms/step - accuracy: 0.9414 - loss: 0.2916 - val_accuracy: 0.9874 - val_loss: 0.1444 - learning_rate: 1.8750e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9390 - loss: 0.2962\n",
      "Epoch 78: accuracy did not improve from 0.93971\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 186ms/step - accuracy: 0.9390 - loss: 0.2962 - val_accuracy: 0.9856 - val_loss: 0.1456 - learning_rate: 1.8750e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9420 - loss: 0.2907\n",
      "Epoch 79: accuracy improved from 0.93971 to 0.93973, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 186ms/step - accuracy: 0.9420 - loss: 0.2907 - val_accuracy: 0.9867 - val_loss: 0.1434 - learning_rate: 1.8750e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9412 - loss: 0.2905\n",
      "Epoch 80: accuracy improved from 0.93973 to 0.94134, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 190ms/step - accuracy: 0.9412 - loss: 0.2905 - val_accuracy: 0.9860 - val_loss: 0.1445 - learning_rate: 1.8750e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9389 - loss: 0.2971\n",
      "Epoch 81: accuracy did not improve from 0.94134\n",
      "\n",
      "Epoch 81: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 186ms/step - accuracy: 0.9389 - loss: 0.2971 - val_accuracy: 0.9871 - val_loss: 0.1412 - learning_rate: 1.8750e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9399 - loss: 0.2931\n",
      "Epoch 82: accuracy did not improve from 0.94134\n",
      "\n",
      "Epoch 82: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 187ms/step - accuracy: 0.9399 - loss: 0.2931 - val_accuracy: 0.9857 - val_loss: 0.1464 - learning_rate: 1.8750e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9417 - loss: 0.2892\n",
      "Epoch 83: accuracy improved from 0.94134 to 0.94205, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 83: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 186ms/step - accuracy: 0.9417 - loss: 0.2892 - val_accuracy: 0.9864 - val_loss: 0.1424 - learning_rate: 1.8750e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9421 - loss: 0.2871\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 9.375000445288606e-06.\n",
      "\n",
      "Epoch 84: accuracy did not improve from 0.94205\n",
      "\n",
      "Epoch 84: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 186ms/step - accuracy: 0.9421 - loss: 0.2871 - val_accuracy: 0.9863 - val_loss: 0.1416 - learning_rate: 1.8750e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9413 - loss: 0.2878\n",
      "Epoch 85: accuracy did not improve from 0.94205\n",
      "\n",
      "Epoch 85: val_accuracy did not improve from 0.98736\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 188ms/step - accuracy: 0.9413 - loss: 0.2878 - val_accuracy: 0.9871 - val_loss: 0.1398 - learning_rate: 9.3750e-06\n",
      "Epoch 86/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9419 - loss: 0.2871\n",
      "Epoch 86: accuracy improved from 0.94205 to 0.94215, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 86: val_accuracy improved from 0.98736 to 0.98782, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 186ms/step - accuracy: 0.9419 - loss: 0.2871 - val_accuracy: 0.9878 - val_loss: 0.1384 - learning_rate: 9.3750e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9426 - loss: 0.2853\n",
      "Epoch 87: accuracy did not improve from 0.94215\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.98782\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 185ms/step - accuracy: 0.9426 - loss: 0.2853 - val_accuracy: 0.9873 - val_loss: 0.1399 - learning_rate: 9.3750e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9400 - loss: 0.2945\n",
      "Epoch 88: accuracy did not improve from 0.94215\n",
      "\n",
      "Epoch 88: val_accuracy improved from 0.98782 to 0.98805, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 188ms/step - accuracy: 0.9400 - loss: 0.2945 - val_accuracy: 0.9880 - val_loss: 0.1373 - learning_rate: 9.3750e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9429 - loss: 0.2870\n",
      "Epoch 89: accuracy did not improve from 0.94215\n",
      "\n",
      "Epoch 89: val_accuracy did not improve from 0.98805\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 188ms/step - accuracy: 0.9429 - loss: 0.2870 - val_accuracy: 0.9875 - val_loss: 0.1381 - learning_rate: 9.3750e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9400 - loss: 0.2864\n",
      "Epoch 90: accuracy did not improve from 0.94215\n",
      "\n",
      "Epoch 90: val_accuracy improved from 0.98805 to 0.98810, saving model to best_val.weights.h5\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 193ms/step - accuracy: 0.9400 - loss: 0.2864 - val_accuracy: 0.9881 - val_loss: 0.1369 - learning_rate: 9.3750e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9451 - loss: 0.2810\n",
      "Epoch 91: accuracy improved from 0.94215 to 0.94351, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 91: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 186ms/step - accuracy: 0.9451 - loss: 0.2810 - val_accuracy: 0.9871 - val_loss: 0.1367 - learning_rate: 9.3750e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9433 - loss: 0.2786\n",
      "Epoch 92: accuracy did not improve from 0.94351\n",
      "\n",
      "Epoch 92: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 188ms/step - accuracy: 0.9433 - loss: 0.2786 - val_accuracy: 0.9880 - val_loss: 0.1373 - learning_rate: 9.3750e-06\n",
      "Epoch 93/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9395 - loss: 0.2896\n",
      "Epoch 93: accuracy did not improve from 0.94351\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 187ms/step - accuracy: 0.9395 - loss: 0.2896 - val_accuracy: 0.9875 - val_loss: 0.1372 - learning_rate: 9.3750e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9449 - loss: 0.2778\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 4.687500222644303e-06.\n",
      "\n",
      "Epoch 94: accuracy did not improve from 0.94351\n",
      "\n",
      "Epoch 94: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 187ms/step - accuracy: 0.9449 - loss: 0.2778 - val_accuracy: 0.9872 - val_loss: 0.1374 - learning_rate: 9.3750e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9430 - loss: 0.2811\n",
      "Epoch 95: accuracy did not improve from 0.94351\n",
      "\n",
      "Epoch 95: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 189ms/step - accuracy: 0.9430 - loss: 0.2811 - val_accuracy: 0.9879 - val_loss: 0.1354 - learning_rate: 4.6875e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9445 - loss: 0.2786\n",
      "Epoch 96: accuracy did not improve from 0.94351\n",
      "\n",
      "Epoch 96: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 187ms/step - accuracy: 0.9445 - loss: 0.2786 - val_accuracy: 0.9880 - val_loss: 0.1356 - learning_rate: 4.6875e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9431 - loss: 0.2842\n",
      "Epoch 97: accuracy improved from 0.94351 to 0.94402, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 188ms/step - accuracy: 0.9431 - loss: 0.2842 - val_accuracy: 0.9880 - val_loss: 0.1359 - learning_rate: 4.6875e-06\n",
      "Epoch 98/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9462 - loss: 0.2751\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 2.3437501113221515e-06.\n",
      "\n",
      "Epoch 98: accuracy improved from 0.94402 to 0.94515, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 98: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 187ms/step - accuracy: 0.9462 - loss: 0.2751 - val_accuracy: 0.9876 - val_loss: 0.1359 - learning_rate: 4.6875e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9465 - loss: 0.2732\n",
      "Epoch 99: accuracy improved from 0.94515 to 0.94600, saving model to best_train.weights.h5\n",
      "\n",
      "Epoch 99: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 187ms/step - accuracy: 0.9465 - loss: 0.2732 - val_accuracy: 0.9880 - val_loss: 0.1350 - learning_rate: 2.3438e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9443 - loss: 0.2755\n",
      "Epoch 100: accuracy did not improve from 0.94600\n",
      "\n",
      "Epoch 100: val_accuracy did not improve from 0.98810\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 187ms/step - accuracy: 0.9443 - loss: 0.2755 - val_accuracy: 0.9881 - val_loss: 0.1348 - learning_rate: 2.3438e-06\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Training Execution\n",
    "# ========================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('/home/adithya/projects/ASL-CNN-Project/models/asl_cnn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rebuilt and resaved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Add, Multiply, Activation\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 1. Define your model architecture (must match the original exactly)\n",
    "def residual_block(inputs, filters, strides=1):\n",
    "    x = Conv2D(filters, (3,3), strides=strides, padding='same', kernel_regularizer=l2(0.001))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (3,3), padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    attention = Conv2D(1, (1,1), activation='sigmoid')(x)\n",
    "    x = Multiply()([x, attention])\n",
    "    shortcut = inputs\n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1,1), strides=strides)(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    return Add()([x, shortcut])\n",
    "\n",
    "inputs = Input(shape=(200, 200, 3))\n",
    "x = residual_block(inputs, 32)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.3)(x)\n",
    "x = residual_block(x, 64)\n",
    "x = MaxPooling2D(2)(x)\n",
    "x = SpatialDropout2D(0.35)(x)\n",
    "x = residual_block(x, 128)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(144, activation='relu', kernel_regularizer=l2(0.0003))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(29, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# 2. Load weights\n",
    "weights_path = os.path.abspath(os.path.join(os.getcwd(), 'best_train.weights.h5'))\n",
    "if not os.path.exists(weights_path):\n",
    "    raise FileNotFoundError(f'Weights file not found at {weights_path}')\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "# 3. Compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0012, clipvalue=0.5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 4. Save as a new Keras model for easy loading later\n",
    "model.save(\"../models/asl_cnn_resaved.keras\")\n",
    "print(\"Model rebuilt and resaved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something else entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: DRI3: Screen seems not DRI3 capable\n",
      "libEGL warning: DRI3: Screen seems not DRI3 capable\n",
      "MESA: error: ZINK: failed to choose pdev\n",
      "libEGL warning: egl: failed to create dri2 screen\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746383250.048693  480652 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1746383250.219288  622065 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: D3D12 (NVIDIA GeForce RTX 4050 Laptop GPU)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1746383250.306956  622039 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746383250.358056  622037 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746383250.366988  622041 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loaded 38254 training examples\n",
      "Loading validation data...\n",
      "Loaded 12636 validation examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">123,008</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast_6 (\u001b[38;5;33mCast\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m960\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m123,008\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │         \u001b[38;5;34m3,741\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">146,461</span> (572.11 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m146,461\u001b[0m (572.11 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">146,013</span> (570.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m146,013\u001b[0m (570.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Augmenting training data...\n",
      "Training with 153016 examples after augmentation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set up paths to your dataset\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../dataset/asl_split\"))\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"validation\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, \n",
    "                      min_detection_confidence=0.5)\n",
    "\n",
    "def extract_landmarks(image):\n",
    "    \"\"\"Extract hand landmarks using MediaPipe\"\"\"\n",
    "    # Convert to RGB (MediaPipe requirement)\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif image.shape[2] == 4:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    elif image.shape[2] == 3 and image.dtype == np.uint8:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get hand landmarks\n",
    "    results = hands.process(image)\n",
    "    \n",
    "    # Create feature vector from landmarks\n",
    "    if results.multi_hand_landmarks:\n",
    "        landmarks = results.multi_hand_landmarks[0].landmark\n",
    "        # Extract coordinates and flatten to 63 values (21 landmarks × 3 coordinates)\n",
    "        coords = np.array([[lm.x, lm.y, lm.z] for lm in landmarks]).flatten()\n",
    "        \n",
    "        # Min-max normalization\n",
    "        coords = (coords - np.min(coords)) / (np.max(coords) - np.min(coords) + 1e-8)\n",
    "        \n",
    "        # Reshape for CNN input (21 landmarks, 3 coordinates, 1 channel)\n",
    "        return coords.reshape(21, 3, 1)\n",
    "    else:\n",
    "        # Return zeros if no hand detected\n",
    "        return np.zeros((21, 3, 1))\n",
    "\n",
    "def augment_landmarks(landmarks, augmentation_factor=5):\n",
    "    \"\"\"Apply augmentations to landmark coordinates\"\"\"\n",
    "    augmented_data = []\n",
    "    \n",
    "    for _ in range(augmentation_factor):\n",
    "        aug_landmarks = landmarks.copy()\n",
    "        \n",
    "        # Random rotation (simulate different hand orientations)\n",
    "        angle = np.random.uniform(-15, 15)\n",
    "        theta = np.radians(angle)\n",
    "        rotation_matrix = np.array([\n",
    "            [np.cos(theta), -np.sin(theta)],\n",
    "            [np.sin(theta), np.cos(theta)]\n",
    "        ])\n",
    "        \n",
    "        # Apply rotation to x,y coordinates\n",
    "        for i in range(21):\n",
    "            xy = aug_landmarks[i, :2, 0]\n",
    "            aug_landmarks[i, :2, 0] = np.dot(rotation_matrix, xy)\n",
    "        \n",
    "        # Random scaling (simulate different distances)\n",
    "        scale = np.random.uniform(0.8, 1.2)\n",
    "        aug_landmarks *= scale\n",
    "        \n",
    "        # Random shift (simulate different hand positions)\n",
    "        shift_x = np.random.uniform(-0.1, 0.1)\n",
    "        shift_y = np.random.uniform(-0.1, 0.1)\n",
    "        aug_landmarks[:, 0, 0] += shift_x\n",
    "        aug_landmarks[:, 1, 0] += shift_y\n",
    "        \n",
    "        augmented_data.append(aug_landmarks)\n",
    "    \n",
    "    return augmented_data\n",
    "\n",
    "def load_and_preprocess_dataset(directory):\n",
    "    \"\"\"Load images and preprocess them to landmark features\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    class_dirs = sorted(os.listdir(directory))\n",
    "    label_map = {class_name: i for i, class_name in enumerate(class_dirs)}\n",
    "    \n",
    "    for class_name in class_dirs:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            try:\n",
    "                # Load and resize image\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (200, 200))\n",
    "                \n",
    "                # Extract landmarks\n",
    "                landmarks = extract_landmarks(img)\n",
    "                \n",
    "                # Skip images where no hand is detected\n",
    "                if np.sum(landmarks) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                X.append(landmarks)\n",
    "                y.append(label_map[class_name])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(X), to_categorical(np.array(y), num_classes=len(class_dirs))\n",
    "\n",
    "def create_model(num_classes):\n",
    "    \"\"\"Create a lightweight CNN model for landmark classification\"\"\"\n",
    "    # Input shape: 21 landmarks × 3 coordinates × 1 channel\n",
    "    inputs = Input(shape=(21, 3, 1))\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict_with_tta(model, image, num_augments=5):\n",
    "    \"\"\"Test-time augmentation for more robust prediction\"\"\"\n",
    "    # Resize image if needed\n",
    "    if image.shape[:2] != (200, 200):\n",
    "        image = cv2.resize(image, (200, 200))\n",
    "        \n",
    "    # Extract landmarks\n",
    "    landmarks = extract_landmarks(image)\n",
    "    \n",
    "    # If no hand detected, return prediction based on original image\n",
    "    if np.sum(landmarks) == 0:\n",
    "        return model.predict(np.expand_dims(landmarks, axis=0))[0]\n",
    "    \n",
    "    # Create augmented versions for TTA\n",
    "    augmented = augment_landmarks(landmarks, augmentation_factor=num_augments)\n",
    "    \n",
    "    # Add original landmarks\n",
    "    all_landmarks = [landmarks] + augmented\n",
    "    \n",
    "    # Make predictions on all versions\n",
    "    predictions = model.predict(np.array(all_landmarks))\n",
    "    \n",
    "    # Average the predictions\n",
    "    final_prediction = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess training data\n",
    "    print(\"Loading training data...\")\n",
    "    X_train, y_train = load_and_preprocess_dataset(train_dir)\n",
    "    print(f\"Loaded {len(X_train)} training examples\")\n",
    "    \n",
    "    # Load and preprocess validation data\n",
    "    print(\"Loading validation data...\")\n",
    "    X_val, y_val = load_and_preprocess_dataset(val_dir)\n",
    "    print(f\"Loaded {len(X_val)} validation examples\")\n",
    "    \n",
    "    # Create the model\n",
    "    num_classes = y_train.shape[1]\n",
    "    model = create_model(num_classes)\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Apply data augmentation\n",
    "    print(\"Augmenting training data...\")\n",
    "    augmented_data = []\n",
    "    augmented_labels = []\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        # Add original sample\n",
    "        augmented_data.append(X_train[i])\n",
    "        augmented_labels.append(y_train[i])\n",
    "        \n",
    "        # Add augmented versions (reduce factor if memory is an issue)\n",
    "        aug_samples = augment_landmarks(X_train[i], augmentation_factor=3)\n",
    "        for aug in aug_samples:\n",
    "            augmented_data.append(aug)\n",
    "            augmented_labels.append(y_train[i])\n",
    "    \n",
    "    X_train_aug = np.array(augmented_data)\n",
    "    y_train_aug = np.array(augmented_labels)\n",
    "    print(f\"Training with {len(X_train_aug)} examples after augmentation\")\n",
    "    \n",
    "    # Training callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7867 - loss: 0.7913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 22:53:22.094888: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 256 bytes spill stores, 256 bytes spill loads\n",
      "\n",
      "2025-05-04 22:53:22.127055: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 224 bytes spill stores, 224 bytes spill loads\n",
      "\n",
      "2025-05-04 22:53:24.791640: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "2025-05-04 22:53:25.138645: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.7912 - val_accuracy: 0.9808 - val_loss: 0.0750 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.1095 - val_accuracy: 0.9820 - val_loss: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.0879 - val_accuracy: 0.9876 - val_loss: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0727 - val_accuracy: 0.9897 - val_loss: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0685 - val_accuracy: 0.9903 - val_loss: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0620 - val_accuracy: 0.9890 - val_loss: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0587 - val_accuracy: 0.9910 - val_loss: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.0548 - val_accuracy: 0.9870 - val_loss: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0543 - val_accuracy: 0.9908 - val_loss: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0476 - val_accuracy: 0.9899 - val_loss: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0500 - val_accuracy: 0.9885 - val_loss: 0.0480 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0479 - val_accuracy: 0.9915 - val_loss: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0379 - val_accuracy: 0.9924 - val_loss: 0.0332 - learning_rate: 2.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0324 - val_accuracy: 0.9929 - val_loss: 0.0317 - learning_rate: 2.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0305 - val_accuracy: 0.9921 - val_loss: 0.0339 - learning_rate: 2.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0289 - val_accuracy: 0.9930 - val_loss: 0.0320 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0286 - val_accuracy: 0.9926 - val_loss: 0.0318 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0282 - val_accuracy: 0.9925 - val_loss: 0.0313 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0285 - val_accuracy: 0.9928 - val_loss: 0.0319 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0273 - val_accuracy: 0.9930 - val_loss: 0.0317 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0280 - val_accuracy: 0.9932 - val_loss: 0.0318 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0286 - val_accuracy: 0.9931 - val_loss: 0.0318 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0259 - val_accuracy: 0.9930 - val_loss: 0.0318 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0246 - val_accuracy: 0.9929 - val_loss: 0.0320 - learning_rate: 4.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0247 - val_accuracy: 0.9931 - val_loss: 0.0322 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0245 - val_accuracy: 0.9930 - val_loss: 0.0319 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0244 - val_accuracy: 0.9933 - val_loss: 0.0317 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m4782/4782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0232 - val_accuracy: 0.9930 - val_loss: 0.0318 - learning_rate: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "        X_train_aug, y_train_aug,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as asl_landmark_model.keras\n"
     ]
    }
   ],
   "source": [
    "model.save(\"asl_landmark_model.keras\")\n",
    "print(\"Model saved as asl_landmark_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746387629.075799  480652 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1746387629.195731  646211 gl_context.cc:369] GL version: 3.1 (OpenGL ES 3.1 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: D3D12 (NVIDIA GeForce RTX 4050 Laptop GPU)\n",
      "W0000 00:00:1746387629.235705  646206 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1746387629.301210  646207 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12786 test samples.\n",
      "\u001b[1m390/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 23:46:41.217325: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n",
      "2025-05-04 23:46:41.239829: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 272 bytes spill stores, 272 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0226\n",
      "Test accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Paths\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../dataset/asl_split\"))\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "def extract_landmarks(image):\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    elif image.shape[2] == 4:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)\n",
    "    elif image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "    if results.multi_hand_landmarks:\n",
    "        landmarks = results.multi_hand_landmarks[0].landmark\n",
    "        coords = np.array([[lm.x, lm.y, lm.z] for lm in landmarks]).flatten()\n",
    "        coords = (coords - np.min(coords)) / (np.max(coords) - np.min(coords) + 1e-8)\n",
    "        return coords.reshape(21, 3, 1)\n",
    "    else:\n",
    "        return np.zeros((21, 3, 1))\n",
    "\n",
    "def load_and_preprocess_dataset(directory):\n",
    "    X, y = [], []\n",
    "    class_dirs = sorted(os.listdir(directory))\n",
    "    label_map = {class_name: i for i, class_name in enumerate(class_dirs)}\n",
    "    for class_name in class_dirs:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (200, 200))\n",
    "                landmarks = extract_landmarks(img)\n",
    "                if np.sum(landmarks) == 0:\n",
    "                    continue\n",
    "                X.append(landmarks)\n",
    "                y.append(label_map[class_name])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    return np.array(X), to_categorical(np.array(y), num_classes=len(class_dirs))\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"asl_landmark_model.keras\")\n",
    "\n",
    "# Load and preprocess test data\n",
    "X_test, y_test = load_and_preprocess_dataset(test_dir)\n",
    "print(f\"Loaded {len(X_test)} test samples.\")\n",
    "\n",
    "# Evaluate test accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all training data...\n",
      "Combined dataset size: 50890 examples\n",
      "\n",
      "------------- Fold 1 -------------\n",
      "Training size: 40712, Validation size: 10178\n",
      "Augmenting training data...\n",
      "Training with 162848 examples after augmentation\n",
      "Epoch 1/100\n",
      "\u001b[1m4555/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.7130"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 00:54:00.853872: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "2025-05-05 00:54:01.062608: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136', 168 bytes spill stores, 168 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.8199 - loss: 0.6678 - val_accuracy: 0.9859 - val_loss: 0.0556 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1087 - val_accuracy: 0.9900 - val_loss: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0837 - val_accuracy: 0.9898 - val_loss: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0763 - val_accuracy: 0.9843 - val_loss: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0652 - val_accuracy: 0.9911 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0649 - val_accuracy: 0.9903 - val_loss: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0605 - val_accuracy: 0.9908 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0575 - val_accuracy: 0.9921 - val_loss: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0540 - val_accuracy: 0.9915 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0511 - val_accuracy: 0.9803 - val_loss: 0.0628 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0491 - val_accuracy: 0.9903 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0478 - val_accuracy: 0.9919 - val_loss: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0447 - val_accuracy: 0.9912 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0440 - val_accuracy: 0.9917 - val_loss: 0.0335 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0422 - val_accuracy: 0.9924 - val_loss: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0413 - val_accuracy: 0.9925 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0421 - val_accuracy: 0.9933 - val_loss: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0393 - val_accuracy: 0.9900 - val_loss: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0416 - val_accuracy: 0.9932 - val_loss: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0396 - val_accuracy: 0.9918 - val_loss: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0371 - val_accuracy: 0.9929 - val_loss: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0373 - val_accuracy: 0.9932 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0299 - val_accuracy: 0.9935 - val_loss: 0.0260 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0277 - val_accuracy: 0.9935 - val_loss: 0.0257 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0259 - val_accuracy: 0.9940 - val_loss: 0.0255 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0257 - val_accuracy: 0.9943 - val_loss: 0.0257 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0257 - val_accuracy: 0.9940 - val_loss: 0.0249 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0232 - val_accuracy: 0.9943 - val_loss: 0.0261 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0229 - val_accuracy: 0.9942 - val_loss: 0.0260 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0247 - val_accuracy: 0.9940 - val_loss: 0.0258 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0223 - val_accuracy: 0.9941 - val_loss: 0.0254 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0235 - val_accuracy: 0.9943 - val_loss: 0.0253 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0235 - val_accuracy: 0.9941 - val_loss: 0.0256 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0215 - val_accuracy: 0.9942 - val_loss: 0.0247 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0215 - val_accuracy: 0.9943 - val_loss: 0.0251 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0222 - val_accuracy: 0.9943 - val_loss: 0.0252 - learning_rate: 4.0000e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0207 - val_accuracy: 0.9943 - val_loss: 0.0253 - learning_rate: 4.0000e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0216 - val_accuracy: 0.9941 - val_loss: 0.0249 - learning_rate: 4.0000e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0209 - val_accuracy: 0.9943 - val_loss: 0.0247 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0211 - val_accuracy: 0.9943 - val_loss: 0.0252 - learning_rate: 8.0000e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0202 - val_accuracy: 0.9943 - val_loss: 0.0251 - learning_rate: 8.0000e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0205 - val_accuracy: 0.9944 - val_loss: 0.0251 - learning_rate: 8.0000e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0211 - val_accuracy: 0.9943 - val_loss: 0.0250 - learning_rate: 8.0000e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0211 - val_accuracy: 0.9944 - val_loss: 0.0249 - learning_rate: 8.0000e-06\n",
      "Score for fold 1: loss of 0.024688290432095528; compile_metrics of 99.42032098770142%\n",
      "\n",
      "------------- Fold 2 -------------\n",
      "Training size: 40712, Validation size: 10178\n",
      "Augmenting training data...\n",
      "Training with 162848 examples after augmentation\n",
      "Epoch 1/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.7171 - val_accuracy: 0.9842 - val_loss: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.1132 - val_accuracy: 0.9810 - val_loss: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.9716 - loss: 0.0943 - val_accuracy: 0.9859 - val_loss: 0.0551 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0814 - val_accuracy: 0.9878 - val_loss: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.0745 - val_accuracy: 0.9889 - val_loss: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0652 - val_accuracy: 0.9821 - val_loss: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0623 - val_accuracy: 0.9906 - val_loss: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0579 - val_accuracy: 0.9899 - val_loss: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.0559 - val_accuracy: 0.9916 - val_loss: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0535 - val_accuracy: 0.9931 - val_loss: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0503 - val_accuracy: 0.9920 - val_loss: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0489 - val_accuracy: 0.9912 - val_loss: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0476 - val_accuracy: 0.9916 - val_loss: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0462 - val_accuracy: 0.9929 - val_loss: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.0461 - val_accuracy: 0.9915 - val_loss: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0427 - val_accuracy: 0.9921 - val_loss: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0414 - val_accuracy: 0.9925 - val_loss: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0425 - val_accuracy: 0.9926 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0398 - val_accuracy: 0.9918 - val_loss: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0335 - val_accuracy: 0.9936 - val_loss: 0.0274 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0294 - val_accuracy: 0.9937 - val_loss: 0.0274 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0296 - val_accuracy: 0.9937 - val_loss: 0.0276 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0280 - val_accuracy: 0.9935 - val_loss: 0.0259 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0276 - val_accuracy: 0.9933 - val_loss: 0.0273 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0257 - val_accuracy: 0.9938 - val_loss: 0.0266 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0270 - val_accuracy: 0.9940 - val_loss: 0.0261 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0261 - val_accuracy: 0.9935 - val_loss: 0.0268 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0258 - val_accuracy: 0.9936 - val_loss: 0.0261 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0255 - val_accuracy: 0.9938 - val_loss: 0.0260 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0245 - val_accuracy: 0.9938 - val_loss: 0.0256 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.9936 - val_loss: 0.0264 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0241 - val_accuracy: 0.9940 - val_loss: 0.0256 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.9936 - val_loss: 0.0260 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0232 - val_accuracy: 0.9938 - val_loss: 0.0263 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0233 - val_accuracy: 0.9936 - val_loss: 0.0262 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0244 - val_accuracy: 0.9937 - val_loss: 0.0261 - learning_rate: 8.0000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0241 - val_accuracy: 0.9938 - val_loss: 0.0262 - learning_rate: 8.0000e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9938 - val_loss: 0.0262 - learning_rate: 8.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0235 - val_accuracy: 0.9937 - val_loss: 0.0262 - learning_rate: 8.0000e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0228 - val_accuracy: 0.9937 - val_loss: 0.0259 - learning_rate: 8.0000e-06\n",
      "Score for fold 2: loss of 0.025597207248210907; compile_metrics of 99.38101768493652%\n",
      "\n",
      "------------- Fold 3 -------------\n",
      "Training size: 40712, Validation size: 10178\n",
      "Augmenting training data...\n",
      "Training with 162848 examples after augmentation\n",
      "Epoch 1/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.7181 - val_accuracy: 0.9784 - val_loss: 0.0873 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.9689 - loss: 0.1048 - val_accuracy: 0.9829 - val_loss: 0.0708 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0841 - val_accuracy: 0.9726 - val_loss: 0.0831 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0772 - val_accuracy: 0.9874 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0640 - val_accuracy: 0.9888 - val_loss: 0.0501 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0586 - val_accuracy: 0.9872 - val_loss: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0550 - val_accuracy: 0.9900 - val_loss: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0548 - val_accuracy: 0.9898 - val_loss: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0519 - val_accuracy: 0.9903 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9849 - loss: 0.0483 - val_accuracy: 0.9897 - val_loss: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0469 - val_accuracy: 0.9882 - val_loss: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0447 - val_accuracy: 0.9886 - val_loss: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0429 - val_accuracy: 0.9891 - val_loss: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0430 - val_accuracy: 0.9888 - val_loss: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.0420 - val_accuracy: 0.9889 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0394 - val_accuracy: 0.9901 - val_loss: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0328 - val_accuracy: 0.9908 - val_loss: 0.0419 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0285 - val_accuracy: 0.9921 - val_loss: 0.0398 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0274 - val_accuracy: 0.9921 - val_loss: 0.0408 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0255 - val_accuracy: 0.9918 - val_loss: 0.0411 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0267 - val_accuracy: 0.9925 - val_loss: 0.0400 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0268 - val_accuracy: 0.9922 - val_loss: 0.0408 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0269 - val_accuracy: 0.9930 - val_loss: 0.0376 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.0251 - val_accuracy: 0.9915 - val_loss: 0.0422 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0251 - val_accuracy: 0.9921 - val_loss: 0.0403 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0254 - val_accuracy: 0.9923 - val_loss: 0.0414 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0242 - val_accuracy: 0.9929 - val_loss: 0.0388 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0233 - val_accuracy: 0.9932 - val_loss: 0.0381 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0222 - val_accuracy: 0.9931 - val_loss: 0.0387 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0227 - val_accuracy: 0.9929 - val_loss: 0.0392 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0216 - val_accuracy: 0.9932 - val_loss: 0.0388 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0223 - val_accuracy: 0.9934 - val_loss: 0.0394 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0215 - val_accuracy: 0.9926 - val_loss: 0.0398 - learning_rate: 4.0000e-05\n",
      "Score for fold 3: loss of 0.03761131688952446; compile_metrics of 99.30241703987122%\n",
      "\n",
      "------------- Fold 4 -------------\n",
      "Training size: 40712, Validation size: 10178\n",
      "Augmenting training data...\n",
      "Training with 162848 examples after augmentation\n",
      "Epoch 1/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.7855 - val_accuracy: 0.9866 - val_loss: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.1166 - val_accuracy: 0.9888 - val_loss: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.0942 - val_accuracy: 0.9858 - val_loss: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0789 - val_accuracy: 0.9897 - val_loss: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.0721 - val_accuracy: 0.9905 - val_loss: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0657 - val_accuracy: 0.9907 - val_loss: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0597 - val_accuracy: 0.9909 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0584 - val_accuracy: 0.9889 - val_loss: 0.0372 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0555 - val_accuracy: 0.9916 - val_loss: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0527 - val_accuracy: 0.9920 - val_loss: 0.0322 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0505 - val_accuracy: 0.9933 - val_loss: 0.0289 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0493 - val_accuracy: 0.9928 - val_loss: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0476 - val_accuracy: 0.9923 - val_loss: 0.0308 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0452 - val_accuracy: 0.9922 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0446 - val_accuracy: 0.9929 - val_loss: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0431 - val_accuracy: 0.9942 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0411 - val_accuracy: 0.9932 - val_loss: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0384 - val_accuracy: 0.9940 - val_loss: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0404 - val_accuracy: 0.9931 - val_loss: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0398 - val_accuracy: 0.9932 - val_loss: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0372 - val_accuracy: 0.9930 - val_loss: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0311 - val_accuracy: 0.9938 - val_loss: 0.0246 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0261 - val_accuracy: 0.9945 - val_loss: 0.0230 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0258 - val_accuracy: 0.9952 - val_loss: 0.0225 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0268 - val_accuracy: 0.9947 - val_loss: 0.0240 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0259 - val_accuracy: 0.9952 - val_loss: 0.0230 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0250 - val_accuracy: 0.9943 - val_loss: 0.0240 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0250 - val_accuracy: 0.9950 - val_loss: 0.0237 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0272 - val_accuracy: 0.9953 - val_loss: 0.0229 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0234 - val_accuracy: 0.9952 - val_loss: 0.0222 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0239 - val_accuracy: 0.9954 - val_loss: 0.0223 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0233 - val_accuracy: 0.9955 - val_loss: 0.0222 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0221 - val_accuracy: 0.9954 - val_loss: 0.0224 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0227 - val_accuracy: 0.9951 - val_loss: 0.0226 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0221 - val_accuracy: 0.9951 - val_loss: 0.0223 - learning_rate: 4.0000e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0217 - val_accuracy: 0.9953 - val_loss: 0.0223 - learning_rate: 8.0000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 0.9953 - val_loss: 0.0223 - learning_rate: 8.0000e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0232 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 8.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0225 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 8.0000e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0227 - val_accuracy: 0.9953 - val_loss: 0.0221 - learning_rate: 8.0000e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0223 - val_accuracy: 0.9953 - val_loss: 0.0223 - learning_rate: 1.6000e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0219 - val_accuracy: 0.9953 - val_loss: 0.0222 - learning_rate: 1.6000e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0217 - val_accuracy: 0.9953 - val_loss: 0.0223 - learning_rate: 1.6000e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0224 - val_accuracy: 0.9953 - val_loss: 0.0221 - learning_rate: 1.6000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0227 - val_accuracy: 0.9954 - val_loss: 0.0220 - learning_rate: 1.6000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0216 - val_accuracy: 0.9954 - val_loss: 0.0222 - learning_rate: 1.6000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0218 - val_accuracy: 0.9954 - val_loss: 0.0223 - learning_rate: 1.6000e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0218 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 1.6000e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0224 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 1.6000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0229 - val_accuracy: 0.9954 - val_loss: 0.0222 - learning_rate: 1.6000e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0232 - val_accuracy: 0.9954 - val_loss: 0.0222 - learning_rate: 3.2000e-07\n",
      "Epoch 52/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0215 - val_accuracy: 0.9953 - val_loss: 0.0220 - learning_rate: 3.2000e-07\n",
      "Epoch 53/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0213 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 3.2000e-07\n",
      "Epoch 54/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0228 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 3.2000e-07\n",
      "Epoch 55/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0203 - val_accuracy: 0.9954 - val_loss: 0.0220 - learning_rate: 3.2000e-07\n",
      "Epoch 56/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0232 - val_accuracy: 0.9953 - val_loss: 0.0223 - learning_rate: 6.4000e-08\n",
      "Epoch 57/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0224 - val_accuracy: 0.9953 - val_loss: 0.0221 - learning_rate: 6.4000e-08\n",
      "Epoch 58/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0227 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 6.4000e-08\n",
      "Epoch 59/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0205 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 6.4000e-08\n",
      "Epoch 60/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0241 - val_accuracy: 0.9954 - val_loss: 0.0220 - learning_rate: 6.4000e-08\n",
      "Epoch 61/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0218 - val_accuracy: 0.9954 - val_loss: 0.0222 - learning_rate: 1.2800e-08\n",
      "Epoch 62/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0225 - val_accuracy: 0.9954 - val_loss: 0.0222 - learning_rate: 1.2800e-08\n",
      "Epoch 63/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0229 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 1.2800e-08\n",
      "Epoch 64/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0232 - val_accuracy: 0.9954 - val_loss: 0.0220 - learning_rate: 1.2800e-08\n",
      "Epoch 65/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0217 - val_accuracy: 0.9954 - val_loss: 0.0220 - learning_rate: 1.2800e-08\n",
      "Epoch 66/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0213 - val_accuracy: 0.9953 - val_loss: 0.0222 - learning_rate: 2.5600e-09\n",
      "Epoch 67/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0203 - val_accuracy: 0.9953 - val_loss: 0.0222 - learning_rate: 2.5600e-09\n",
      "Epoch 68/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0227 - val_accuracy: 0.9953 - val_loss: 0.0221 - learning_rate: 2.5600e-09\n",
      "Epoch 69/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0224 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 2.5600e-09\n",
      "Epoch 70/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0222 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 2.5600e-09\n",
      "Epoch 71/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0210 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 5.1200e-10\n",
      "Epoch 72/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0228 - val_accuracy: 0.9954 - val_loss: 0.0222 - learning_rate: 5.1200e-10\n",
      "Epoch 73/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0214 - val_accuracy: 0.9953 - val_loss: 0.0221 - learning_rate: 5.1200e-10\n",
      "Epoch 74/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0219 - val_accuracy: 0.9954 - val_loss: 0.0221 - learning_rate: 5.1200e-10\n",
      "Score for fold 4: loss of 0.02196730487048626; compile_metrics of 99.53821897506714%\n",
      "\n",
      "------------- Fold 5 -------------\n",
      "Training size: 40712, Validation size: 10178\n",
      "Augmenting training data...\n",
      "Training with 162848 examples after augmentation\n",
      "Epoch 1/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.7938 - loss: 0.7628 - val_accuracy: 0.9750 - val_loss: 0.0856 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.1181 - val_accuracy: 0.9835 - val_loss: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.0976 - val_accuracy: 0.9873 - val_loss: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0856 - val_accuracy: 0.9883 - val_loss: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0787 - val_accuracy: 0.9897 - val_loss: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.0693 - val_accuracy: 0.9891 - val_loss: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.0684 - val_accuracy: 0.9891 - val_loss: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0640 - val_accuracy: 0.9881 - val_loss: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0586 - val_accuracy: 0.9896 - val_loss: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0583 - val_accuracy: 0.9914 - val_loss: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0540 - val_accuracy: 0.9890 - val_loss: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0519 - val_accuracy: 0.9901 - val_loss: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0513 - val_accuracy: 0.9910 - val_loss: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0508 - val_accuracy: 0.9904 - val_loss: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0496 - val_accuracy: 0.9906 - val_loss: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0402 - val_accuracy: 0.9922 - val_loss: 0.0276 - learning_rate: 2.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0377 - val_accuracy: 0.9926 - val_loss: 0.0268 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0355 - val_accuracy: 0.9927 - val_loss: 0.0267 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0337 - val_accuracy: 0.9924 - val_loss: 0.0259 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9892 - loss: 0.0328 - val_accuracy: 0.9930 - val_loss: 0.0258 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0341 - val_accuracy: 0.9929 - val_loss: 0.0257 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0326 - val_accuracy: 0.9929 - val_loss: 0.0251 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0322 - val_accuracy: 0.9928 - val_loss: 0.0260 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0307 - val_accuracy: 0.9928 - val_loss: 0.0264 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0298 - val_accuracy: 0.9929 - val_loss: 0.0257 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0317 - val_accuracy: 0.9933 - val_loss: 0.0257 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9893 - loss: 0.0321 - val_accuracy: 0.9934 - val_loss: 0.0254 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0300 - val_accuracy: 0.9931 - val_loss: 0.0253 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0295 - val_accuracy: 0.9930 - val_loss: 0.0245 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0293 - val_accuracy: 0.9934 - val_loss: 0.0247 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0290 - val_accuracy: 0.9935 - val_loss: 0.0255 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0271 - val_accuracy: 0.9934 - val_loss: 0.0246 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0275 - val_accuracy: 0.9931 - val_loss: 0.0250 - learning_rate: 4.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0291 - val_accuracy: 0.9932 - val_loss: 0.0250 - learning_rate: 4.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0284 - val_accuracy: 0.9933 - val_loss: 0.0246 - learning_rate: 8.0000e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0283 - val_accuracy: 0.9930 - val_loss: 0.0248 - learning_rate: 8.0000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0292 - val_accuracy: 0.9931 - val_loss: 0.0251 - learning_rate: 8.0000e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0270 - val_accuracy: 0.9932 - val_loss: 0.0247 - learning_rate: 8.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m5089/5089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0278 - val_accuracy: 0.9931 - val_loss: 0.0249 - learning_rate: 8.0000e-06\n",
      "Score for fold 5: loss of 0.024510247632861137; compile_metrics of 99.30241703987122%\n",
      "\n",
      "------------- K-FOLD CROSS VALIDATION RESULTS -------------\n",
      "Average scores for all folds:\n",
      "Accuracy: 99.39% (+/- 0.09%)\n",
      "Loss: 0.026875\n",
      "Individual fold results:\n",
      "Fold 1: Accuracy 99.42%, Loss 0.024688\n",
      "Fold 2: Accuracy 99.38%, Loss 0.025597\n",
      "Fold 3: Accuracy 99.30%, Loss 0.037611\n",
      "Fold 4: Accuracy 99.54%, Loss 0.021967\n",
      "Fold 5: Accuracy 99.30%, Loss 0.024510\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Your existing code for setup and preprocessing...\n",
    "# (Keep all the functions: extract_landmarks, augment_landmarks, load_and_preprocess_dataset, create_model, predict_with_tta)\n",
    "\n",
    "# Main execution with K-fold cross validation\n",
    "if __name__ == \"__main__\":\n",
    "    # Load all training data (combining train and validation sets for cross-validation)\n",
    "    print(\"Loading all training data...\")\n",
    "    base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../dataset/asl_split\"))\n",
    "    train_dir = os.path.join(base_dir, \"train\")\n",
    "    val_dir = os.path.join(base_dir, \"validation\")\n",
    "    test_dir = os.path.join(base_dir, \"test\")\n",
    "    \n",
    "    # Load training and validation data\n",
    "    X_train, y_train = load_and_preprocess_dataset(train_dir)\n",
    "    X_val, y_val = load_and_preprocess_dataset(val_dir)\n",
    "    \n",
    "    # Combine datasets for cross-validation\n",
    "    X_combined = np.concatenate([X_train, X_val], axis=0)\n",
    "    y_combined = np.concatenate([y_train, y_val], axis=0)\n",
    "    \n",
    "    print(f\"Combined dataset size: {len(X_combined)} examples\")\n",
    "    \n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    \n",
    "    for train_idx, val_idx in kfold.split(X_combined):\n",
    "        print(f\"\\n------------- Fold {fold_no} -------------\")\n",
    "        \n",
    "        # Generate fold training and validation data\n",
    "        X_train_fold = X_combined[train_idx]\n",
    "        y_train_fold = y_combined[train_idx]\n",
    "        X_val_fold = X_combined[val_idx]\n",
    "        y_val_fold = y_combined[val_idx]\n",
    "        \n",
    "        print(f\"Training size: {len(X_train_fold)}, Validation size: {len(X_val_fold)}\")\n",
    "        \n",
    "        # Create and compile model\n",
    "        num_classes = y_combined.shape[1]\n",
    "        model = create_model(num_classes)\n",
    "        \n",
    "        # Apply data augmentation\n",
    "        print(\"Augmenting training data...\")\n",
    "        augmented_data = []\n",
    "        augmented_labels = []\n",
    "        \n",
    "        for i in range(len(X_train_fold)):\n",
    "            # Add original sample\n",
    "            augmented_data.append(X_train_fold[i])\n",
    "            augmented_labels.append(y_train_fold[i])\n",
    "            \n",
    "            # Add augmented versions\n",
    "            aug_samples = augment_landmarks(X_train_fold[i], augmentation_factor=3)\n",
    "            for aug in aug_samples:\n",
    "                augmented_data.append(aug)\n",
    "                augmented_labels.append(y_train_fold[i])\n",
    "        \n",
    "        X_train_aug = np.array(augmented_data)\n",
    "        y_train_aug = np.array(augmented_labels)\n",
    "        print(f\"Training with {len(X_train_aug)} examples after augmentation\")\n",
    "        \n",
    "        # Training callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "        ]\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train_aug, y_train_aug,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation fold\n",
    "        scores = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        print(f\"Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%\")\n",
    "        \n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        \n",
    "        # Save fold model if needed\n",
    "        model.save(f\"asl_model_fold_{fold_no}.keras\")\n",
    "        \n",
    "        # Increment fold number\n",
    "        fold_no += 1\n",
    "    \n",
    "    # Print fold results\n",
    "    print(\"\\n------------- K-FOLD CROSS VALIDATION RESULTS -------------\")\n",
    "    print(\"Average scores for all folds:\")\n",
    "    print(f\"Accuracy: {np.mean(acc_per_fold):.2f}% (+/- {np.std(acc_per_fold):.2f}%)\")\n",
    "    print(f\"Loss: {np.mean(loss_per_fold):.6f}\")\n",
    "    print(\"Individual fold results:\")\n",
    "    for i in range(len(acc_per_fold)):\n",
    "        print(f\"Fold {i+1}: Accuracy {acc_per_fold[i]:.2f}%, Loss {loss_per_fold[i]:.6f}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
